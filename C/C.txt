<doc id="1063997" url="https://en.wikipedia.org/wiki?curid=1063997" title="ObjectCenter">
ObjectCenter

ObjectCenter is the version of CodeCenter for the C++ language. ObjectCenter is an integrated development environment (IDE) offering facilities similar to CodeCenter, plus other features such as class browsing facilities. ObjectCenter was formerly named Saber-C++. CodeCenter and ObjectCenter were created by CenterLine Software (formerly Saber Software), a company located in Cambridge, Massachusetts. CenterLine Software later became CenterLine Systems. It was subsequently acquired by Integrated Computer Solutions of Bedford, Massachusetts.



</doc>
<doc id="1003005" url="https://en.wikipedia.org/wiki?curid=1003005" title="Reference (C++)">
Reference (C++)

In the C++ programming language, a reference is a simple reference datatype that is less powerful but safer than the pointer type inherited from C. The name "C++ reference" may cause confusion, as in computer science a reference is a general concept datatype, with "pointers" and "C++ references" being specific reference datatype implementations. The definition of a reference in C++ is such that it does not need to exist. It can be implemented as a new name for an existing object (similar to rename keyword in Ada).

The declaration of the form:

where codice_1 is a type and codice_2 is an identifier whose type is reference to codice_1.

Examples:
Here, codice_4 and codice_5 are of type "reference to codice_6"

codice_7 is a function that returns a "reference to codice_6"

codice_9 is a function with a reference parameter, which is a "reference to codice_6"

codice_11 is a codice_12 with a member which is reference to codice_6

codice_14 is a function that returns a (non-reference type) codice_6 and codice_16 is an "alias" for codice_14

codice_18 is a constant reference pointing to a piece of storage having value 65.

Types which are of kind "reference to codice_1" are sometimes called reference types. Identifiers which are of reference type are called reference variables. To call them "variable", however, is in fact a misnomer, as we will see.

C++ references differ from pointers in several essential ways:
There is a simple conversion between pointers and references: the address-of operator (codice_20) will yield a pointer referring to the same object when applied to a reference, and a reference which is initialized from the dereference (codice_21) of a pointer value will refer to the same object as that pointer, where this is possible without invoking undefined behavior. This equivalence is a reflection of the typical implementation, which effectively compiles references into pointers which are implicitly dereferenced at each use. Though that is usually the case, the C++ Standard does not force compilers to implement references using pointers.

A consequence of this is that in many implementations, operating on a variable with automatic or static lifetime through a reference, although syntactically similar to accessing it directly, can involve hidden dereference operations that are costly.

Also, because the operations on references are so limited, they are much easier to understand than pointers and are more resistant to errors. While pointers can be made invalid through a variety of mechanisms, ranging from carrying a null value to out-of-bounds arithmetic to illegal casts to producing them from arbitrary integers, a previously-valid reference only becomes invalid in two cases:
The first is easy to detect automatically if the reference has static scoping, but is still a problem if the reference is a member of a dynamically allocated object; the second is more difficult to detect. These are the only concerns with references, and are suitably addressed by a reasonable allocation policy.

Then, the following call would place 9 in "y":
However, the following call would give a compiler error, since reference parameters not qualified with codice_22 can only be bound to addressable values:
If codice_24 actually requires its own copy of "x" that it can modify, it must create a copy explicitly. While the same technique could be applied using pointers, this would involve modifying every call site of the function to add cumbersome address-of (codice_20) operators to the argument, and would be equally difficult to undo, if the object became smaller later on.

Continuing the relationship between references and pointers (in C++ context), the former exhibit polymorphic capabilities, as one might expect:

The source above is valid C++ and generates the following output: 
codice_26

References are defined by the ISO C++ standard as follows (excluding the example section):



</doc>
<doc id="3250351" url="https://en.wikipedia.org/wiki?curid=3250351" title="Precompiled header">
Precompiled header

In computer programming, a precompiled header is a (C or C++) header file that is compiled into an intermediate form that is faster to process for the compiler. Usage of precompiled headers may significantly reduce compilation time, especially when applied to large header files, header files that include many other header files, or header files that are included in many translation units.

In the C and C++ programming languages, a header file is a file whose text may be automatically included in another source file by the C preprocessor by the use of a preprocessor directive in the source file.

Header files can sometimes contain very large amounts of source code (for instance, the header files codice_1 and codice_2 on Microsoft Windows and OS X, respectively). This is especially true with the advent of large "header" libraries that make extensive use of templates, like the Eigen math library and Boost C++ libraries. They are written almost entirely as header files that the user codice_3s, rather than being linked at runtime. Thus, each time the user compiles their program, the user is essentially recompiling numerous header libraries as well. (These would be precompiled into shared objects or dynamic link libraries in non "header" libraries.)

To reduce compilation times, some compilers allow header files to be compiled into a form that is faster for the compiler to process. This intermediate form is known as a "precompiled header", and is commonly held in a file named with the extension .pch or similar, such as .gch under the GNU Compiler Collection.

For example, given a C++ file source.cpp that includes header.hpp:
//header.hpp

//source.cpp

When compiling source.cpp for the first time with the precompiled header feature turned on, the compiler will generate a precompiled header, codice_4. The next time, if the timestamp of this header did not change, the compiler can skip the compilation phase relating to codice_5 and instead use header.pch directly.

Microsoft Visual C++ (version 6.0 and newer) can precompile any code, not just headers.
It can do this in two ways: either precompiling all code up to a file whose name matches the codice_6 option or (when codice_7 is specified without any codice_8) precompiling all code up to the first occurrence of codice_9 in the code
The precompiled output is saved in a file named after the codice_8 given to the codice_7 option, with a codice_12 extension, or in a file named according to the name supplied by the codice_13 option.
The codice_14 option, subordinate to the codice_7 option if used together, causes the compiler to make used of already precompiled code from such a file.

codice_16 (named codice_17 before Visual Studio 2017) is a file generated by the Microsoft Visual Studio IDE wizard, that describes both standard system and project specific include files that are used frequently but hardly ever change.

The "afx" in "stdafx.h" stands for "application framework extensions". AFX was the original abbreviation for the Microsoft Foundation Classes (MFC). While the name stdafx.h was used by default in MSVC projects prior to version 2017, any alternative name may be manually specified.

Compatible compilers will precompile this file to reduce overall compile times. Visual C++ will not compile anything before the codice_18 in the source file, unless the compile option codice_19 is unchecked (by default); it assumes all code in the source up to and including that line is already compiled.

The clang compiler has two mechanisms.

The original, simpler and less powerful, mechanism was pretokenized headers where the stream of lexical tokens in one or more source files is stored in what is in effect a "token cache", from which they can be more quickly retrieved in subsequent compilations than performing lexical analysis again on the original source files.

Compared to a full precompiled header mechanism this has the advantages of language independence, as lexical analysis is the same in clang for the C, C++, Objective C, and Objective C++ languages, and architecture independence, as the same stream of tokens can be used when compiling for different target architectures.
It however has the disadvantage of not going any "further" than simple lexical analysis, requiring that syntactic and semantic analysis of the token stream be performed with every compilation; and the time to compile scaling linearly with the size, in lexical tokens, of the pretokenized file, which is not necessarily the case for a fully-fledged precompilation mechanism.

The pretokenization mechanism includes several minor mechanisms for assisting the pre-processor: caching of file existence and datestamp information, and recording inclusion guards so that guarded code can be quickly skipped over.

Later clang development thus introduced a fully fledged precompiled header mechanism.
This both tokenizes the input source code and performs syntactic and semantic analyses of it, writing out the compiler's internal generated abstract syntax tree (AST) and symbol table to a precompiled header file.

Compared to the pretokenized header mechanism, this scales much better, as when reading the precompiled header file back in the compiler is not constrained by the fact that the input is a stream (of lexical tokens) to read the file linearly, using sequential I/O.
The AST is written to the precompiled header file in such a way that the compiler can read it in using random-access I/O, in particular "not" reading in the parts of the precompiled AST that subsequent code does not in fact reference, which is a common occurrence with headers that provide large template libraries.
This eliminates the problem of reading the cache file scaling linearly with the size of the precompiled input.

The downside is, however, the loss of generality compared to the pretokenization mechanism.
The precompiled header has to store information about the language dialect being used, down to the level of whether things like C++-style codice_20 comments are enabled in non-C++ languages, the target architecture, the compiler version (more specifically, the version of the internal AST data structure that the compiler is using), and the list of predefined pre-processor macros; so that upon re-reading the precompiled header file the compiler can ensure that it is using a precompiled header that is valid for the compilation at hand.

clang's precompiled header scheme, with some improvements such as the ability for one precompiled header to reference another, internally used, precompiled header, also forms the basis for its modules mechanism.
It uses the same "bitcode" file format that is employed by LLVM, encapsulated in clang-specific sections within Common Object File Format or Extensible Linking Format files.

Precompiled headers are supported in GCC (3.4 and newer). GCC's approach is similar to these of VC and compatible compilers. GCC saves precompiled versions of header files using a ".gch" suffix. When compiling a source file, the compiler checks whether this file is present in the same directory and uses it if possible.

GCC can only use the precompiled version if the same compiler switches are set as when the header was compiled and it may use at most one. Further, only preprocessor instructions may be placed before the precompiled header (because it must be directly or indirectly included through another normal header, before any compilable code).

GCC automatically identifies most header files by their extension. However, if this fails (e.g. because of non-standard header extensions), the -x switch can be used to ensure that GCC treats the file as a header.

In the default project configuration, the C++Builder compiler implicitly generates precompiled headers for all headers included by a source module until the line codice_9 is found. Precompiled headers are shared for all modules of the project if possible. For example, when working with the Visual Component Library, it is common to include the codice_22 header first which contains most of the commonly used VCL header files. Thus, the precompiled header can be shared across all project modules, which dramatically reduces the build times.

In addition, C++Builder can be instrumented to use a specific header file as precompiled header, similar to the mechanism provided by Visual C++.

C++Builder 2009 introduces a "Precompiled Header Wizard" which parses all source modules of the project for included header files, classifies them (i.e. excludes header files if they are part of the project or do not have an Include guard) and generates and tests a precompiled header for the specified files automatically.




</doc>
<doc id="198000" url="https://en.wikipedia.org/wiki?curid=198000" title="Template metaprogramming">
Template metaprogramming

Template metaprogramming (TMP) is a metaprogramming technique in which templates are used by a compiler to generate temporary source code, which is merged by the compiler with the rest of the source code and then compiled. The output of these templates include compile-time constants, data structures, and complete functions. The use of templates can be thought of as compile-time execution. The technique is used by a number of languages, the best-known being C++, but also Curl, D, and XL.

Template metaprogramming was, in a sense, discovered accidentally.

Some other languages support similar, if not more powerful, compile-time facilities (such as Lisp macros), but those are outside the scope of this article.

The use of templates as a metaprogramming technique requires two distinct operations: a template must be defined, and a defined template must be instantiated. The template definition describes the generic form of the generated source code, and the instantiation causes a specific set of source code to be generated from the generic form in the template.

Template metaprogramming is Turing-complete, meaning that any computation expressible by a computer program can be computed, in some form, by a template metaprogram.

Templates are different from "macros". A macro is a piece of code that executes at compile time and either performs textual manipulation of code to-be compiled (e.g. C++ macros) or manipulates the abstract syntax tree being produced by the compiler (e.g. Rust or Lisp macros). Textual macros are notably more independent of the syntax of the language being manipulated, as they merely change the in-memory text of the source code right before compilation.

Template metaprograms have no mutable variables— that is, no variable can change value once it has been initialized, therefore template metaprogramming can be seen as a form of functional programming. In fact many template implementations implement flow control only through recursion, as seen in the example below.

Though the syntax of template metaprogramming is usually very different from the programming language it is used with, it has practical uses. Some common reasons to use templates are to implement generic programming (avoiding sections of code which are similar except for some minor variations) or to perform automatic compile-time optimization such as doing something once at compile time rather than every time the program is run — for instance, by having the compiler unroll loops to eliminate jumps and loop count decrements whenever the program is executed.

What exactly "programming at compile-time" means can be illustrated with an example of a factorial function, which in non-template C++ can be written using recursion as follows:

The code above will execute at run time to determine the factorial value of the literals 4 and 0.
By using template metaprogramming and template specialization to provide the ending condition for the recursion, the factorials used in the program—ignoring any factorial not used—can be calculated at compile time by this code:

The code above calculates the factorial value of the literals 4 and 0 at compile time and uses the results as if they were precalculated constants.
To be able to use templates in this manner, the compiler must know the value of its parameters at compile time, which has the natural precondition that factorial<X>::value can only be used if X is known at compile time. In other words, X must be a constant literal or a constant expression.

In C++11, constexpr, a way to let the compiler execute simple constant expressions, was added. Using constexpr, one can use the usual recursive factorial definition.

The factorial example above is one example of compile-time code optimization in that all factorials used by the program are pre-compiled and injected as numeric constants at compilation, saving both run-time overhead and memory footprint. It is, however, a relatively minor optimization.

As another, more significant, example of compile-time loop unrolling, template metaprogramming can be used to create length-"n" vector classes (where "n" is known at compile time). The benefit over a more traditional length-"n" vector is that the loops can be unrolled, resulting in very optimized code. As an example, consider the addition operator. A length-"n" vector addition might be written as
When the compiler instantiates the function template defined above, the following code may be produced:

The compiler's optimizer should be able to unroll the codice_1 loop because the template parameter codice_2 is a constant at compile time.

However, take care and exercise caution as this may cause code bloat as separate unrolled code will be generated for each 'N'(vector size) you instantiate with.

Polymorphism is a common standard programming facility where derived objects can be used as instances of their base object but where the derived objects' methods will be invoked, as in this code

where all invocations of codice_3 methods will be those of the most-derived class. This "dynamically polymorphic" behaviour is (typically) obtained by the creation of virtual look-up tables for classes with virtual methods, tables that are traversed at run time to identify the method to be invoked. Thus, "run-time polymorphism" necessarily entails execution overhead (though on modern architectures the overhead is small).

However, in many cases the polymorphic behaviour needed is invariant and can be determined at compile time. Then the Curiously Recurring Template Pattern (CRTP) can be used to achieve static polymorphism, which is an imitation of polymorphism in programming code but which is resolved at compile time and thus does away with run-time virtual-table lookups. For example: 

Here the base class template will take advantage of the fact that member function bodies are not instantiated until after their declarations, and it will use members of the derived class within its own member functions, via the use of a codice_4, thus at compilation generating an object composition with polymorphic characteristics. As an example of real-world usage, the CRTP is used in the Boost iterator library.

Another similar use is the "Barton–Nackman trick", sometimes referred to as "restricted template expansion", where common functionality can be placed in a base class that is used not as a contract but as a necessary component to enforce conformant behaviour while minimising code redundancy.

The benefit of static tables is the replacement of "expensive" calculations with a simple array indexing operation (for examples see lookup table).
In C++ exists more than one way to generate a static table at compile time.
The following listing shows an example of creating a very simple table by using recursive structs and Variadic templates.
The table has a size of ten and each value is just the index multiplied with itself.

constexpr int TABLE_SIZE = 10;
template<int INDEX = 0, int ...D>
struct Helper : Helper<INDEX + 1, D..., INDEX * INDEX> { };
template<int ...D>
struct Helper<TABLE_SIZE, D...> {

constexpr std::array<int, TABLE_SIZE> table = Helper<>::table;

enum {

int main() {

The idea behind this is that the struct Helper recursively inherits from a struct with one more template argument (in this example calculated as INDEX * INDEX) until the specialization of the template ends the recursion at a size of 10 elements. The specialization simply uses the variable argument list as elements for the array.
The compiler will produce code similar to the following (taken from clang called with -Xclang -ast-print -fsyntax-only).

template <int INDEX = 0, int ...D> struct Helper : Helper<INDEX + 1, D..., INDEX * INDEX> {
template<> struct Helper<0, <» : Helper<0 + 1, 0 * 0> {
template<> struct Helper<1, <0» : Helper<1 + 1, 0, 1 * 1> {
template<> struct Helper<2, <0, 1» : Helper<2 + 1, 0, 1, 2 * 2> {
template<> struct Helper<3, <0, 1, 4» : Helper<3 + 1, 0, 1, 4, 3 * 3> {
template<> struct Helper<4, <0, 1, 4, 9» : Helper<4 + 1, 0, 1, 4, 9, 4 * 4> {
template<> struct Helper<5, <0, 1, 4, 9, 16» : Helper<5 + 1, 0, 1, 4, 9, 16, 5 * 5> {
template<> struct Helper<6, <0, 1, 4, 9, 16, 25» : Helper<6 + 1, 0, 1, 4, 9, 16, 25, 6 * 6> {
template<> struct Helper<7, <0, 1, 4, 9, 16, 25, 36» : Helper<7 + 1, 0, 1, 4, 9, 16, 25, 36, 7 * 7> {
template<> struct Helper<8, <0, 1, 4, 9, 16, 25, 36, 49» : Helper<8 + 1, 0, 1, 4, 9, 16, 25, 36, 49, 8 * 8> {
template<> struct Helper<9, <0, 1, 4, 9, 16, 25, 36, 49, 64» : Helper<9 + 1, 0, 1, 4, 9, 16, 25, 36, 49, 64, 9 * 9> {
template<> struct Helper<10, <0, 1, 4, 9, 16, 25, 36, 49, 64, 81» {

Since C++17 this can be more readable written as:

constexpr int TABLE_SIZE = 10;

constexpr std::array<int, TABLE_SIZE> table = [] { // OR: constexpr auto table

enum {

int main() {

To show a more sophisticated example the code in the following listing has been extended to have a helper for value calculation (in preparation for more complicated computations), a table specific offset and a template argument for the type of the table values (e.g. uint8_t, uint16_t, ...). 

constexpr int TABLE_SIZE = 20;
constexpr int OFFSET = 12;
template <typename VALUETYPE, VALUETYPE OFFSET, VALUETYPE INDEX>
struct ValueHelper {

template<typename VALUETYPE, VALUETYPE OFFSET, int N = 0, VALUETYPE ...D>
struct Helper : Helper<VALUETYPE, OFFSET, N+1, D..., ValueHelper<VALUETYPE, OFFSET, N>::value> { };
template<typename VALUETYPE, VALUETYPE OFFSET, VALUETYPE ...D>
struct Helper<VALUETYPE, OFFSET, TABLE_SIZE, D...> {

constexpr std::array<uint16_t, TABLE_SIZE> table = Helper<uint16_t, OFFSET>::table;

int main() {

Which could be written as following since C++17:


constexpr int TABLE_SIZE = 20;
constexpr int OFFSET = 12;

template<typename VALUETYPE, VALUETYPE OFFSET>
constexpr std::array<VALUETYPE, TABLE_SIZE> table = [] { // OR: constexpr auto table

int main() {
} 





</doc>
<doc id="4573232" url="https://en.wikipedia.org/wiki?curid=4573232" title="Compatibility of C and C++">
Compatibility of C and C++

The C and C++ programming languages are closely related but have many significant differences. C++ began as a fork of an early, pre-standardized C, and was designed to be mostly source-and-link compatible with C compilers of the time. Due to this, development tools for the two languages (such as IDEs and compilers) are often integrated into a single product, with the programmer able to specify C or C++ as their source language. 

However, C is not a subset of C++, and nontrivial C programs will not compile as C++ code without modification. Likewise, C++ introduces many features that are not available in C and in practice almost all code written in C++ is not conforming C code. This article, however, focuses on differences that cause conforming C code to be ill-formed C++ code, or to be conforming/well-formed in both languages but to behave differently in C and C++.

Bjarne Stroustrup, the creator of C++, has suggested that the incompatibilities between C and C++ should be reduced as much as possible in order to maximize inter-operability between the two languages. Others have argued that since C and C++ are two different languages, compatibility between them is useful but not vital; according to this camp, efforts to reduce incompatibility should not hinder attempts to improve each language in isolation. The official rationale for the 1999 C standard (C99) "endorse<nowiki>[d]</nowiki> the principle of maintaining the largest common subset" between C and C++ "while maintaining a distinction between them and allowing them to evolve separately", and stated that the authors were "content to let C++ be the big and ambitious language."

Several additions of C99 are not supported in the current C++ standard or conflicted with C++ features, such as variable-length arrays, native complex number types and the codice_1 type qualifier. On the other hand, C99 reduced some other incompatibilities compared with C89 by incorporating C++ features such as codice_2 comments and mixed declarations and code.

C++ enforces stricter typing rules (no implicit violations of the static type system), and initialization requirements (compile-time enforcement that in-scope variables do not have initialization subverted) than C, and so some valid C code is disallowed in C++. A rationale for these is provided in Annex C.1 of the ISO C++ standard.

Though C++ favors this:








C99 and C11 added several additional features to C that have not been incorporated into standard C++, such as complex numbers, variable length arrays (note that complex numbers and variable length arrays are designated as optional extensions in C11), flexible array members, the restrict keyword, array parameter qualifiers, compound literals, and designated initializers. 




C++ adds numerous additional keywords to support its new features. This renders C code using those keywords for identifiers invalid in C++. For example:

There are a few syntactical constructs that are valid in both C and C++ but produce different results in the two languages.


Several of the other differences from the previous section can also be exploited to create code that compiles in both languages but behaves differently. For example, the following function will return different values in C and C++:

This is due to C requiring codice_15 in front of structure tags (and so codice_60 refers to the variable), but C++ allowing it to be omitted (and so codice_60 refers to the implicit codice_62). Beware that the outcome is different when the codice_44 declaration is placed inside the function: then the presence of an identifier with same name in the function scope inhibits the implicit codice_62 to take effect for C++, and the outcome for C and C++ would be the same. Observe also that the ambiguity in the example above is due to the use of the parenthesis with the codice_65 operator. Using codice_66 would expect codice_67 to be an expression and not a type, and thus the example would not compile with C++.

While C and C++ maintain a large degree of source compatibility, the object files their respective compilers produce can have important differences that manifest themselves when intermixing C and C++ code. Notably:

For these reasons, for C++ code to call a C function codice_68, the C++ code must prototype codice_68 with codice_70. Likewise, for C code to call a C++ function codice_71, the C++ code for codice_71 must be declared with codice_70.

A common practice for header files to maintain both C and C++ compatibility is to make its declaration be codice_70 for the scope of the header:

Differences between C and C++ linkage and calling conventions can also have subtle implications for code that uses function pointers. Some compilers will produce non-working code if a function pointer declared codice_70 points to a C++ function that is not declared codice_70.

For example, the following code:
Using Sun Microsystems' C++ compiler, this produces the following warning:

This is because codice_77 is not declared with C linkage and calling conventions, but is being passed to the C function codice_68.



</doc>
<doc id="6484336" url="https://en.wikipedia.org/wiki?curid=6484336" title="CodeSynthesis XSD">
CodeSynthesis XSD

CodeSynthesis XSD is an XML Data Binding compiler for C++ developed by Code Synthesis and dual-licensed under the GNU GPL and a proprietary license. Given an XML instance specification (XML Schema), it generates C++ classes that represent the given vocabulary as well as parsing and serialization code. It is supported on a large number of platforms, including AIX, Linux, HP-UX, OS X, Solaris, Windows, OpenVMS, and z/OS. Supported C++ compilers include GNU G++, Intel C++, HP aCC, Solaris Studio C++, IBM XL C++, and Microsoft Visual C++. A version for mobile and embedded systems, called CodeSynthesis XSD/e, is also available.

One of the unique features of CodeSynthesis XSD is its support for two different XML Schema to C++ mappings: in-memory C++/Tree and stream-oriented C++/Parser. The C++/Tree mapping is a traditional mapping with a tree-like, in-memory data structure. C++/Parser is a new, SAX-like mapping which represents the information stored in XML instance documents as a hierarchy of vocabulary-specific parsing events. In comparison to C++/Tree, the C++/Parser mapping allows one to handle large XML documents that would not fit in memory, perform stream-oriented processing, or use an existing in-memory representation. The XSD-generated code can target C++98/03 or C++11.

CodeSynthesis XSD itself is written in C++.



</doc>
<doc id="1984529" url="https://en.wikipedia.org/wiki?curid=1984529" title="Argument-dependent name lookup">
Argument-dependent name lookup

In the C++ programming language, argument-dependent lookup (ADL), or argument-dependent name lookup, applies to the lookup of an unqualified function name depending on the types of the arguments given to the function call. This behavior is also known as Koenig lookup, as it is often attributed to Andrew Koenig, though he is not its inventor.

During argument-dependent lookup, other namespaces not considered during normal lookup may be searched where the set of namespaces to be searched depends on the types of the function arguments. Specifically, the set of declarations discovered during the ADL process, and considered for resolution of the function name, is the union of the declarations found by normal lookup with the declarations found by looking in the set of namespaces associated with the types of the function arguments.

An example of ADL looks like this:
Even though the function is not in namespace NS, nor is namespace NS in scope, the function is found because of the declared types of the actual parameters in the function call statement. 

A common pattern in the C++ Standard Library is to declare overloaded operators that will be found in this manner. For example, this simple Hello World program would not compile if it weren't for ADL:

Using codice_1 is equivalent to calling codice_2 without the codice_3 qualifier. However, in this case, the overload of operator« that works for codice_4 is in the codice_5 namespace, so ADL is required for it to be used.

The following code would work without ADL (which is applied to it anyway):

It works because the output operator for integers is a member function of the codice_6 class, which is the type of codice_7. 
Thus, the compiler interprets this statement as
which it can resolve during normal lookup. However, consider that e.g. the codice_8 overloaded codice_9 is a non-member function in the codice_10 namespace and, thus, requires ADL for a correct lookup:
The codice_10 namespace overloaded non-member codice_2 function to handle strings is another example:

As Koenig points out in a personal note, without ADL the compiler would indicate an error stating it could not find codice_13 as the statement doesn't explicitly specify that it is found in the codice_10 namespace.

Functions found by ADL are considered part of a class's interface. In the C++ Standard Library, several algorithms use unqualified calls to codice_15 from within the codice_5 namespace. As a result, the generic codice_17 function is used if nothing else is found, but if these algorithms are used with a third-party class, codice_18, found in another namespace that also contains codice_19, that overload of codice_15 will be used.

While ADL makes it practical for functions defined outside of a class to behave as if they were part of the interface of that class, it makes namespaces less strict and so can require the use of fully qualified names when they would not otherwise be needed. For example, the C++ standard library makes extensive use of unqualified calls to to swap two values. The idea is that then one can define an own version of std::swap in one's own namespace and it will be used within the standard library algorithms. In other words, the behavior of

may or may not be the same as the behavior of

(where codice_21 and codice_22 are of type codice_23) because if codice_24 exists, the second of the above examples will call it while the first will not. Furthermore, if for some reason both codice_24 and codice_26 are defined, then the first example will call codice_26 but the second will not compile because codice_28 would be ambiguous.

In general, over-dependence on ADL can lead to semantic problems. If one library, codice_29, expects unqualified calls to codice_30 to have one meaning and another library, codice_31 expects it to have another, then namespaces lose their utility. If, however, codice_29 expects codice_33 to have one meaning and codice_31 does likewise, then there is no conflict, but calls to codice_30 would have to be fully qualified (i.e. codice_36 as opposed to codice_37) lest ADL get in the way.



</doc>
<doc id="542190" url="https://en.wikipedia.org/wiki?curid=542190" title="Copy constructor (C++)">
Copy constructor (C++)

In the C++ programming language, a copy constructor is a special constructor for creating a new object as a copy of an existing object. Copy constructors are the standard way of copying objects in C++, as opposed to cloning, and have C++-specific nuances.

The first argument of such a constructor is a reference to an object of the same type as is being constructed (const or non-const), which might be followed by parameters of any type (all having default values).

Normally the compiler automatically creates a copy constructor for each class (known as an implicit copy constructor) but for special cases the programmer creates the copy constructor, known as a user-defined copy constructor. In such cases, the compiler does not create one. Hence, there is always one copy constructor that is either defined by the user or by the system.

A user-defined copy constructor is generally needed when an object owns pointers or non-shareable references, such as to a file, in which case a destructor and an assignment operator should also be written (see Rule of three).

Copying of objects is achieved by the use of a copy constructor and an assignment operator. A copy constructor has as its first parameter a (possibly const or volatile) reference to its own class type. It can have more arguments, but the rest must have default values associated with them. The following would be valid copy constructors for class codice_1:

The first one should be used unless there is a good reason to use one of the others. One of the differences between the first and the second is that temporaries can be copied with the first. For example:

Another difference between them is the obvious:

The codice_2 form of the copy constructor is used when it is necessary to modify the copied object. This is very rare but it can be seen used in the standard library's codice_3. A reference must be provided:

The following are invalid copy constructors (Reason - codice_4 is not passed as reference) :

because the call to those constructors would require a copy as well, which would result in an infinitely recursive call.

The following cases may result in a call to a copy constructor:


These cases are collectively called "copy-initialization" and are equivalent to:<ref name="C++03 8.5/12">ISO/IEC (2003). "ISO/IEC 14882:2003(E): Programming Languages - C++ §8.5 Initializers [dcl.init]" para. 12</ref>
codice_5

It is however, not guaranteed that a copy constructor will be called in these cases, because the C++ Standard allows the compiler to optimize the copy away in certain cases, one example being the return value optimization (sometimes referred to as RVO).

An object can be assigned value using one of the two techniques:

An object can be initialized by any one of the following ways.

a. Through declaration

b. Through function arguments

c. Through function return value
The copy constructor is used only for initializations, and does not apply to assignments where the assignment operator is used instead.

The implicit copy constructor of a class calls base copy constructors and copies its members by means appropriate to their type. If it is a class type, the copy constructor is called. If it is a scalar type, the built-in assignment operator is used. Finally, if it is an array, each element is copied in the manner appropriate to its type.

By using a user-defined copy constructor the programmer can define the behavior to be performed when an object is copied.

These examples illustrate how copy constructors work and why they are required sometimes.

Consider the following example:
Output

As expected, "timmy" has been copied to the new object, "timmy_clone". While "timmy's" age was changed, "timmy_clone's" age remained the same. This is because they are totally different objects.

The compiler has generated a copy constructor for us, and it could be written like this:

So, when do we really need a user-defined copy constructor? The next section will explore that question.

Now, consider a very simple dynamic array class like the following:

Output

Since we did not specify a copy constructor, the compiler generated one for us. The generated constructor would look something like:

The problem with this constructor is that it performs a shallow copy of the "data" pointer. It only copies the address of the original data member; this means they both share a pointer to the same chunk of memory, which is not what we want. When the program reaches line (1), "copy's" destructor gets called (because objects on the stack are destroyed automatically when their scope ends). 
"Array's" destructor deletes the "data" array of the original, therefore when it deleted "copy's" data, because they share the same pointer, it also deleted "first's" data. Line (2) now accesses invalid data and writes to it! This produces the infamous segmentation fault. 

If we write our own copy constructor that performs a "deep copy" then this problem goes away. 

Here, we are creating a new int array and copying the contents to it. Now, "other's" destructor deletes only its data, and not "first's" data. Line (2) will not produce a segmentation fault anymore.

Instead of doing a deep copy right away, there are some optimization strategies that can be used. These allow you to safely share the same data between several objects, thus saving space. The copy-on-write strategy makes a copy of the data only when it is written to. Reference counting keeps the count of how many objects are referencing the data, and will delete it only when this count reaches zero (e.g. boost::shared_ptr).

Contrary to expectations, a template copy constructor is not a user-defined copy constructor. Thus it is not enough to just have:

(Note that the type of codice_6 can be codice_7.) A user-defined, non-template copy constructor must also be provided for construction of Array from Array.

There is no such thing as "bitwise copy constructor" in C++. However, the default generated copy constructor copies by invoking copy constructors on members, and for a raw pointer member this will copy the raw pointer (i.e. not a deep copy).

A logical copy constructor makes a true copy of the structure as well as its dynamic structures. Logical copy constructors come into the picture mainly when there are pointers or complex objects within the object being copied.

An explicit copy constructor is one that is declared explicit by using the explicit keyword. For example:

It is used to prevent copying of objects at function calls or with the copy-initialization syntax.



</doc>
<doc id="2482237" url="https://en.wikipedia.org/wiki?curid=2482237" title="Typedef">
Typedef

typedef is a reserved keyword in the C and C++ programming languages. It is used to create an alias name for another data type. As such, it is often used to simplify the syntax of declaring complex data structures consisting of struct and union types, but is just as common in providing specific descriptive type names for integer data types of varying lengths.

The syntax of the typedef declaration is:


The name of the type alias declared follows the same syntax as declaring any other C identifier, therefore in more detailed form:


In the C standard library and in POSIX specifications the identifier for the typedef alias definition is often suffixed with , such as in size_t and time_t. This is practiced in other coding systems, although POSIX explicitly reserves this practice for POSIX data types.

typedef int length;
This creates the type as a synonym of the type .

A typedef declaration may be used as documentation by indicating the meaning of a variable within the programming context, e.g., it may include the expression of a unit of measurement or counts. The generic declarations,
int current_speed;
int high_score;

void congratulate(int your_score) {

may be expressed by declaring context specific types:
typedef int km_per_hour;
typedef int points;

// `km_per_hour` is synonymous with `int` here, and thus, the compiler treats
// our new variables as integers.
km_per_hour current_speed;
points high_score;

void congratulate(points your_score) {

Both sections of code execute identically. However, the use of typedef declarations in the second code block makes it clear that the two variables, while represented by the same data type , represent different or incompatible data. The definition in of indicates to the programmer that (or any other variable not declared as a ) should not be passed as an argument. This would not be as apparent if both were declared as variables of datatype. However, the indication is "for the programmer only"; the C/C++ compiler considers both variables to be of type and does not flag type mismatch warnings or errors for "wrong" argument types for in the code snippet below:
void foo() {

Although the compiler considers to be equivalent to , the two cannot be used interchangeably when the type is changed via a prefix of , , or .
void foo() {

A typedef may be used to simplify the declaration of a compound type (struct, union) or pointer type. For example,
struct MyStruct {

This defines the data type . A variable declaration of this type in C also requires the keyword , but it may be omitted in C++:
struct MyStruct a;
A typedef declaration eliminates the requirement of specifying in C. For example, the declaration
typedef struct MyStruct newtype;
is reduced to:
newtype a;
The structure declaration and typedef may also be combined into a single statement:
typedef struct MyStruct {
} newtype;
Or it may be used as follows:
typedef struct {
} newtype;
In C++, in contrast to C, the keywords , , and are optional in variable declarations that are separate from the definitions, as long as there is no ambiguity to another identifier:
struct MyStruct x; // This is legal
MyStruct y; // This is also legal
As such, can be used wherever can be used. However, the reverse is not true; for instance, the constructor methods for cannot be named .

A notorious example where even C++ needs the keyword is the POSIX stat system call that uses a struct of the same name in its arguments:
int stat(const char *filename, struct stat *buf)

Here both C as well as C++ need the keyword in the parameter definition.

The typedef may be used to define a new pointer type.
typedef int *intptr;

intptr ptr;

// Same as:
// int *ptr;

Using typedef to define a new pointer type may sometimes lead to confusion. For example:
typedef int *intptr;

// Both `cliff` and `allen` are of type `int*`.
intptr cliff, allen;

// `cliff2` is of type `int*`, but `allen2` is of type `int**`.
intptr cliff2, *allen2;

// Same as:
// intptr cliff2;
// intptr *allen2;
Above, means defining 2 variables with type for both. This is because a type defined by typedef is a type, not an expansion. In other words, , which is the type, decorates both and . For , the type decorates the and . So, is equivalent to 2 separate definitions, and . means that is a pointer pointing to a memory with type. Shortly, has the type, .

Typedefs can also simplify definitions or declarations for structure pointer types. Consider this:
struct Node {

Using typedef, the above code can be rewritten like this:
typedef struct Node Node;

struct Node {

In C, one can declare multiple variables of the same type in a single statement, even mixing structure with pointer or non-pointers. However, one would need to prefix an asterisk to each variable to designate it as a pointer. In the following, a programmer might assume that was indeed a , but a typographical error means that is a . This can lead to subtle syntax errors.
struct Node *startptr, *endptr, *curptr, *prevptr, errptr, *refptr;
By defining the typedef , it is assured that all variables are structure pointer types, or say, that each variable is a pointer type pointing to a structure type.
typedef struct Node* NodePtr;

NodePtr startptr, endptr, curptr, prevptr, errptr, refptr;

int do_math(float arg1, int arg2) {

int call_a_func(int (*call_this)(float, int)) {

int final_result = call_a_func(&do_math);
The preceding code may rewritten with typedef specifications:
typedef int (*MathFunc)(float, int);

int do_math(float arg1, int arg2) {

int call_a_func(MathFunc call_this) {

int final_result = call_a_func(&do_math);
Here, is the new alias for the type. A is a pointer to a function that returns an integer and takes as arguments a float followed by an integer.

When a function returns a function pointer, it can be even more confusing without typedef. The following is the function prototype of "signal(3)" from FreeBSD:
void (*signal(int sig, void (*func)(int)))(int);
The function declaration above is cryptic as it does not clearly show what the function accepts as arguments, or the type that it returns. A novice programmer may even assume that the function accepts a single as its argument and returns nothing, but in reality it also needs a function pointer and returns another function pointer. It can be written more cleanly:
typedef void (*sighandler_t)(int);

sighandler_t signal(int sig, sighandler_t func);
A typedef can also be used to simplify the definition of array types. For example,
typedef char arrType[6];

arrType arr = {1, 2, 3, 4, 5, 6};
arrType *pArr;

// Same as:
// char arr[6] = {1, 2, 3, 4, 5, 6};
// char (*pArr)[6];
Here, is the new alias for the type, which is an array type with 6 elements. For , is a pointer pointing to the memory of the type.

A typedef is created using type "definition" syntax but can be used as if it were created using type "cast" syntax. (Type casting changes a data type.) For instance, in each line after the first line of:
// `funcptr` is a pointer to a function which takes a `double` and returns an `int`.
typedef int (*funcptr)(double);

// Valid in C or C++.
funcptr x = (funcptr) NULL;

// Only valid in C++.
funcptr y = funcptr(NULL);
funcptr z = static_cast<funcptr>(NULL);

Note that, without the typedef, it is generally not possible to use definition syntax and cast syntax interchangeably. For example:
void *p = NULL;

// This is legal.
int (*x)(double) = (int (*)(double)) p;

// Left-hand side is not legal.
int (*)(double) y = (int (*)(double)) p;

// Right-hand side is not legal.
int (*z)(double) = (int (*p)(double));
Kernigan and Ritchie state in their book "The C Programming Language" two reasons for using a typedef. First, it provides a means to make a program more portable or easier to maintain. Instead of having to change a type everywhere it appears throughout the program's source files, only a single typedef statement needs to be changed. Second, a typedef can make a complex definition or declaration easier to understand.

Some people are opposed to the extensive use of typedefs. Most arguments center on the idea that typedefs simply hide the actual data type of a variable. For example, Greg Kroah-Hartman, a Linux kernel hacker and documenter, discourages their use for anything except function prototype declarations. He argues that this practice not only unnecessarily obfuscates code, it can also cause programmers to accidentally misuse large structures thinking them to be simple types. 

In C++ type names can be complex and typedef provides a mechanism to assign a simple name to the type.
std::vector<std::pair<std::string, int» values;

for (std::vector<std::pair<std::string, int»::const_iterator i = values.begin(); i != values.end(); ++i)
and
typedef std::pair<std::string, int> value_t;
typedef std::vector<value_t> values_t;

values_t values;

for (values_t::const_iterator i = values.begin(); i != values.end(); ++i)
C++03 does not provide templated typedefs. For instance, to have represent for every type one "cannot" use:
template<typename T>
typedef std::pair<std::string, T> stringpair<T>; // Doesn't work
However, if one is willing to accept in lieu of , then it is possible to achieve the desired result via a typedef within an otherwise unused templated class or struct:
template<typename T>
class stringpair
private:
public:

// Declare a variable of type `std::pair<std::string, int>`.
stringpair<int>::type my_pair_of_string_and_int;
In C++11, templated typedefs are added with the following syntax, which requires the keyword rather than the keyword. (See template aliases.)
template <typename T>
using stringpair = std::pair<std::string, T>;

// Declare a variable of type `std::pair<std::string, int>`.
stringpair<int> my_pair_of_string_and_int;
In SystemVerilog, typedef behaves exactly the way it does in C and C++.

In many statically typed functional languages, like Haskell, Miranda, OCaml, etc., one can define "type synonyms", which are the same as typedefs in C. An example in Haskell:
type PairOfInts = (Int, Int)
This example has defined a type synonym as an integer type.

In Seed7 the definition of a constant type is used to introduce a synonym for a type:
const type: myVector is array integer;
In Swift, one uses the keyword to create a typedef:
typealias PairOfInts = (Int, Int)
C# contains a feature which is similar to the typedef or the syntax of C++.
using newType = global::System.Runtime.Interop.Marshal;
using otherType = Enums.MyEnumType;
using StringListMap = System.Collections.Generic.Dictionary<string, System.Collections.Generic.List<string»;
In D the keyword allows to create type or partial type synonyms.
alias FooInt = Foo!int;
alias Fun = int delegate(int);


</doc>
<doc id="7789356" url="https://en.wikipedia.org/wiki?curid=7789356" title="Assignment operator (C++)">
Assignment operator (C++)

In the C++ programming language, the assignment operator, codice_1, is the operator used for assignment. Like most other operators in C++, it can be overloaded.

The copy assignment operator, often just called the "assignment operator", is a special case of assignment operator where the source (right-hand side) and destination (left-hand side) are of the same class type. It is one of the special member functions, which means that a default version of it is generated automatically by the compiler if the programmer does not declare one. The default version performs a memberwise copy, where each member is copied by its own copy assignment operator (which may also be programmer-declared or compiler-generated).

The copy assignment operator differs from the copy constructor in that it must clean up the data members of the assignment's target (and correctly handle self-assignment) whereas the copy constructor assigns values to uninitialized data members. For example:

The language permits an overloaded assignment operator to have an arbitrary return type (including codice_2). However, the operator is usually defined to return a reference to the assignee. This is consistent with the behavior of assignment operator for built-in types (returning the assigned value) and allows for using the operator invocation as an expression, for instance in control statements or in chained assignment. Also, the C++ Standard Library requires this behavior for some user-supplied types.

When deep copies of objects have to be made, exception safety should be taken into consideration. One way to achieve this when resource deallocation never fails is:


However, if a no-fail (no-throw) swap function is available for all the member subobjects and the class provides a copy constructor and destructor (which it should do according to the rule of three), the most straightforward way to implement copy assignment is as follows:

C++ supports assignment between different classes, both via implicit copy constructor and assignment operator, if the destination instance class is the ancestor of the source instance class:

Copying from ancestor to descendant objects, which could leave descendant's fields uninitialized, is not permitted.




</doc>
<doc id="1795006" url="https://en.wikipedia.org/wiki?curid=1795006" title="Inner class">
Inner class

In object-oriented programming (OOP), an inner class or nested class is a class declared entirely within the body of another class or interface. It is distinguished from a subclass.

An instance of a normal or top-level class can exist on its own. By contrast, an instance of an inner class cannot be instantiated without being bound to a top-level class.

Let us take the abstract notion of a codice_1 with four codice_2s. Our codice_2s have a specific feature that relies on being part of our codice_1. This notion does not represent the codice_2s as codice_2s in a more general form that could be part of any vehicle. Instead, it represents them as specific to a codice_1. We can model this notion using inner classes as follows:

We have the top-level class codice_1. Instances of class codice_1 are composed of four instances of the class codice_2. This particular implementation of codice_2 is specific to a car, so the code does not model the general notion of a wheel that would be better represented as a top-level class. Therefore, it is semantically connected to the class codice_1 and the code of codice_2 is in some way coupled to its outer class, being a composition unit of a car. The wheel for a particular car is unique to that car, but for generalization, the wheel is an aggregation unit to the car.

Inner classes provide a mechanism to accurately model this connection. We can refer to our codice_2 class as codice_15, codice_1 being the top-level class and codice_2 being the inner class.

Inner classes therefore allow for the object orientation of certain parts of the program that would otherwise not be encapsulated into a class.

Larger segments of code within a class might be better modeled or refactored as a separate top-level class, rather than an inner class. This would make the code more general in its application and therefore more re-usable but potentially might be premature generalization. This may prove more effective, if code has many inner classes with the shared functionality.

In Java there are four types of nested class:


Inner class The following categories are called "inner classes". Each instance of these classes has a reference to an "enclosing instance" (i.e. an instance of the enclosing class), except for local and anonymous classes declared in static context. Hence, they can implicitly refer to instance variables and methods of the enclosing class. The enclosing instance reference can be explicitly obtained via codice_19. Inner classes may not have static variables or methods, except for compile-time constant variables. When they are created, they must have a reference to an instance of the enclosing class; which means they must either be created within an instance method or constructor of the enclosing class, or (for member and anonymous classes) be created using the syntax codice_20.



Local inner classes are often used in Java to define callbacks for GUI code. Components can then share an object that implements an event handling interface or extends an abstract adapter class, containing the code to be executed when a given event is triggered.

Anonymous inner classes are also used where the event handling code is only used by one component and therefore does not need a named reference.

This avoids a large monolithic method with multiple if-else branches to identify the source of the event. This type of code is often considered messy and the inner class variations are considered to be better in all regards.



</doc>
<doc id="1924276" url="https://en.wikipedia.org/wiki?curid=1924276" title="Mentat (computing)">
Mentat (computing)

Mentat is a macro-dataflow extension of the C++ programming language. It was developed at the University of Virginia computer science Department by a research group led by Andrew Grimshaw. The combination of the ideas needed to implement the Mentat run-time with the ideas in Carnegie Mellon University's Hydra distributed operating system led to the Legion distributed OS.



</doc>
<doc id="8715728" url="https://en.wikipedia.org/wiki?curid=8715728" title="Rule of three (C++ programming)">
Rule of three (C++ programming)

The rule of three and rule of five are rules of thumb in C++ for the building of exception-safe code and for formalizing rules on resource management. It accomplishes this by prescribing how the default members of a class should be used to accomplish this task in a systematic manner.

The rule of three (also known as the Law of The Big Three or The Big Three) is a rule of thumb in C++ (prior to C++11) that claims that if a class defines one (or more) of the following it should probably explicitly define all three:


These three functions are special member functions. If one of these functions is used without first being declared by the programmer it will be implicitly implemented by the compiler with the following default semantics:


The Rule of Three claims that if one of these had to be defined by the programmer, it means that the compiler-generated version does not fit the needs of the class in one case and it will probably not fit in the other cases either. The term "Rule of three" was coined by Marshall Cline in 1991.

An amendment to this rule is that if the class is designed in such a way that Resource Acquisition Is Initialization (RAII) is used for all its (nontrivial) members, the destructor may be left undefined (also known as The Law of The Big Two). A ready-to-go example of this approach is the use of smart pointers instead of plain ones. 

Because implicitly-generated constructors and assignment operators simply copy all class data members ("shallow copy"), one should define explicit copy constructors and copy assignment operators for classes that encapsulate complex data structures or have external references such as pointers, if you need to copy the objects pointed to by the class members. If the default behavior ("shallow copy") is actually the intended one, then an explicit definition, although redundant, will be a "self-documenting code" indicating that it was an intention rather than an oversight.

With the advent of C++11 the rule of three can be broadened to "the rule of five" (also known as the rule of big 5

) as C++11 implements "move semantics", allowing destination objects to "grab" (or "steal") data from temporary objects. The following example also shows the new moving members: move constructor and move assignment operator. Consequently, for "the rule of five" we have the following "special members":

Situations exist where classes may need destructors, but cannot sensibly implement copy and move constructors and copy and move assignment operators. This happens, for example, when the base class does not support these latter "Big Four" members, but the derived class's constructor allocates memory for its own use. In C++11, this can be simplified by explicitly specifying the five members as default.



</doc>
<doc id="10321476" url="https://en.wikipedia.org/wiki?curid=10321476" title="Special member functions">
Special member functions

Special member functions in C++ are functions which the compiler will automatically generate if they are used, but not declared explicitly by the programmer.
The automatically generated special member functions are:

In these cases the compiler generated versions of these functions perform a "memberwise" operation. For example the compiler generated destructor will destroy each sub-object (base class or member) of the object.

The compiler generated functions will be codice_1, non-virtual and the copy constructor and assignment operators will receive codice_2 parameters (and not be of the alternative legal forms).

The following example depicts two classes: Explicit for which all special member functions are explicitly declared and Implicit for which none are declared.

Here are the signatures of the special member functions:

In C++03 before the introduction of move semantics the special member functions were:


</doc>
<doc id="6854573" url="https://en.wikipedia.org/wiki?curid=6854573" title="CFLAGS">
CFLAGS

CFLAGS and CXXFLAGS are either the name of environment variables or of Makefile variables that can be set to specify additional switches to be passed to a compiler in the process of building computer software.

These variables are usually set inside a Makefile and are then appended to the command line when the compiler is invoked. If they are not specified in the Makefile, then they will be read from the environment, if present. Tools like autoconf's ./configure script will usually pick them up from the environment and write them into the generated Makefiles. Some package install scripts, like SDL, allow CFLAGS settings to override their normal settings (instead of append to them), so setting CFLAGS can cause harm in this case.

CFLAGS enables the addition of switches for the C compiler, while CXXFLAGS is meant to be used when invoking a C++ compiler. Similarly, a variable CPPFLAGS exists with switches to be passed to the C or C++ preprocessor.

These variables are most commonly used to specify optimization or debugging switches to a compiler, as for example codice_1, codice_2 or (GCC-specific) codice_3.




</doc>
<doc id="14745134" url="https://en.wikipedia.org/wiki?curid=14745134" title="Prefix header">
Prefix header

In computer programming, a prefix header is a feature found in some C or C++ compilers used to ensure that a certain snippet of code is inserted at the beginning of every file.

In the C and C++ programming languages, a header file is a file whose text is included in another source file by the compiler, usually by the use of compiler directives at the beginning of the source file. A prefix header differs from a normal header file in that it is "automatically" included at the beginning of every source file by the compiler, without the use of any compiler directives.

Prefix headers are usually pre-compiled in order to reduce compilation times. Use of prefix headers outside of this purpose can make your code more difficult to maintain & less re-usable.
Prefix headers can also be used for cross-platform support. On *NIX systems, it is common to have a config.h header file generated at build time (via something like autoconf) that describes the capabilities of the system. However, when using certain build systems such as Visual Studio or Xcode, this config.h may be unavailable. One technique to solve this is to have HAVE_CONFIG_H be a pre-defined macro in the build-system that generates a config.h so that code knows whether it needs to #include config.h (& is safe for use by build systems that do not have it). An alternative, would be for the build system to add config.h as a prefix header instead of defining HAVE_CONFIG_H. Of course the downside is that this header will be added to every compilation unit, not just the ones that include it explicitly.

On Mac OS X, the Xcode build system generates prefix headers automatically for new projects. A new Cocoa project, for instance, gets a prefix header that looks like this:

As a result, explicit includes of the above header files in any Objective-C code file do not imply a second inclusion because of the codice_1 directive of Objective-C, or more generally with codice_2 because of the use of include guards; hence, these includes can be forgotten, but it is advocated to have them explicitly written in order to keep the source code autonomous and reusable, and make the library dependencies clear.

Similar prefix headers are generated for other types of project.




</doc>
<doc id="14558772" url="https://en.wikipedia.org/wiki?curid=14558772" title="Plain Old C++ Object">
Plain Old C++ Object

Like the term POJO ("Plain Old Java Object") in the Java world, the term Plain Old C++ object or its acronym POCO means a C++ artifact that is "neither defined by nor coupled to" the underlying C++ component framework that manipulates it.

Examples of such an artifact include, for instance, instances of C++ classes, K&R structs, unions, or even functions (as function pointers). This is contrast to component model in classic C++ component frameworks, such as OMG-CCM, JTRS-SCA core framework (CF), OpenSOA's SCA for C++. These classic component frameworks either dedicate a proprietary component programming model (a super class), or mandate component implementations to be tightly coupled to the underlying framework (calling its runtime).




</doc>
<doc id="17256074" url="https://en.wikipedia.org/wiki?curid=17256074" title="Dominance (C++)">
Dominance (C++)

In the C++ programming language, dominance refers to a particular aspect of C++ name lookup in the presence of Inheritance. When the compiler computes the set of declarations to which a particular name might refer, declarations in very-ancestral classes which are "dominated" by declarations in less-ancestral classes are "hidden" for the purposes of name lookup. In other languages or contexts, the same principle may be referred to as "name masking" or "shadowing".

The algorithm for computing name lookup is described in section 10.2 [class.member.lookup] of the C++11 Standard. The Standard's description does not use the word "dominance", preferring to describe things in terms of "declaration sets" and "hiding". However, the Index contains an entry for "dominance, virtual base class" referring to section 10.2.

In the above example, codice_1 contains a reference to the name codice_2. However, the program as a whole contains four declarations of the name codice_2. In order to figure out which codice_2 is meant, the compiler computes an "overload set" containing all the declarations which are not hidden at the point of the call. The declaration of codice_2 at global scope is hidden by codice_6, and in turn codice_6 is hidden by codice_8. Thus the only declaration which is considered by overload resolution is codice_8 — and the result in this case is a diagnostic, because the call-site provides two arguments where codice_8 expects only one.

It is often surprising to new C++ programmers that the declaration of codice_8 dominates and hides "all" of the more-ancestral declarations, regardless of signature; that is, codice_12 dominates and hides the declaration of codice_13 even though the two member functions have very different signatures.

It is also important to observe that in C++, "name lookup" precedes "overload resolution". If codice_8 had multiple overloads (for example codice_15 and codice_16), the compiler would choose between them at overload-resolution time; but during the name-lookup phase we are concerned only with choosing among the three scopes codice_6, codice_8, and codice_19. The fact that codice_13 would have been a better "overload" than codice_15 is not part of the compiler's consideration.

In the above example, the compiler computes an overload set for codice_2 which contains both codice_23 and codice_24. The compiler produces a diagnostic indicating that the program is ill-formed because the name codice_2 is "ambiguous".

In this final example, the name codice_2 once again unambiguously refers to codice_23, because codice_23 hides the codice_2 declared in its codice_30 subobject. The Standard calls out this surprising case in an informative note (§10.2 paragraph 10):

Even if codice_31 itself were to inherit virtually from codice_30, there would be no ambiguity in name lookup. However, if codice_31 were to inherit "non"-virtually from codice_30 (i.e., codice_35), then the name would again be ambiguated (between the codice_2s declared in the two codice_30 subobjects).



</doc>
<doc id="1669477" url="https://en.wikipedia.org/wiki?curid=1669477" title="One Definition Rule">
One Definition Rule

The One Definition Rule (ODR) is an important rule of the C++ programming language that prescribes that objects and non-inline functions cannot have more than one definition in the entire program and template and types cannot have more than one definition by translation unit. It is defined in the ISO C++ Standard (ISO/IEC 14882) 2003, at section 3.2.

In short, the ODR states that:


Some violations of the ODR must be diagnosed by the compiler. Other violations, particularly those that span translation units, are not required to be diagnosed.<ref name="C++03 3.2/3">ISO/IEC (2003). "ISO/IEC 14882:2003(E): Programming Languages - C++ §3.2 One definition rule [basic.def.odr]" para. 3</ref>

In general, a translation unit shall contain no more than one definition of any class type. In this example, two definitions of the class type C occur in the same translation unit. This typically occurs if a header file is included twice by the same source file without appropriate header guards.
In the following, forming a pointer to S or defining a function taking a reference to S are examples of legal constructs, because they do not require the type of S to be complete. Therefore, a definition is not required.<ref name="C++03 3.2/4">ISO/IEC (2003). "ISO/IEC 14882:2003(E): Programming Languages - C++ §3.2 One definition rule [basic.def.odr]" para. 4</ref> 

Defining an object of type S, a function taking an argument of type S, or using S in a sizeof expression are examples of contexts where S must be complete, and therefore require a definition.

In certain cases, there can be more than one definition of a type or a template. A program consisting of multiple header files and source files will typically have more than one definition of a type, but not more than one definition per translation unit.

If a program contains more than one definition of a type, then each definition must be equivalent.<ref name="C++03 3.2/5">ISO/IEC (2003). "ISO/IEC 14882:2003(E): Programming Languages - C++ §3.2 One definition rule [basic.def.odr]" para. 5</ref>

In pre-standard C++, all static data members required a definition outside of their class. However, during the C++ standardization process it was decided to lift this requirement for static const integral members. The intent was to allow uses such as:

without a namespace scope definition for codice_1.

Nevertheless, the wording of the 1998 C++ standard still required a definition if the member was used in the program.<ref name="C++03 9.4.2/4">ISO/IEC (1998). "ISO/IEC 14882:1998(E): Programming Languages - C++ §9.4.2 Static data members [class.static.data]" para. 4</ref> This included the member appearing anywhere except as the operand to sizeof or typeid, effectively making the above ill-formed.<ref name="C++03 3.2/2">ISO/IEC (1998). "ISO/IEC 14882:1998(E): Programming Languages - C++ §3.2 One definition rule [basic.def.odr]" para. 2</ref>

This was identified as a defect, and the wording was adjusted to allow such a member to appear anywhere a constant expression is required, without requiring an out-of-class definition. This includes array bounds, case expressions, static member initializers, and nontype template arguments.<ref name="C++03 5.19/1">ISO/IEC (2003). "ISO/IEC 14882:2003(E): Programming Languages - C++ §5.19 Constant expressions [expr.const]" para. 1</ref>

However, using a static const integral member anywhere except where an integral constant-expression is required, requires a definition:

This requirement was relaxed in a later standard, C++11.

We need 4 files: "odr.h", "main.cpp", "odr1.cpp", "odr2.cpp"

The acronym "odr" here is short for "One Definition Rule".

odr.h:
main.cpp
odr1.cpp
odr2.cpp
Under a Linux shell to try out, compile with:
Under a Windows Visual Studio "Build Tools Command Prompt", compile with:
When executed the expected output is:
But you very likely get:
The problem is, that the C++ linker has to figure out how to build the virtual method table for the (two different) "CDummy" classes, and that only works if the class names are different.



</doc>
<doc id="6206094" url="https://en.wikipedia.org/wiki?curid=6206094" title="Seekg">
Seekg

In the C++ programming language, seekg is a function in the codice_1 library (part of the standard library) that allows you to seek to an arbitrary position in a file. This function is defined for istream class - for ostream class there's a similar function seekp (this is to avoid conflicts in case of classes that derive both istream and ostream, such as iostream).

codice_4 is the seeking direction. It is an object of type codice_6 that can take any of the following constant values: 

Note: If you have previously got an end of file on the stream, codice_10 will not reset it but will return an error in many implementations.
- use the codice_11 method to clear the end of file bit first. This is a relatively common mistake and if codice_12 is not performing as expected, it is wise to clear the fail bit, as shown below.


</doc>
<doc id="8646451" url="https://en.wikipedia.org/wiki?curid=8646451" title="Single Compilation Unit">
Single Compilation Unit

Single Compilation Unit (SCU) is a computer programming technique for the C and C++ languages, which reduces compilation time for programs spanning multiple files. Specifically, it allows the compiler to keep data from shared header files, definitions and templates, so that it need not recreate them for each file. It is an instance of program optimization. The technique can be applied to an entire program or to some subset of source files; when applied to an entire program, it is also known as a unity build.

In the C/C++ compilation model (formally "translation environment"), individual .c/.cpp source files are preprocessed into translation units, which are then translated (compiled) separately by the compiler into multiple object (.o or .obj) files. These object files can then be linked together to create a single executable file or library. However, this leads to multiple passes being performed on common header files, and with C++, multiple template instantiations of the same templates in different translation units.

The "Single Compilation Unit" technique uses pre-processor directives to "glue" different translation units together at compile time rather than at link time. This reduces the overall build time, due to eliminating the duplication, but increases the incremental build time (the time required after making a change to any single source file that is included in the Single Compilation Unit), due to requiring a full rebuild of the entire unit if any single input file changes. Therefore, this technique is appropriate for a set of infrequently modified source files with significant overlap (many or expensive common headers or templates), or source files that frequently require recompilation together, such as due to all including a common header or template that changes frequently.

Another disadvantage of SCU is that it is serial, compiling all included source files in sequence in one process, and thus cannot be parallelized, as can be done in separate compilation (via distcc or similar programs). Thus SCU requires explicit partitioning (manual partitioning or "sharding" into multiple units) to parallelize compilation.

SCU also allows an optimizing compiler to perform interprocedural optimization without requiring link-time optimization, therefore allowing optimizations such as inlining, and helps avoiding implicit code bloat due to exceptions, side effects, and register allocation. These optimizations are often not possible in many compilers, due to independent compilation, where optimization happens separately in each translation unit during "compilation," but the "dumb linker" simply links object files, without performing any optimizations itself, and thus interprocedural optimization between translation units is not possible.

For example, if you have the source files foo.cpp and bar.cpp, they can be placed in a Single Compilation Unit as follows:
Suppose foo.cpp and bar.cpp are:
//foo.cpp

int main() // Definition of function 'main'

//bar.cpp

void bar() // Definition of function 'bar'

Now the standard header file (iostream) is compiled only once, and function bar may be inlined into function main, despite being from another module.



</doc>
<doc id="20950072" url="https://en.wikipedia.org/wiki?curid=20950072" title="Auto-linking">
Auto-linking

Auto-linking is a mechanism for automatically determining which libraries to link to while building a C, C++ or Obj-C program. It is activated by means of <nowiki>#pragma comment(lib, <name>)</nowiki> statements in the header files of the library, or <nowiki>@import <name></nowiki> depending on the compiler.

Most Windows compilers support auto-linking, as does Clang, while GCC does not support auto-linking 



</doc>
<doc id="4819306" url="https://en.wikipedia.org/wiki?curid=4819306" title="Curiously recurring template pattern">
Curiously recurring template pattern

The curiously recurring template pattern (CRTP) is an idiom in C++ in which a class codice_1 derives from a class template instantiation using codice_1 itself as template argument. More generally it is known as F-bound polymorphism, and it is a form of "F"-bounded quantification.

The technique was formalized in 1989 as ""F"-bounded quantification." The name "CRTP" was independently coined by Jim Coplien in 1995, who had observed it in some of the earliest C++ template code
as well as in code examples that Timothy Budd created in his multiparadigm language Leda. It is sometimes called "Upside-Down Inheritance" due to the way it allows class hierarchies to be extended by substituting different base classes.

The Microsoft Implementation of CRTP in Active Template Library (ATL) was independently discovered, also in 1995 by Jan Falkin who accidentally derived a base class from a derived class. Christian Beaumont first saw Jan's code and initially thought it couldn't possibly compile in the Microsoft compiler available at the time. Following this revelation that it did indeed work, Christian based the entire ATL and Windows Template Library (WTL) design on this mistake.

Some use cases for this pattern are static polymorphism and other metaprogramming techniques such as those described by Andrei Alexandrescu in "Modern C++ Design".
It also figures prominently in the C++ implementation of the Data, Context, and Interaction paradigm.

Typically, the base class template will take advantage of the fact that member function bodies (definitions) are not instantiated until long after their declarations, and will use members of the derived class within its own member functions, via the use of a cast; e.g.:

In the above example, note in particular that the function Base<Derived>::interface(), though "declared" before the existence of the struct Derived is known by the compiler (i.e., before Derived is declared), is not actually "instantiated" by the compiler until it is actually "called" by some later code which occurs "after" the declaration of Derived (not shown in the above example), so that at the time the function "implementation" is instantiated, the declaration of Derived::implementation() is known.

This technique achieves a similar effect to the use of virtual functions, without the costs (and some flexibility) of dynamic polymorphism. This particular use of the CRTP has been called "simulated dynamic binding" by some. This pattern is used extensively in the Windows ATL and WTL libraries.

To elaborate on the above example, consider a base class with no virtual functions. Whenever the base class calls another member function, it will always call its own base class functions. When we derive a class from this base class, we inherit all the member variables and member functions that weren't overridden (no constructors or destructors). If the derived class calls an inherited function which then calls another member function, that function will never call any derived or overridden member functions in the derived class.

However, if base class member functions use CRTP for all member function calls, the overridden functions in the derived class will be selected at compile time. This effectively emulates the virtual function call system at compile time without the costs in size or function call overhead (VTBL structures, and method lookups, multiple-inheritance VTBL machinery) at the disadvantage of not being able to make this choice at runtime.

The main purpose of an object counter is retrieving statistics of object creation and destruction for a given class. This can be easily solved using CRTP:

Each time an object of class codice_1 is created, the constructor of codice_4 is called, incrementing both the created and alive count. Each time an object of class codice_1 is destroyed, the alive count is decremented. It is important to note that codice_4 and codice_7 are two separate classes and this is why they will keep separate counts of codice_1's and codice_9's. In this example of CRTP, this distinction of classes is the only use of the template parameter (codice_10 in codice_11) and the reason why we cannot use a simple un-templated base class.

Method chaining, also known as named parameter idiom, is a common syntax for invoking multiple method calls in object-oriented programming languages. Each method returns an object, allowing the calls to be chained together in a single statement without requiring variables to store the intermediate results.

When the named parameter object pattern is applied to an object hierarchy, things can go wrong. Suppose we have such a base class:

Prints can be easily chained:

However, if we define the following derived class:

we "lose" the concrete class as soon as we invoke a function of the base:

This happens because 'print' is a function of the base - 'Printer' - and then it returns a 'Printer' instance.

The CRTP can be used to avoid such problem and to implement "Polymorphic chaining":

When using polymorphism, one sometimes needs to create copies of objects by the base class pointer. A commonly used idiom for this is adding a virtual clone function that is defined in every derived class. The CRTP can be used to avoid having to duplicate that function or other similar functions in every derived class.

This allows obtaining copies of squares, circles or any other shapes by codice_12.

One issue with static polymorphism is that without using a general base class like "Shape" from the above example, derived classes cannot be stored homogeneously as each CRTP base class is a unique type. For this reason, it is more common to inherit from a shared base class with a virtual destructor, like the example above.



</doc>
<doc id="2570200" url="https://en.wikipedia.org/wiki?curid=2570200" title="Opaque pointer">
Opaque pointer

In computer programming, an opaque pointer is a special case of an opaque data type, a data type declared to be a pointer to a record or data structure of some unspecified type.

Opaque pointers are present in several programming languages including Ada, C, C++, D and Modula-2.

If the language is strongly typed, programs and procedures that have no other information about an opaque pointer type "T" can still declare variables, arrays, and record fields of type "T", assign values of that type, and compare those values for equality. However, they will not be able to de-reference such a pointer, and can only change the object's content by calling some procedure that has the missing information.

Opaque pointers are a way to hide the implementation details of an interface from ordinary clients, so that the implementation may be changed without the need to recompile the modules using it. This benefits the programmer as well since a simple interface can be created, and most details can be hidden in another file. This is important for providing binary code compatibility through different versions of a shared library, for example.

This technique is described in "Design Patterns" as the Bridge pattern. It is sometimes referred to as "handle classes", the "Pimpl idiom" (for "pointer to implementation idiom"), "Compiler firewall idiom", "d-pointer" or "Cheshire Cat", especially among the C++ community.

The type codice_1 is an opaque pointer to the real implementation, that is not defined in the specification. Note that the type is not only private (to forbid the clients from accessing the type directly, and only through the operations), but also limited (to avoid the copy of the data structure, and thus preventing dangling references).

These types are sometimes called "Taft types"—named after Tucker Taft, the main designer of Ada 95—because they were introduced in the so-called Taft Amendment to Ada 83.

This example demonstrates a way to achieve the information hiding (encapsulation) aspect of object-oriented programming using the C language. If someone wanted to change the declaration of codice_2, it would be unnecessary to recompile any other modules in the program that use the codice_3 header file unless the API was also changed. Note that it may be desirable for the functions to check that the passed pointer is not codice_4, but such checks have been omitted above for brevity.

The d-pointer pattern is one of the implementations of the . It is commonly used in C++ classes due to its advantages (noted below). A d-pointer is a private data member of the class that points to an instance of a structure. This method allows class declarations to omit private data members, except for the d-pointer itself. As a result,
One side benefit is that compilations are faster because the header file changes less often. Note, possible disadvantage of d-pointer pattern is indirect member access through pointer (in example, pointer to object in dynamic storage), which is sometimes slower than access to plain, not-a-pointer member. The d-pointer is heavily used in the Qt and KDE libraries.




</doc>
<doc id="21015558" url="https://en.wikipedia.org/wiki?curid=21015558" title="Expression templates">
Expression templates

Expression templates are a C++ template metaprogramming technique that builds structures representing a computation at compile time, where expressions are evaluated only as needed to produce efficient code for the entire computation. Expression templates thus allow programmers to bypass the normal order of evaluation of the C++ language and achieve optimizations such as loop fusion.

Expression templates were invented independently by Todd Veldhuizen and David Vandevoorde; it was Veldhuizen who gave them their name. They are a popular technique for the implementation of linear algebra software.

Consider a library representing vectors and operations on them. One common mathematical operation is to add two vectors and , element-wise, to produce a new vector. The obvious C++ implementation of this operation would be an overloaded that returns a new vector object:

Users of this class can now write where and are both instances of .

A problem with this approach is that more complicated expressions such as are implemented inefficiently. The implementation first produces a temporary vector to hold , then produces another vector with the elements of added in. Even with return value optimization this will allocate memory at least twice and require two loops.

Delayed evaluation solves this problem, and can be implemented in C++ by letting return an object of a custom type, say , that represents the unevaluated sum of two vectors, or a vector with a , etc. Larger expressions then effectively build expression trees that are evaluated only when assigned to an actual variable. But this requires traversing such trees to do the evaluation, which is in itself costly.

Expression templates implement delayed evaluation using expression trees that only exist at compile time. Each assignment to a , such as , generates a new constructor if needed by template instantiation. This constructor operates on three ; it allocates the necessary memory and then performs the computation. Thus only one memory allocation is performed.

An example implementation of expression templates looks like the following. A base class represents any vector-valued expression. It is templated on the actual expression type to be implemented, per the curiously recurring template pattern.

The class still stores the coordinates of a fully evaluated vector expression, and becomes a subclass of .

The sum of two vectors is represented by a new type, , that is templated on the types of the left- and right-hand sides of the sum so that it can be applied to arbitrary pairs of vector expressions. An overloaded serves as syntactic sugar for the constructor.

With the above definitions, the expression is of type

so invokes the templated constructor with this type as its template argument. Inside this constructor, the loop body

is effectively expanded (following the recursive definitions of and on this type) to

with no temporary vectors needed and only one pass through each memory block.

Basic Usage :
Expression templates have been found especially useful by the authors of libraries for linear algebra, i.e., for dealing with vectors and matrices of numbers. Among libraries employing expression template are Armadillo, Blaze, Blitz++, Boost uBLAS, Eigen, POOMA, Stan Math Library, and xtensor. Expression templates can also accelerate C++ automatic differentiation implementations, as demonstrated in the Adept library.

Outside of vector math, the Spirit parser framework uses expression templates to represent formal grammars and compile these into parsers.


</doc>
<doc id="4487955" url="https://en.wikipedia.org/wiki?curid=4487955" title="Sizeof">
Sizeof

In the programming languages C and C++, the unary operator sizeof generates the size of an expression or a data type, measured in the number of "char"-sized storage units required for the type. Consequently, the construct "sizeof (char)" is guaranteed to be 1. The actual number of bits of type char is specified by the preprocessor macro , defined in the standard include file limits.h. On most modern systems this is eight bits. The result of "sizeof" has an unsigned integral type that is usually denoted by size_t.

The operator has a single operand, which is either an expression or a data type cast. A cast is a data type enclosed in parenthesis. Data types may not only be primitive types, such as integer and floating-point types, but also pointer types, and compound datatypes (unions, structs, and C++ classes).

Many programs must know the storage size of a particular datatype. Though for any given implementation of C or C++ the size of a particular datatype is constant, the sizes of even primitive types in C and C++ may be defined differently for different platforms of implementation. For example, runtime allocation of array space may use the following code, in which the sizeof operator is applied to the cast of the type "int":
int *pointer = malloc(10 * sizeof (int));
In this example, function "malloc" allocates memory and returns a pointer to the memory block. The size of the block allocated is equal to the number of bytes for a single object of type "int" multiplied by 10, providing space for ten integers.

It is generally not safe to assume the size of any datatype. For example, even though most implementations of C and C++ on 32-bit systems define type "int" to be four octets, this size may change when code is ported to a different system, breaking the code. The exception to this is the data type "char", which always has the size "1" in any standards-compliant C implementation. In addition, it is frequently difficult to predict the sizes of compound datatypes such as a "struct" or "union", due to padding. The use of "sizeof" enhances readability, since it avoids unnamed numeric constants (magic numbers).

An equivalent syntax for allocating the same array space results from using the dereferenced form of the pointer to the storage address, this time applied the operator to a pointer variable:

int *pointer = malloc(10 * sizeof *pointer);
The "sizeof" operator computes the required memory storage space of its operand. The operand is written following the keyword "sizeof" and may be the symbol of a storage space, e.g., a variable, type name, or an expression. If it is a type name, it must be enclosed in parentheses. The result of the operation is the size of the operand in bytes, or the size of the memory representation. For expressions it evaluates to the representation size for the type that would result from evaluation of the expression, which is not performed. 

For example, since "sizeof (char)" is defined to be 1 and assuming the integer type is four bytes long, the following code prints :
/* the following code fragment illustrates the use of sizeof
char c;
printf("%zu,%zu\n", sizeof c, sizeof (int));
Certain standard header files, such as "stddef.h", define "size_t" to denote the unsigned integral type of the result of a "sizeof" expression. The "printf" width specifier "z" is intended to format that type.

"sizeof" cannot be used in C preprocessor expressions, such as , because the preprocessor has no data types.

When "sizeof" is applied to the name of an array, the result is the number of bytes required to store the entire array. This is one of the few exceptions to the rule that the name of an array is converted to a pointer to the first element of the array, and is possible just because the actual array size is fixed and known at compile time, when the "sizeof" operator is evaluated. The following program uses "sizeof" to determine the size of a declared array, avoiding a buffer overflow when copying characters:

int main(int argc, char **argv)

Here, is equivalent to , which evaluates to 10, because the size of the type "char" is defined as 1.

C99 adds support for flexible array members to structures. This form of array declaration is allowed as the last element in structures only, and differs from normal arrays in that no length is specified to the compiler. For a structure named "s" containing a flexible array member named "a", is therefore equivalent to :

struct flexarray {

int main(int argc, char **argv)

In this case the "sizeof" operator returns the size of the structure, including any padding, but without any storage allowed for the array. Most platforms produce the following output:

C99 also allows variable length arrays that have the length specified at runtime, although the feature is considered an optional implementation in later versions of the C standard. In such cases, the "sizeof" operator is evaluated in part at runtime to determine the storage occupied by the array.

size_t flexsize(int n)

int main(void)

"sizeof" can be used to determine the number of elements in an array, by dividing the size of the entire array by the size of a single element:

int main(void)

"sizeof" can only be applied to "completely" defined types. With arrays, this means that the dimensions of the array must be present in its declaration, and that the type of the elements must be completely defined. For "struct"s and "union"s, this means that there must be a member list of completely defined types. For example, consider the following two source files:
/* file1.c */
int arr[10];
struct x {int one; int two;};
/* more code */

/* file2.c */
extern int arr[];
struct x;
/* more code */
Both files are perfectly legal C, and code in can apply "sizeof" to "arr" and . However, it is illegal for code in to do this, because the definitions in are not complete. In the case of "arr", the code does not specify the dimension of the array; without this information, the compiler has no way of knowing how many elements are in the array, and cannot calculate the array's overall size. Likewise, the compiler cannot calculate the size of because it does not know what members it is made up of, and therefore cannot calculate the sum of the sizes of the structure's members (and padding). If the programmer provided the size of the array in its declaration in , or completed the definition of by supplying a member list, this would allow the application of "sizeof" to "arr" or in that source file.

C++11 introduced the possibility to apply the "sizeof" parameter to specific members of a class without the necessity to instantiate the object to achieve this. The following example for instance yields and on most platforms.

struct foo {

int main()

C++11 introduced variadic templates; the keyword "sizeof" followed by ellipsis returns the number of elements in a parameter pack.
template <typename... Args>
void print_size(Args... args)

int main()

When applied to a fixed-length datatype or variable, expressions with the operator "sizeof" are evaluated during program compilation; they are replaced by constant result-values. The C99 standard introduced variable-length arrays (VLAs), which required evaluation for such expressions during program execution. In many cases, the implementation specifics may be documented in an application binary interface (ABI) document for the platform, specifying formats, padding, and alignment for the data types, to which the compiler must conform.

When calculating the size of any object type, the compiler must take into account any required data structure alignment to meet efficiency or architectural constraints. Many computer architectures do not support multiple-byte access starting at any byte address that is not a multiple of the word size, and even when the architecture allows it, usually the processor can fetch a word-aligned object faster than it can fetch an object that straddles multiple words in memory. Therefore, compilers usually align data structures to at least a word boundary, and also align individual members to their respective boundaries. In the following example, the structure "student" is likely to be aligned on a word boundary, which is also where the member "grade" begins, and the member "age" is likely to start at the next word address. The compiler accomplishes the latter by inserting padding bytes between members as needed to satisfy the alignment requirements. There may also be padding at the end of a structure to ensure proper alignment in case the structure is used as an element of an array.

Thus, the aggregate size of a structure in C can be greater than the sum of the sizes of its individual members. For example, on many systems the following code prints :
struct student {

printf("%zu", sizeof (struct student));


</doc>
<doc id="18859896" url="https://en.wikipedia.org/wiki?curid=18859896" title="Header-only">
Header-only

In the context of the C or C++ programming languages, a library is called header-only if the full definitions of all macros, functions and classes comprising the library are visible to the compiler in a header file form. Header-only libraries do not need to be separately compiled, packaged and installed in order to be used. All that is required is to point the compiler at the location of the headers (the -I switch in gcc/g++), and then #include the header files into the application source. Another advantage is that the compiler's optimizer can do a much better job when all the library's source code is available.

The disadvantages include:

Nonetheless, the header-only form is popular because it avoids the (often much more serious) problem of packaging.

For templates, including the definitions in header is the only way to compile, since the compiler needs to know the full definition of the templates in order to instantiate.



</doc>
<doc id="2864060" url="https://en.wikipedia.org/wiki?curid=2864060" title="Passive data structure">
Passive data structure

In computer science and object-oriented programming, a passive data structure (PDS, also termed a plain old data structure, or plain old data, POD), is a term for a record, to contrast with objects. It is a data structure that is represented only as passive collections of field values (instance variables), without using object-oriented features.

Passive data structures are appropriate when there is a part of a system where it should be clearly indicated that the detailed logic for data manipulation and integrity are elsewhere. PDSs are often found at the boundaries of a system, where information is being moved to and from other systems or persistent storage and the problem domain logic that is found in other parts of the system is irrelevant. For example, PDS would be convenient for representing the field values of objects that are being constructed from external data, in a part of the system where the semantic checks and interpretations needed for valid objects are not applied yet.

A PDS type in C++, or Plain Old C++ Object, is defined as either a scalar type or a PDS class. A PDS class has no user-defined copy assignment operator, no user-defined destructor, and no non-static data members that are not themselves PDS. Moreover, a PDS class must be an aggregate, meaning it has no user-declared constructors, no private nor protected non-static data, no virtual base classes and no virtual functions. The standard includes statements about how PDS must behave in C++. The type_traits library in the C++ Standard Library provides a template named is_pod that can be used to determine whether a given type is a POD.

In some contexts, C++ allows only PDS types to be used. For example, a union in C++98 cannot contain a class that has virtual functions or nontrivial constructors or destructors. This restriction is imposed because the compiler cannot determine which constructor or destructor should be called for a union. PDS types can also be used for interfacing with C, which supports only PDS.

In Java, some developers consider that the PDS concept corresponds to a class with public data members and no methods (Java Code Conventions 10.1), i.e., a data transfer object. Others would also include Plain old Java objects (POJOs), a class that has methods but only getters and setters, with no logic, and JavaBeans to fall under the PDS concept if they do not use event handling and do not implement added methods beyond getters and setters. However, POJOs and Java Beans have encapsulation, and so violate the fundamental definition of PDS.

In PHP, associative arrays and stdClass objects can be considered PDS.

Other structured data representations such as XML or JSON can also be used as a PDS if no significant semantic restrictions are used.



</doc>
<doc id="1063614" url="https://en.wikipedia.org/wiki?curid=1063614" title="Wide character">
Wide character

A wide character is a computer character datatype that generally has a size greater than the traditional 8-bit character. The increased datatype size allows for the use of larger coded character sets.

During the 1960s, mainframe and mini-computer manufacturers began to standardize around the 8-bit byte as their smallest datatype. The 7-bit ASCII character set became the industry standard method for encoding alphanumeric characters for teletype machines and computer terminals. The extra bit was used for parity, to ensure the integrity of data storage and transmission. As a result, the 8-bit byte became the de facto datatype for computer systems storing ASCII characters in memory.

Later, computer manufacturers began to make use of the spare bit to extend the ASCII character set beyond its limited set of English alphabet characters. 8-bit extensions such as IBM code page 37, PETSCII and ISO 8859 became commonplace, offering terminal support for Greek, Cyrillic, and many others. However, such extensions were still limited in that they were region specific and often could not be used in tandem. Special conversion routines had to be used to convert from one character set to another, often resulting in destructive translation when no equivalent character existed in the target set.

In 1989, the International Organization for Standardization began work on the Universal Character Set (UCS), a multilingual character set that could be encoded using either a 16-bit (2-byte) or 32-bit (4-byte) value. These larger values required the use of a datatype larger than 8-bits to store the new character values in memory. Thus the term wide character was used to differentiate them from traditional 8-bit character datatypes.

A wide character refers to the size of the datatype in memory. It does not state how each value in a character set is defined. Those values are instead defined using character sets, with UCS and Unicode simply being two common character sets that contain more characters than an 8-bit value would allow.

Just as earlier data transmission systems suffered from the lack of an 8-bit clean data path, modern transmission systems often lack support for 16-bit or 32-bit data paths for character data. This has led to character encoding systems such as UTF-8 that can use multiple bytes to encode a value that is too large for a single 8-bit symbol.

The C standard distinguishes between "multibyte" encodings of characters, which use a fixed or variable number of bytes to represent each character (primarily used in source code and external files), from "wide characters", which are run-time representations of characters in single objects (typically, greater than 8 bits).

UTF-16 little-endian is the encoding standard at Microsoft (and in the Windows operating system). Yet with surrogate pairs it supports 32-bit as well . The .NET Framework platform supports multiple wide-character implementations including UTF7, UTF8, UTF16 and UTF32.

The Java platform requires that wide character variables be defined as 16-bit values, and that characters be encoded using UTF-16 (due to former use of UCS-2), while modern Unix-like systems generally require UTF-8 in their interfaces.

The C and C++ standard libraries include a number of facilities for dealing with wide characters and strings composed of them. The wide characters are defined using datatype codice_1, which in the original C90 standard was defined as

Both C and C++ introduced fixed-size character types codice_2 and codice_3 in the 2011 revisions of their respective standards to provide unambiguous representation of 16-bit and 32-bit Unicode transformation formats, leaving codice_1 implementation-defined. The ISO/IEC 10646:2003 Unicode standard 4.0 says that:

According to Python's documentation, the language sometimes uses codice_1 as the basis for its character type codice_9. It depends on whether codice_1 is "compatible with the chosen Python Unicode build variant" on that system.



</doc>
<doc id="930164" url="https://en.wikipedia.org/wiki?curid=930164" title="Partial template specialization">
Partial template specialization

Partial template specialization is a particular form of class template specialization. Usually used in reference to the C++ programming language, it allows the programmer to specialize only some arguments of a class template, as opposed to explicit full specialization, where all the template arguments are provided.

Class templates are really meta-classes: they are partial abstract data types that provide instructions to the compiler on how to create classes with the proper data members. For example, the C++ standard containers are class templates. When a programmer uses a vector, one instantiates it with a specific data type, for example, int, string or double. Each type of vector results in a different class in the compiler's object code, each one working with a different data type.

If one knows that a class template will be used with a specific data type fairly often and this data type allows some optimizations (e.g. bit shifting with integers, as opposed to multiplying or dividing by 2), one may introduce a specialized class template with some of the template parameters preset. When the compiler sees such a class template instantiated in code, it will generally choose the most specialized template definition that matches the instantiation. Therefore, an explicit full specialization (one where all the template arguments are specified) will be preferred to a partial specialization if all the template arguments match.

Templates can have more than one parameter type. Some older compilers allow one only to specialize either all or none of the template's parameters. Compilers that support partial specialization allow the programmer to specialize some parameters while leaving the others generic.

Suppose there exists a codice_1 class with two template parameters, as follows.
The following is an example of a class that defines an explicit full template specialization of codice_1 by pairing integers with strings. The class type retains the same name as the original version.
The next is an example of partial specialization of codice_1 with the same name as the original version and one specialized template parameter.
The next example class codice_4 is derived from the original codice_1 with a new name, and defines a partial template specialization. In contrast to the explicit specialization above, only the "Value" template parameter of the superclass is specialized, while the "Key" template parameter remains generic.
It does not matter which template parameters are specialized and which remain generic. For instance, the following is also a valid example of a partial specialization of the original codice_1 class.
C++ templates are not limited to classes - they can also be used to define function templates. Although function templates can be fully specialized, they "cannot" be partially specialized, irrespective of whether they are member function templates or non-member function templates. This can be beneficial to compiler writers, but affects the flexibility and granularity of what developers can do. But, function templates can be overloaded, which gives nearly the same effect as what partial function template specialization would have. The following examples are provided to illustrate these points.
In the example listed above, note that while the last two definitions of the function codice_7 are legal C++, they are considered ill-formed according to the standard because they are non-overloadable declarations. This is because the definition of function overloading only accounts for the function name, parameter type list and the enclosing namespace (if any). It does not account for the return type. However, these functions can still be called by explicitly indicating the signature to the compiler, as demonstrated by the following program.


</doc>
<doc id="598913" url="https://en.wikipedia.org/wiki?curid=598913" title="Run-time type information">
Run-time type information

In computer programming, run-time type information or run-time type identification (RTTI) is a feature of the C++ programming language that exposes information about an object's data type at runtime. Run-time type information can apply to simple data types, such as integers and characters, or to generic types. This is a C++ specialization of a more general concept called type introspection. Similar mechanisms are also known in other programming languages, such as Object Pascal (Delphi).

In the original C++ design, Bjarne Stroustrup did not include run-time type information, because he thought this mechanism was often misused.

In C++, RTTI can be used to do safe typecasts, using the codice_1 operator, and to manipulate type information at runtime, using the codice_2 operator and codice_3 class.

RTTI is available only for classes that are polymorphic, which means they have at least one virtual method. In practice, this is not a limitation because base classes must have a virtual destructor to allow objects of derived classes to perform proper cleanup if they are deleted from a base pointer.

RTTI is optional with some compilers; the programmer can choose at compile time whether to include the functionality. There may be a resource cost to making RTTI available even if a program does not use it.

The codice_2 keyword is used to determine the class of an object at run time. It returns a reference to codice_3 object, which exists until the end of the program. The use of codice_2, in a non-polymorphic context, is often preferred over codice_7 in situations where just the class information is needed, because codice_2 is always a constant-time procedure, whereas codice_9 may need to traverse the class derivation lattice of its argument at runtime. Some aspects of the returned object are implementation-defined, such as codice_10, and cannot be relied on across compilers to be consistent.

Objects of class codice_11 are thrown when the expression for codice_2 is the result of applying the unary * operator on a null pointer. Whether an exception is thrown for other null reference arguments is implementation-dependent. In other words, for the exception to be guaranteed, the expression must take the form codice_13 where codice_14 is any expression resulting in a null pointer.

Output (exact output varies by system and compiler):

The codice_9 operator in C++ is used for downcasting a reference or pointer to a more specific type in the class hierarchy. Unlike the codice_16, the target of the codice_9 must be a pointer or reference to class. Unlike codice_16 and C-style typecast (where type check is made during compilation), a type safety check is performed at runtime. If the types are not compatible, an exception will be thrown (when dealing with references) or a null pointer will be returned (when dealing with pointers).

A Java typecast behaves similarly; if the object being cast is not actually an instance of the target type, and cannot be converted to one by a language-defined method, an instance of codice_19 will be thrown.

Suppose some function takes an object of type codice_20 as its argument, and wishes to perform some additional operation if the object passed is an instance of codice_21, a subclass of codice_20. This can be accomplished using codice_9 as follows.

Console output:

A similar version of codice_24 can be written with pointers instead of references:




</doc>
<doc id="1442891" url="https://en.wikipedia.org/wiki?curid=1442891" title="BCX">
BCX

BCX is a BASIC to C computer language translator created by Kevin Diggins in 1999. 

BCX's new official website https://BcxBasicCoders.com went live in October 2019. 

BCX converts BASIC source code to C source code which can be compiled using a number of available C/C++ compilers on MS Windows.

For many years, most implementations of BASIC shared a nagging drawback - BASIC programs performed slower than similar programs that were created using C/C++. BCX helped change that by giving BASIC programmers the joy of programming in a modern BASIC language while coupling its output with the high performance of a C/C++ compiler.

BCX is written in the BCX BASIC language, making BCX a self-translating translator. BCX was made an open source project in 2004. Since then, several members of the BCX community have led the development and maintenance of the BCX project. Past project forks have resulted in variants of BCX that produces native-code applications for Linux, Apple, and Atari operating systems.

BCX contains statements and functions that simplify the creation of Windows UI desktop applications. Unlike many BASIC implementations that rely on run-time engines, the combination of BCX and most C/C++ compilers produce efficient, high performing native code applications. BCX easily creates GUI, DLL, console mode, and web server applications.





</doc>
<doc id="24220775" url="https://en.wikipedia.org/wiki?curid=24220775" title="Decltype">
Decltype

In the C++ programming language, codice_1 is a keyword used to query the type of an expression. Introduced in C++11, its primary intended use is in generic programming, where it is often difficult, or even impossible, to express types that depend on template parameters.

As generic programming techniques became increasingly popular throughout the 1990s, the need for a type-deduction mechanism was recognized. Many compiler vendors implemented their own versions of the operator, typically called codice_2, and some portable implementations with limited functionality, based on existing language features were developed. In 2002, Bjarne Stroustrup proposed that a standardized version of the operator be added to the C++ language, and suggested the name "decltype", to reflect that the operator would yield the "declared type" of an expression.

codice_1's semantics were designed to cater to both generic library writers and novice programmers. In general, the deduced type matches the type of the object or function exactly as declared in the source code. Like the codice_4 operator, codice_1's operand is not evaluated.

With the introduction of templates into the C++ programming language, and the advent of generic programming techniques pioneered by the Standard Template Library, the need for a mechanism for obtaining the type of an expression, commonly referred to as codice_2, was recognized. In generic programming, it is often difficult or impossible to express types that depend on template parameters, in particular the return type of function template instantiations.

Many vendors provide the codice_2 operator as a compiler extension. As early as 1997, before C++ was fully standardized, Brian Parker proposed a portable solution based on the codice_4 operator. His work was expanded on by Bill Gibbons, who concluded that the technique had several limitations and was generally less powerful than an actual codice_2 mechanism. In an October 2000 article of "Dr. Dobb's Journal", Andrei Alexandrescu remarked that "having a typeof would make much template code easier to write and understand." He also noted that "typeof and sizeof share the same backend, because sizeof has to compute the type anyway." Andrew Koenig and Barbara E. Moo also recognized the usefulness of a built-in codice_2 facility, with the caveat that "using it often invites subtle programming errors, and there are some problems that it cannot solve." They characterized the use of type conventions, like the typedefs provided by the Standard Template Library, as a more powerful and general technique. However, Steve Dewhurst argued that such conventions are "costly to design and promulgate", and that it would be "much easier to ... simply extract the type of the expression." In a 2011 article on C++0x, Koenig and Moo predicted that "decltype will be widely used to make everyday programs easier to write."

In 2002, Bjarne Stroustrup suggested extending the C++ language with mechanisms for querying the type of an expression, and initializing objects without specifying the type. Stroustrup observed that the reference-dropping semantics offered by the codice_2 operator provided by the GCC and EDG compilers could be problematic. Conversely, an operator returning a reference type based on the lvalue-ness of the expression was deemed too confusing. The initial proposal to the C++ standards committee outlined a combination of the two variants; the operator would return a reference type only if the declared type of the expression included a reference. To emphasize that the deduced type would reflect the "declared type" of the expression, the operator was proposed to be named codice_1.

One of the cited main motivations for the codice_1 proposal was the ability to write perfect forwarding function templates. It is sometimes desirable to write a generic forwarding function that returns the same type as the wrapped function, regardless of the type it is instantiated with. Without codice_1, it is not generally possible to accomplish this. An example, which also utilizes the "trailing-return-type":
codice_1 is essential here because it preserves the information about whether the wrapped function returns a reference type.

Similarly to the codice_4 operator, the operand of codice_1 is unevaluated. Informally, the type returned by codice_18 is deduced as follows:
These semantics were designed to fulfill the needs of generic library writers, while at the same time being intuitive for novice programmers, because the return type of codice_1 always matches the type of the object or function exactly as declared in the source code. More formally, Rule 1 applies to unparenthesized "id-expression"s and class member access expressions. Example:

The reason for the difference between the latter two invocations of codice_1 is that the parenthesized expression codice_28 is neither an "id-expression" nor a member access expression, and therefore does not denote a named object. Because the expression is an lvalue, its deduced type is "reference to the type of the expression", or codice_29.

In December 2008, a concern was raised to the committee by Jaakko Järvi over the inability to use codice_1 to form a "qualified-id", which is inconsistent with the intent that codice_18 should be treated "as if it were a "typedef-name"". While commenting on the formal Committee Draft for C++0x, the Japanese ISO member body noted that "a scope operator(::) cannot be applied to decltype, but it should be. It would be useful in the case to obtain member type(nested-type) from an instance as follows":
This, and similar issues pertaining to the wording inhibiting the use of codice_1 in the declaration of a derived class and in a destructor call, were addressed by David Vandevoorde, and voted into the working paper in March 2010.

codice_1 is included in the C++ Language Standard since C++11. It is provided by a number of compilers as an extension. Microsoft's Visual C++ 2010 and later compilers provide a codice_1 type specifier that closely mimics the semantics as described in the standards committee proposal. It can be used with both managed and native code. The documentation states that it is "useful primarily to developers who write template libraries." codice_1 was added to the mainline of the GCC C++ compiler in version 4.3, released on March 5, 2008. codice_1 is also present in Codegear's C++ Builder 2009, the Intel C++ Compiler, and Clang.



</doc>
<doc id="2640550" url="https://en.wikipedia.org/wiki?curid=2640550" title="Circular dependency">
Circular dependency

In software engineering, a circular dependency is a relation between two or more modules which either directly or indirectly depend on each other to function properly. Such modules are also known as mutually recursive.

Circular dependencies are natural in many domain models where certain objects of the same domain depend on each other. However, in software design circular dependencies between larger software modules are considered an anti-pattern because of their negative effects, however such circular (or cyclic) dependencies have been found to be widespread among the source files of real-world software. Mutually recursive modules are, however, somewhat common in functional programming, where inductive and recursive definitions are often encouraged.

Circular dependencies can cause many unwanted effects in software programs. Most problematic from a software design point of view is the "tight coupling" of the mutually dependent modules which reduces or makes impossible the separate re-use of a single module.

Circular dependencies can cause a domino effect when a small local change in one module spreads into other modules and has unwanted global effects (program errors, compile errors). Circular dependencies can also result in infinite recursions or other unexpected failures.

Circular dependencies may also cause memory leaks by preventing certain very primitive automatic garbage collectors (those that use reference counting) from deallocating unused objects.

In very large software designs, software engineers may lose the context and inadvertently introduce circular dependencies. There are tools to analyze software and find unwanted circular dependencies.

Circular dependencies are often introduced by inexperienced programmers who need to implement some kind of callback functionality. Experienced programmers avoid such unnecessary circular dependencies by applying design patterns like the observer pattern.

Implementation of circular dependencies in C/C++ can be a bit tricky, because any structure or class definition must be placed above its usage in the same file. A circular dependency between classes "A" and "B" will thus both require the definition of "A" to be placed above "B", and the definition of "B" to be placed above "A", which of course is impossible. A forward declaration is therefore needed to accomplish this.

The following example illustrates how this is done.

Note that although a name (e.g. codice_1) can be "declared" multiple times, such as in forward declarations, it can only be "defined" once (the One Definition Rule).

Following is another example of forward declaration, which might be useful if the application needs a self-sustaining array of objects which is able to add and remove objects from itself during run-time:

The static variables first and last have to be defined, because their declaration does not reserve memory space for them. Note: static variables do not change from object to object and stay the same for this given class.

They should also be initialized to 0, or NULL, so we know what they are to start with.




</doc>
<doc id="3242663" url="https://en.wikipedia.org/wiki?curid=3242663" title="The lexer hack">
The lexer hack

In computer programming, the lexer hack (as opposed to "a lexer hack") describes a common solution to the problems in parsing ANSI C, due to the reference grammar being context-sensitive. In C, classifying a sequence of characters as a variable name or a type name requires contextual information of the phrase structure, which prevents one from having a context-free lexer.

The problem is that in the following code, the lexical class of codice_1 cannot be determined without further contextual information:

This code could be multiplication of two variables, in which case codice_1 is a variable; written unambiguously:

Alternatively, it could be casting the dereferenced value of codice_3 to the type codice_1, in which case codice_1 is a typedef name; written unambiguously:
In more detail, in a compiler, the lexer performs one of the earliest stages of converting the source code to a program. It scans the text to extract meaningful "tokens", such as words, numbers, and strings. The parser analyzes sequences of tokens attempting to match them to syntax rules representing language structures, such as loops and variable declarations. A problem occurs here if a single sequence of tokens can ambiguously match more than one syntax rule.

This ambiguity can happen in C if the lexer does not distinguish between variable and typedef identifiers. For example, in the C expression:

the lexer may find these tokens:

The problem is precisely that the lexical class of "A" cannot be determined without further context: the parser can interpret this as variable "A" multiplied by "B" or as type "A" casting the dereferenced value of "B". This is known as the "typedef-name: identifier" problem, due to the name of the problematic production rule.

The solution generally consists of feeding information from the semantic symbol table back into the lexer. That is, rather than functioning as a pure one-way pipeline from the lexer to the parser, there is a backchannel from semantic analysis back to the lexer. This mixing of parsing and semantic analysis is generally regarded as inelegant, which is why it is called a "hack".

Without added context, the lexer cannot distinguish type identifiers from other identifiers because all identifiers have the same format. With the hack in the above example, when the lexer finds the identifier "A" it should be able to classify the token as a type identifier. The rules of the language would be clarified by specifying that typecasts require a type identifier and the ambiguity disappears.

The problem also exists in C++ and parsers can use the same hack.

This problem does not arise (and hence needs no "hack" in order to solve) when using lexerless parsing techniques, as these are intrinsically contextual. These are generally seen as less elegant designs, however, because they lack the modularity of having a concurrent lexer and parser in a pipeline.

Some parser generators, such as the yacc-derived BtYacc ("Backtracking Yacc"), give the generated parser the ability to try multiple attempts to parse the tokens. In the problem described here, if an attempt fails because of semantic information about the identifier, it can backtrack and attempt other rules.

The Clang parser handles the situation in a completely different way, namely by using a non-reference lexical grammar. Clang's lexer does not attempt to differentiate between type names and variable names: it simply reports the current token as an identifier. The parser then uses Clang's semantic analysis library to determine the nature of the identifier. This allows a much cleaner separation of concerns and encapsulation of the lexer and parser, and is therefore considered a much more elegant solution than The Lexer Hack by most modern software design metrics. This is also the approach used in most other modern languages, which do not distinguish different classes of identifiers in the lexical grammar, but instead defer them to the parsing or semantic analysis phase, when sufficient information is available.




</doc>
<doc id="25311457" url="https://en.wikipedia.org/wiki?curid=25311457" title="Typename">
Typename

"codice_1" is a keyword in the C++ programming language used when writing templates. It is used for specifying that a dependent name in a template definition or declaration is a type. In the original C++ compilers before the first ISO standard was completed, the codice_1 keyword was not part of the C++ language and Bjarne Stroustrup used the codice_3 keyword for template arguments instead. While codice_1 is now the preferred keyword, older source code may still use the codice_3 keyword instead (for example see the difference in source code examples between The Design and Evolution of C++ by Bjarne Stroustrup published in 1994 and the source code examples in The C++ Programming Language: Fourth Edition by Bjarne Stroustrup published in 2013).

In C++'s generic programming feature known as "templates", codice_1 can be used for introducing a template parameter: 
An alternative and semantically equivalent keyword in this scenario is "codice_3":

Consider this invalid code:
This code looks like it should compile, but it is incorrect because the compiler does not know if codice_9 is a type or a value. The reason it doesn't know is that codice_9 is a "template-parameter dependent name", or "dependent name" for short, which then could represent anything named "bar" inside a type passed to foo(), which could include typedefs, enums, variables, etc.

To resolve this ambiguity, the C++ Language Standard declares:
A name used in a template declaration or definition and that is dependent on a template-parameter is assumed not to name a type unless the applicable name lookup finds a type name or the name is qualified by the keyword typename. In short, if the compiler can't tell if a dependent name is a value or a type, then it will assume that it is a value. 
In our example, where codice_9 is the dependent name, that means that rather than declaring a pointer to codice_9 named "p", the line
will instead multiply the "value" codice_9 by codice_14 (which is nowhere to be found) and throw away the result. The fact that in codice_15 the dependent bar is in fact a type does not help since codice_16 could be compiled long before codice_15 is seen. Furthermore, if there is also a class like:
then the compiler would be obliged to interpret the codice_9 in codice_16 as an access to data member codice_20 when instantiated. But since codice_21 is not a static data member it will flag an error.

The solution to this problem is to explicitly tell the compiler that codice_9 is in fact a type. For this, the codice_1 keyword is used:
Now the compiler knows for sure that codice_9 is a type, and will correctly make codice_14 a pointer to an object of that type.



</doc>
<doc id="26991951" url="https://en.wikipedia.org/wiki?curid=26991951" title="Copy elision">
Copy elision

In C++ computer programming, copy elision refers to a compiler optimization technique that eliminates unnecessary copying of objects. The C++ language standard generally allows implementations to perform any optimization, provided the resulting program's observable behavior is the same "as if", i.e. pretending, the program were executed exactly as mandated by the standard.

The standard also describes a few situations where copying can be eliminated even if this would alter the program's behavior, the most common being the return value optimization. Another widely implemented optimization, described in the C++ standard, is when a temporary object of class type is copied to an object of the same type.<ref name="C++03 12.8/15">ISO/IEC (2003). "ISO/IEC 14882:2003(E): Programming Languages - C++ §12.8 Copying class objects [class.copy]" para. 15</ref> As a result, "copy-initialization" is usually equivalent to "direct-initialization" in terms of performance, but not in semantics; "copy-initialization" still requires an accessible copy constructor. The optimization can not be applied to a temporary object that has been bound to a reference.

According to the standard a similar optimization may be applied to objects being thrown and caught,<ref name="C++03 15.1/5">ISO/IEC (2003). "ISO/IEC 14882:2003(E): Programming Languages - C++ §15.1 Throwing an exception [except.throw]" para. 5</ref><ref name="C++03 15.3/17">ISO/IEC (2003). "ISO/IEC 14882:2003(E): Programming Languages - C++ §15.3 Handling an exception [except.handle]" para. 17</ref> but it is unclear whether the optimization applies to both the copy from the thrown object to the "exception object", and the copy from the "exception object" to the object declared in the "exception-declaration" of the "catch clause". It is also unclear whether this optimization only applies to temporary objects, or named objects as well. Given the following source code:

A conforming compiler should therefore produce a program which prints "Hello World!" twice. In the current revision of the C++ standard (C++11), the issues have been addressed, essentially allowing both the copy from the named object to the exception object, and the copy into the object declared in the exception handler to be elided.

GCC provides the codice_1 option to disable copy-elision. This option is useful to observe (or not observe) the effects of return value optimization or other optimizations where copies are elided. It is generally not recommended to disable this important optimization.

In the context of the C++ programming language, return value optimization (RVO) is a compiler optimization that involves eliminating the temporary object created to hold a function's return value. RVO is particularly notable for being allowed to change the observable behaviour of the resulting program by the C++ standard.

In general, the C++ standard allows a compiler to perform any optimization, provided the resulting executable exhibits the same observable behaviour "as if" (i.e. pretending) all the requirements of the standard have been fulfilled. This is commonly referred to as the "as-if rule".<ref name="C++03 1.9/1">ISO/IEC (2003). "ISO/IEC 14882:2003(E): Programming Languages - C++ §1.9 Program execution [intro.execution]" para. 1</ref> The term "return value optimization" refers to a special clause in the C++ standard that goes even further than the "as-if" rule: an implementation may omit a copy operation resulting from a return statement, even if the copy constructor has side effects.<ref name="C++03 12.8/15">ISO/IEC (2003). "ISO/IEC 14882:2003(E): Programming Languages - C++ §12.8 Copying class objects [class.copy]" para. 15</ref>

The following example demonstrates a scenario where the implementation may eliminate one or both of the copies being made, even if the copy constructor has a visible side effect (printing text). The first copy that may be eliminated is the one where a nameless temporary codice_2 could be copied into the function codice_3's return value. The second copy that may be eliminated is the copy of the temporary object returned by codice_3 to codice_5.

Depending upon the compiler, and that compiler's settings, the resulting program may display any of the following outputs:

Returning an object of built-in type from a function usually carries little to no overhead, since the object typically fits in a CPU register. Returning a larger object of class type may require more expensive copying from one memory location to another. To avoid this, an implementation may create a hidden object in the caller's stack frame, and pass the address of this object to the function. The function's return value is then copied into the hidden object. Thus, code such as this:

may generate code equivalent to this:

which causes the codice_6 object to be copied twice.

In the early stages of the evolution of C++, the language's inability to efficiently return an object of class type from a function was considered a weakness. Around 1991, Walter Bright implemented a technique to minimize copying, effectively replacing the hidden object and the named object inside the function with the object used for holding the result:

Bright implemented this optimization in his Zortech C++ compiler. This particular technique was later coined "Named return value optimization", referring to the fact that the copying of a named object is elided.

Return value optimization is supported on most compilers. 
There may be, however, circumstances where the compiler is unable to perform the optimization. One common case is when a function may return different named objects depending on the path of execution:



</doc>
<doc id="6915658" url="https://en.wikipedia.org/wiki?curid=6915658" title="C++ string handling">
C++ string handling

The C++ programming language has support for string handling, mostly implemented in its standard library. The language standard specifies several string types, some inherited from C, some designed to make use of the language's features, such as classes and RAII. The most-used of these is .

Since the initial versions of C++ had only the "low-level" C string handling functionality and conventions, multiple incompatible designs for string handling classes have been designed over the years and are still used instead of codice_1, and C++ programmers may need to handle multiple conventions in a single application.

The type is the main string datatype in standard C++ since 1998, but it was not always part of C++. From C, C++ inherited the convention of using null-terminated strings that are handled by a pointer to their first element, and a library of functions that manipulate such strings. In modern standard C++, a string literal such as still denotes a NUL-terminated array of characters.

Using C++ classes to implement a string type offers several benefits of automated memory management and a reduced risk of out-of-bounds accesses, and more intuitive syntax for string comparison and concatenation. Therefore, it was strongly tempting to create such a class. Over the years, C++ application, library and framework developers produced their own, incompatible string representations, such as the one in AT&T's Standard Components library (the first such implementation, 1983) or the type in Microsoft's MFC. While standardized strings, legacy applications still commonly contain such custom string types and libraries may expect C-style strings, making it "virtually impossible" to avoid using multiple string types in C++ programs and requiring programmers to decide on the desired string representation ahead of starting a project.

In a 1991 retrospective on the history of C++, its inventor Bjarne Stroustrup called the lack of a standard string type (and some other standard types) in C++ 1.0 the worst mistake he made in its development; "the absence of those led to everybody re-inventing the wheel and to an unnecessary diversity in the most fundamental classes".

The various vendors' string types have different implementation strategies and performance characteristics. In particular, some string types use a copy-on-write strategy, where an operation such as

does not actually copy the content of to ; instead, both strings share their contents and a reference count on the content is incremented. The actual copying is postponed until a mutating operation, such as appending a character to either string, makes the strings' contents differ. Copy-on-write can make major performance changes to code using strings (making some operations much faster and some much slower). Though no longer uses it, many (perhaps most) alternative string libraries still implement copy-on-write strings.

Some string implementations store 16-bit or 32-bit code points instead of bytes, this was intended to facilitate processing of Unicode text. However, it means that conversion to these types from or from arrays of bytes is a slow and often a lossy operation, dependent on the "locale", and can throw exceptions. Any processing advantages of 16-bit code units vanished when the variable-width UTF-16 encoding was introduced (though there are still advantages if you must communicate with a 16-bit API such as Windows). Qt's is an example.

Third-party string implementations also differed considerably in the syntax to extract or compare substrings, or to perform searches in the text.

The class is the standard representation for a text string since C++98. The class provides some typical string operations like comparison, concatenation, find and replace, and a function for obtaining substrings. An can be constructed from a C-style string, and a C-style string can also be obtained from one.

The individual units making up the string are of type , at least (and almost always) 8 bits each. In modern usage these are often not "characters", but parts of a multibyte character encoding such as UTF-8.

The copy-on-write strategy was deliberately allowed by the initial C++ Standard for because it was deemed a useful optimization, and used by nearly all implementations. However, there were mistakes, in particular the returned a non-const reference in order to make it easy to port C in-place string manipulations (such code often assumed one byte per character and thus this may not have been a good idea!) This allowed the following code that shows that it must make a copy even though it is almost always used only to examine the string and not modify it:

This caused some implementations to abandon copy-on-write. It was also discovered that the overhead in multi-threaded applications due to the locking needed to examine or change the reference count was greater than the overhead of copying small strings on modern processors (especially for strings smaller than the size of a pointer). The optimization was finally disallowed in C++11, with the result that even passing a as an argument to a function, viz.

must be expected to perform a full copy of the string into newly allocated memory. The common idiom to avoid such copying is to pass as a "const reference":

In C++17 added a new class that is only a pointer and length to read-only data, makes passing arguments far faster than either of the above examples:

 is a typedef for a particular instantiation of the template class. Its definition is found in the header:

Thus provides functionality for strings having elements of type . There is a similar class , which consists of , and is most often used to store UTF-16 text on Windows and UTF-32 on most Unix-like platforms. The C++ standard, however, does not impose any interpretation as Unicode code points or code units on these types and does not even guarantee that a holds more bits than a . To resolve some of the incompatibilities resulting from 's properties, C++11 added two new classes: and (made up of the new types and ), which are the given number of bits per code unit on all platforms.
C++11 also added new string literals of 16-bit and 32-bit "characters" and syntax for putting Unicode code points into null-terminated (C-style) strings.

A is guaranteed to be specializable for any type with a struct to accompany it. As of C++11, only , , and specializations are required to be implemented in the standard library; any other types are implementation-defined. Each specialization is also a Standard Library container, and thus the Standard Library algorithms can be applied to the code units in strings.

The design of has been held up as an example of monolithic design by Herb Sutter, who reckons that of the 103 member functions on the class in C++98, 71 could have been decoupled without loss of implementation efficiency.


</doc>
<doc id="28752009" url="https://en.wikipedia.org/wiki?curid=28752009" title="Most vexing parse">
Most vexing parse

The most vexing parse is a specific form of syntactic ambiguity resolution in the C++ programming language. The term was used by Scott Meyers in "Effective STL" (2001). It is formally defined in section 8.2 of the C++ language standard.

An example is:
The line
is seemingly ambiguous, since it could be interpreted either as

Most programmers expect the first, but the C++ standard requires it to be interpreted as the second.

For example, g++ gives the following error message:
Notice that the compiler gives the error message about the return statement of : since it interpreted the declaration of as a function declaration we won't be able to call the member function on this.

Clang++ provides a warning:

The common ways to force the compiler to consider this as a variable definition are:


An even simpler example appears when a functional cast is intended to convert an expression for initializing a variable or passing to a constructor parameter

In this case, the parentheses around codice_6 are superfluous and the declaration of codice_7 is again a function declaration equivalent to the following

To disambiguate this in favour of a variable declaration, the same technique can be used as for the first case above. Another solution is to use the cast notation:

Or also to use a named cast:

Using the new uniform initialization syntax introduced in C++11 solves this issue.

The problematic code is then unambiguous when braces are used:

Using braces as above creates a variable definition for variable of class , initialized with an anonymous instance of class .



</doc>
<doc id="20309902" url="https://en.wikipedia.org/wiki?curid=20309902" title="Placement syntax">
Placement syntax

In the C++ programming language, placement syntax allows programmers to explicitly specify the memory management of individual objects — i.e. their "placement" in memory. Normally, when an object is created dynamically, an allocation function is invoked in such a way that it will both allocate memory for the object, and initialize the object within the newly allocated memory. The placement syntax allows the programmer to supply additional arguments to the allocation function. A common use is to supply a pointer to a suitable region of storage where the object can be initialized, thus separating memory allocation from object construction.

The "placement" versions of the codice_1 and codice_2 operators and functions are known as placement codice_1 and placement codice_2. A codice_1 "expression", placement or otherwise, calls a codice_1 "function", also known as an allocator function, whose name is codice_7. Similarly, a codice_2 "expression" calls a codice_2 "function", also known as a deallocator function, whose name is codice_10.

Any codice_1 expression that uses the placement syntax is a placement codice_1 expression, and any codice_7 or codice_10 function that takes more than the mandatory first parameter ( and , respectively) is a placement new or placement delete function.

In earlier versions of C++ there was no such thing as "placement new"; instead, developers used explicit assignment to "this" within constructors to achieve similar effect. This practice has been deprecated and abolished later, and third edition of "The C++ Programming Language" doesn't mention this technique.

The Standard C++ syntax for a non-placement codice_1 expression is

The placement syntax adds an expression list immediately after the codice_1 keyword. This expression list is the placement. It can contain any number of expressions.

The placement new functions are overloads of the non-placement new functions. The declaration of the non-placement new functions, for non-array and array codice_1 expressions respectively, are:

The Standard C++ library provides two placement overloads each for these functions. Their declarations are:

In all of the overloads, the first parameter to the codice_7 function is of type , which when the function is called will be passed as an argument specifying the amount of memory, in bytes, to allocate. All of the functions must return type , which is a pointer to the storage that the function allocates.

There are also placement delete functions. They are overloaded versions of the non-placement delete functions. The non-placement delete functions are declared as:

The Standard C++ library provides two placement overloads each for these functions. Their declarations are:

In all of the overloads, the first parameter to the codice_10 function is of type , which is the address of the storage to deallocate.

For both the new and the delete functions, the functions are global, are not in any namespace, and do not have static linkage.

Placement syntax has four main uses: default placement, preventing exceptions, custom allocators, and debugging.

The placement overloads of codice_7 and codice_10 that employ an additional parameter are used for default placement, also known as "pointer placement". Their definitions by the Standard C++ library, which it is not permitted for a C++ program to replace or override, are:

There are various uses for default placement.

Bjarne Stroustrup originally observed, in his book "The Design and Evolution of C++", that pointer placement new is necessary for hardware that expects a certain object at a specific hardware address. It is also required for the construction of objects that need to reside in a certain memory area, such as an area that is shared between several processors of a multiprocessor computer.

Other uses, however, include calling a constructor directly, something which the C++ language does not otherwise permit.

The C++ language does allow a program to call a destructor directly, and, since it is not possible to destroy the object using a codice_2 expression, that is how one destroys an object that was constructed via a pointer placement new expression. For example:

Placement new is used when you do not want operator new to allocate memory (you have pre-allocated it and you want to place the object there), but you do want the object to be constructed. Examples of typical situations where this may be required are:

The basic problem is that the constructor is a peculiar function; when it starts off, there is no object, only raw memory. And by the time it finishes, you have a fully initialized object. Therefore, i) The constructor cannot be called on an object ii) However, it needs to access (and initialize) non-static members. This makes calling the constructor directly an error. The solution is the placement form of operator new.

This operator is implemented as:

Normally, the (non-placement) new functions throw an exception, of type codice_25, if they encounter an error, such as exhaustion of all available memory. This was not how the functions were defined by Stroustrup's "Annotated C++ Reference Manual", but was a change made by the standardization committee when the C++ language was standardized. The original behaviour of the functions, which was to return a pointer when an error occurred, is accessible via placement syntax.

Programmers who wish to do this in their programs must include the Standard C++ library header codice_26 in the source code. This header declares the global codice_27 object, which is of type codice_28 (also declared in the header), which is used to call the overloaded new functions that are declared as taking as their second parameter. For example:

Placement syntax is also employed for custom allocators. This does not use any of the allocator and deallocator functions from the Standard C++ library header codice_26, but requires that programmers write their own allocation and deallocation functions, overloaded for user-defined types. For example, one could define a memory management class as follows:

And define custom placement allocation and deallocation functions as follows:

The program would employ the placement syntax to allocate objects using different instances of the codice_30 class as follows:

Destroying an object whose storage is allocated in such a fashion requires some care. Because there is no placement delete expression, one cannot use it to invoke the custom deallocator. One must either write a destruction function that invokes the custom deallocator, or call the placement delete function directly, as a function call.

The former would resemble:
which would be invoked from a program as:

The latter would involve simply writing the destructor invocation and delete function call into the program:

A common error is to attempt to use a delete expression to delete the object. This results in the wrong codice_10 function being called. Dewhurst recommends two strategies for avoiding this error. The first is to ensure that any custom allocators rely upon the Standard C++ library's global, non-placement, codice_7, and are thus nothing more than simple wrappers around the C++ library's memory management. The second is to create new and delete functions for individual classes, and customize memory management via class function members rather than by using the placement syntax.

Placement new can also be used as a simple debugging tool, to enable programs to print the filename and line number of the source code where a memory allocation has failed. This does not require the inclusion of the Standard C++ library header codice_26, but does require the inclusion of a header that declares four placement functions and a macro replacement for the codice_1 keyword that is used in new expressions. For example, such a header would contain:

This would be employed in a program as follows:

The custom-written placement new functions would then handle using the supplied file and line number information in the event of an exception. For example:

As noted above, there is no placement delete expression. It is not possible to call "any" placement codice_10 function using a codice_2 expression.

The placement delete functions are called from placement codice_1 expressions. In particular, they are called if the constructor of the object throws an exception. In such a circumstance, in order to ensure that the program does not incur a memory leak, the placement delete functions are called. A placement new expression first calls the placement codice_7 function, then calls the constructor of the object upon the raw storage returned from the allocator function. If the constructor throws an exception, it is necessary to deallocate that storage before propagating the exception back to the code that executed the placement new expression, and that is the purpose of the placement delete functions.

The placement delete function that is called matches the placement new function that was invoked by the placement new expression. So, for example, if the following code is executed, the placement delete function that is called will be codice_39:

This is why the "pointer placement" delete functions are defined as no-operations by the Standard C++ library. Since the pointer placement new functions do not allocate any storage, there is no storage to be deallocated in the event of the object's constructor throwing an exception.

If no matching placement delete function exists, no deallocation function is called in the event of an exception being thrown by a constructor within a placement codice_1 expression. There are also some (older) C++ implementations that do not support placement delete (which, like the exception-throwing allocator functions, were an addition made to C++ when it was standardized) at all. In both such situations, an exception being thrown by a constructor when allocating using a custom allocator will result in a memory leak. (In the case of the older C++ implementations, a memory leak will also occur with "non-"placement codice_1 expressions.)



</doc>
<doc id="30145829" url="https://en.wikipedia.org/wiki?curid=30145829" title="Edison Design Group">
Edison Design Group

The Edison Design Group (EDG) is a company that makes compiler front ends (preprocessing and parsing) for C++, Java, and Fortran. Their front ends are widely used in commercially available compilers and code analysis tools. Users include the Intel C++ compiler, Microsoft Visual C++ (IntelliSense), SGI MIPSpro, The Portland Group, and Comeau C++. They are widely known for having the first, and likely only, front end to implement the now-deprecated codice_1 keyword of C++.

EDG was founded in 1988 in New Jersey by J. Stephen "Steve" Adamczyk, a 1974 B.S. graduate of the Massachusetts Institute of Technology, a 1977 M.S. graduate of the Indiana University Bloomington, and an experienced compiler engineer who had worked for Advanced Computer Techniques in New York City.

Other employees include John Spicer and Daveed Vandevoorde.




</doc>
<doc id="18949316" url="https://en.wikipedia.org/wiki?curid=18949316" title="ACCU (organisation)">
ACCU (organisation)

ACCU, previously known as the Association of C and C++ Users, is a non-profit user group of people interested in software development, dedicated to raising the standard of computer programming. The ACCU publishes two journals and organizes an annual conference.

ACCU was formed in 1987 by Martin Houston. The original name of the organisation was "C Users' Group (UK)" and this remained the formal name of the organisation until 2011, although it adopted the public name "Association of C and C++ Users" for the period 1993–2003, and adopted the shorter form "ACCU" from 2003 onward. 
As the formal name suggests, the organisation was originally created for people in the United Kingdom. However, the membership is worldwide, predominantly European and North American, but also with members from central and southern America, Australasia, Africa and Asia.
Originally, the voluntary association was mainly for C programmers, but it has expanded over time to include all programming languages, especially C++, C#, Java, Perl and Python.

The ACCU currently publishes two journals:


Other journals have been published by ACCU in the past. Accent was the news letter of the Silicon Valley chapter and CAUGers was the news letter of the Acorn special interest group. Overload was originally the journal of ACCU's C++ special interest group, but is no longer language-specific.

The Silicon Valley chapter organized local meetings in San Jose. Local groups were formed in London, Bristol & Bath, Oxford, Cambridge, North East England, Southern England and Zurich.

The ACCU is operated by a volunteer committee, elected at an Annual General Meeting during the
annual conference each Spring which from 1997 to 2012 took place in Oxford, and for the first time in Bristol in 2013.
It attracts speakers from the computing community including David Abrahams, Andrei Alexandrescu, Ross J. Anderson, James Coplien, Tom Gilb, Kevlin Henney, Andrew Koenig, Simon Peyton-Jones, Eric S. Raymond, Guido van Rossum, Greg Stein, Bjarne Stroustrup (the designer and original implementor of C++), Herb Sutter and Daveed Vandevoorde.

The UK Python Conference, for the Python programming language, originally started out as a track at the ACCU conference.

ACCU supports the standardisation process for computer programming languages. ACCU provided financial sponsorship of meetings in the UK for both the International Organization for Standardization (ISO) C programming language working group and the ISO C++ working groups and helped finance travel to ECMA meetings in mainland Europe.

The ACCU operates mailing lists, some of which are also open to non-members. These lists allow for general programming-orientated discussions, but also for mentored discussions.
Mentored groups have included Effective C++, Python, software patterns, functional programming and XML. They are often based around study of a book.



</doc>
<doc id="3874572" url="https://en.wikipedia.org/wiki?curid=3874572" title="C++ classes">
C++ classes

A class in C++ is a user-defined type or data structure declared with keyword codice_1 that has data and functions (also called member variables and member functions) as its members whose access is governed by the three access specifiers "private", "protected" or "public". By default access to members of a C++ class is "private". The private members are not accessible outside the class; they can be accessed only through methods of the class. The public members form an interface to the class and are accessible outside the class. 

Instances of a class data type are known as objects and can contain member variables, constants, member functions, and overloaded operators defined by the programmer.

In C++, a class defined with the codice_1 keyword has private members and base classes by default. A structure is a class defined with the codice_3 keyword.<ref name="C++03 9/4">ISO/IEC (2003). "ISO/IEC 14882:2003(E): Programming Languages - C++ §9 Classes [class]" para. 4</ref> Its members and base classes are public by default. In practice, structs are typically reserved for data without functions.

An aggregate class is a class with no user-declared constructors, no private or protected
non-static data members, no base classes, and no virtual functions.<ref name="C++03 8.5.1/1">ISO/IEC (2003). "ISO/IEC 14882:2003(E): Programming Languages - C++ §8.5.1 Aggregates [dcl.init.aggr]" para. 1</ref> Such a class can be initialized with a brace-enclosed comma-separated list of initializer-clauses.<ref name="C++03 8.5.1/2">ISO/IEC (2003). "ISO/IEC 14882:2003(E): Programming Languages - C++ §8.5.1 Aggregates [dcl.init.aggr]" para. 2</ref> The following code has the same semantics in both C and C++.

A POD-struct (Plain Old Data Structure) is an aggregate class that has no non-static data members of type non-POD-struct, non-POD-union (or array of such types) or reference, and has no user-defined assignment operator and no user-defined destructor. A POD-struct could be said to be the C++ equivalent of a C codice_3. In most cases, a POD-struct will have the same memory layout as a corresponding struct declared in C. For this reason, POD-structs are sometimes colloquially referred to as "C-style structs".


C++ classes have their own members. These members include variables (including other structures and classes), functions (specific identifiers or overloaded operators) known as methods, constructors and destructors. Members are declared to be either publicly or privately accessible using the codice_5 and codice_6 access specifiers respectively. Any member encountered after a specifier will have the associated access until another specifier is encountered. There is also inheritance between classes which can make use of the codice_7 specifier.

A class defined outside all methods is a global class because its objects can be created from anywhere in the program. If it is defined within a function body then it's a local class because objects of such a class are local to the function scope.

Classes are declared with the codice_1 or codice_3 keyword. Declaration of members are placed within this declaration.

The above definitions are functionally equivalent. Either code will define objects of type codice_10 as having two public data members, codice_11 and codice_12. The semicolons after the closing braces are mandatory.

After one of these declarations (but not both), codice_10 can be used as follows to create newly defined variables of the codice_10 datatype:

Executing the above code will output

An important feature of the C++ class and structure are member functions. Each datatype can have its own built-in functions (referred to as methods) that have access to all (public and private) members of the datatype. In the body of these non-static member functions, the keyword codice_15 can be used to refer to the object for which the function is called. This is commonly implemented by passing the address of the object as an implicit first argument to the function. Take the above codice_10 type as an example again:

In the above example the codice_17 function is declared in the body of the class and defined by qualifying it with the name of the class followed by codice_18. Both codice_19 and codice_20 are private (default for class) and codice_17 is declared as public which is necessary if it is to be used from outside the class.

With the member function codice_17, printing can be simplified into:
where codice_23 and codice_24 above are called senders, and each of them will refer to their own member variables when the codice_25 function is executed.

It is common practice to separate the class or structure declaration (called its interface) and the definition (called its implementation) into separate units. The interface, needed by the user, is kept in a header and the implementation is kept separately in either source or compiled form.

The layout of non-POD classes in memory is not specified by the C++ standard. For example, many popular C++ compilers implement single inheritance by concatenation of the parent class fields with the child class fields, but this is not required by the standard. This choice of layout makes referring to a derived class via a pointer to the parent class type a trivial operation.

For example, consider

An instance of codice_26 with a codice_27 pointing to it might look like this in memory:
An instance of codice_28 with a codice_27 pointing to it might look like this:
Therefore, any code that manipulates the fields of a codice_26 object can manipulate the codice_26 fields inside the codice_28 object without having to consider anything about the definition of codice_28's fields. A properly written C++ program shouldn't make any assumptions about the layout of inherited fields, in any case. Using the static_cast or dynamic_cast type conversion operators will ensure that pointers are properly converted from one type to another.

Multiple inheritance is not as simple. If a class codice_34 inherits codice_26 and codice_28, then the fields of both parents need to be stored in some order, but (at most) only one of the parent classes can be located at the front of the derived class. Whenever the compiler needs to convert a pointer from the codice_34 type to either codice_26 or codice_28, the compiler will provide an automatic conversion from the address of the derived class to the address of the base class fields (typically, this is a simple offset calculation).

For more on multiple inheritance, see virtual inheritance.

In C++, operators, such as codice_40, can be overloaded to suit the needs of programmers. These operators are called overloadable operators.

By convention, overloaded operators should behave nearly the same as they do in built-in datatypes (codice_41, codice_42, etc.), but this is not required. One can declare a structure called codice_43 in which the variable "really" stores an integer, but by calling codice_44 the sum, instead of the product, of the integers might be returned:

The code above made use of a constructor to "construct" the return value. For clearer presentation (although this could decrease efficiency of the program if the compiler cannot optimize the statement into the equivalent one above), the above code can be rewritten as:

Programmers can also put a prototype of the operator in the codice_3 declaration and define the function of the operator in the global scope:

codice_46 above represents the sender's own member variable, while codice_47 represents the member variable from the argument variable codice_48.

The codice_49 keyword appears twice in the above code. The first occurrence, the argument codice_50, indicated that the argument variable will not be changed by the function. The second incidence at the end of the declaration promises the compiler that the sender would not be changed by the function run.

In codice_50, the ampersand (&) means "pass by reference". When the function is called, a pointer to the variable will be passed to the function, rather than the value of the variable.

The same overloading properties above apply also to classes.

Note that arity, associativity and precedence of operators cannot be changed.

Binary operators (operators with two arguments) are overloaded by declaring a function with an "identifier" "operator (something)" which calls one single argument. The variable on the left of the operator is the sender while that on the right is the argument.

'3' would be printed.

The following is a list of binary overloadable operators:

The '=' (assignment) operator between two variables of the same structure type is overloaded by default to copy the entire content of the variables from one to another. It can be overwritten with something else, if necessary.

Operators must be overloaded one by one, in other words, no overloading is associated with one another. For example, codice_52 is not necessarily the opposite of codice_53.

While some operators, as specified above, takes two terms, sender on the left and the argument on the right, some operators have only one argument - the sender, and they are said to be "unary". Examples are the negative sign (when nothing is put on the left of it) and the "logical NOT" (exclamation mark, codice_54).

Sender of unary operators may be on the left or on the right of the operator. The following is a list of unary overloadable operators:
The syntax of an overloading of a unary operator, where the sender is on the right, is as follows:

When the sender is on the left, the declaration is:

codice_57 above stands for the operator to be overloaded. Replace codice_58 with the datatype of the return value (codice_41, codice_60, structures etc.)

The codice_41 parameter essentially means nothing but a convention to show that the sender is on the left of the operator.

codice_49 arguments can be added to the end of the declaration if applicable.

The square bracket codice_63 and the round bracket codice_64 can be overloaded in C++ structures. The square bracket must contain exactly one argument, while the round bracket can contain any specific number of arguments, or no arguments.

The following declaration overloads the square bracket.

The content inside the bracket is specified in the codice_66 part.

Round bracket is overloaded a similar way.

Contents of the bracket in the operator call are specified in the second bracket.

In addition to the operators specified above, the arrow operator (codice_68), the starred arrow (codice_69), the codice_70 keyword and the codice_71 keyword can also be overloaded. These memory-or-pointer-related operators must process memory-allocating functions after overloading. Like the assignment (codice_72) operator, they are also overloaded by default if no specific declaration is made.

Sometimes programmers may want their variables to take a default or specific value upon declaration. This can be done by declaring constructors.

Member variables can be initialized in an initializer list, with utilization of a colon, as in the example below. This differs from the above in that it initializes (using the constructor), rather than using the assignment operator. This is more efficient for class types, since it just needs to be constructed directly; whereas with assignment, they must be first initialized using the default constructor, and then assigned a different value. Also some types (like references and const types) cannot be assigned to and therefore must be initialized in the initializer list.

Note that the curly braces cannot be omitted, even if empty.

Default values can be given to the last arguments to help initializing default values.

When no arguments are given to the constructor in the example above, it is equivalent to calling the following constructor with no arguments (a default constructor):

The declaration of a constructor looks like a function with the same name as the datatype. In fact, a call to a constructor can take the form of a function call. In that case an initialized codice_10 type variable can be thought of as the return value:

An alternate syntax that does the same thing as the above example is

Specific program actions, which may or may not relate to the variable, can be added as part of the constructor.

With the above constructor, a "Hello!" will be printed when the default codice_10 constructor is invoked.

Default constructors are called when constructors are not defined for the classes. 
However, if a "user defined constructor" was defined for the class, both of the above declarations will call this user defined constructor, whose defined code will be executed, but no default values will be assigned to the variable b.

A destructor is the inverse of a constructor. It is called when an instance of a class is destroyed, e.g. when an object of a class created in a block (set of curly braces "{}") is deleted after the closing brace, then the destructor is called automatically. It will be called upon emptying of the memory location storing the variables. Destructors can be used to release resources, such as heap-allocated memory and opened files when an instance of that class is destroyed.

The syntax for declaring a destructor is similar to that of a constructor. There is no return value and the name of the method is the same as the name of the class with a tilde (~) in front.

In C++, class declarations can be generated from class templates. Such class templates represent a family of classes. An actual class declaration is obtained by "instantiating" the template with one or more template arguments. A template instantiated with a particular set of arguments is called a template specialization.

The syntax of C++ tries to make every aspect of a structure look like that of the basic datatypes. Therefore, overloaded operators allow structures to be manipulated just like integers and floating-point numbers, arrays of structures can be declared with the square-bracket syntax (codice_75), and pointers to structures can be dereferenced in the same way as pointers to built-in datatypes.

The memory consumption of a structure is at least the sum of the memory sizes of constituent variables. Take the codice_76 structure below as an example.

The structure consists of two integers. In many current C++ compilers, integers are 32-bit integers by default, so each of the member variables consume four bytes of memory. The entire structure, therefore, consumes at least (or exactly) eight bytes of memory, as follows.

However, the compiler may add padding between the variables or at the end of the structure to ensure proper data alignment for a given computer architecture, often padding variables to be 32-bit aligned. For example, the structure

could look like 
in memory, where X represents padded bytes based on 4 bytes alignment.

As structures may make use of pointers and arrays to declare and initialize its member variables, memory consumption of structures is not necessarily constant. Another example of non-constant memory size is template structures.

Bit fields are used to define the class members that can occupy less storage than an integral type. This field is applicable only for integral types (int, char, short, long, etc.) and excludes float or double.

Bit fields are not allowed in a union. It is applicable only for the classes defined using the keyword struct or class.

Many programmers prefer to use the ampersand (&) to declare the arguments of a function involving structures. This is because by using the dereferencing ampersand only one word (typically 4 bytes on a 32 bit machine, 8 bytes on a 64 bit machine) is required to be passed into the function, namely the memory location to the variable. Otherwise, if pass-by-value is used, the argument needs to be copied every time the function is called, which is costly with large structures.

Since pass-by-reference exposes the original structure to be modified by the function, the codice_49 keyword should be used to guarantee that the function does not modify the parameter (see const-correctness), when this is not intended.

To facilitate structures' ability to reference themselves, C++ implements the codice_15 keyword for all member functions. The codice_15 keyword acts as a pointer to the current object. Its type is that of a pointer to the current object.

The codice_15 keyword is especially important for member functions with the structure itself as the return value:

As stated above, codice_15 is a pointer, so the use of the asterisk (*) is necessary to convert it into a reference to be returned.


General References:


</doc>
<doc id="29958766" url="https://en.wikipedia.org/wiki?curid=29958766" title="Functional (C++)">
Functional (C++)

In the context of the programming language C++, codice_1 refers to a header file that is part of the C++ Standard Library and provides a set of predefined class templates for function objects, including operations for arithmetic, comparisons, and logic. Instances of these class templates are C++ classes that define a function call operator, and the instances of these classes can be called as if they were functions. It is possible to perform very sophisticated operations without writing a new function object, simply by combining predefined function objects and function object adaptors.

The class template codice_2 provided by C++11 is a general-purpose polymorphic function wrapper. Instances of codice_2 can store, copy, and invoke any callable target—functions, lambda expressions (expressions defining anonymous functions), bind expressions (instances of function adapters that transform functions to other functions of smaller arity by providing values for some of the arguments), or other function objects.

The algorithms provided by the C++ Standard Library do not require function objects of more than two arguments. Function objects that return Boolean values are an important special case. A unary function whose return type is is called a "predicate", and a binary function whose return type is is called a "binary predicate".

In general, a function object has restrictions on the type of its argument. The type restrictions need not be simple, though: may be overloaded or may be a member template. Similarly, there need be no way for a program to determine what those restrictions are. An adaptable function object, however, does specify what the argument and return types are, and provides nested s so that those types can be named and used in programs. If a type is a model of an adaptable generator, then it must define . Similarly, if is a model of the adaptable unary function, it must define and , and if is a model of the adaptable binary function, it must define , , and . The C++ Standard Library provides base classes and to simplify the definition of adaptable unary functions and adaptable binary functions.

Adaptable function objects are important, because they can be used by function object adaptors: function objects that transform or manipulate other function objects. The C++ Standard Library provides many different function object adaptors, including (that returns the logical complement of the value returned by a particular adaptable predicate), and and , which perform composition of function object.

The C++ Standard Library includes in the header file codice_1 many different predefined function objects, including arithmetic operations (, , , , , and ), comparisons (, , , , , and ), and logical operations (, , and ).

Function wrappers can be used to make calls to ordinary functions or to functions objects created by lambda expressions.

Function wrappers also can be used to access member variables and member functions of classes.



</doc>
<doc id="725961" url="https://en.wikipedia.org/wiki?curid=725961" title="Name mangling">
Name mangling

In compiler construction, name mangling (also called name decoration) is a technique used to solve various problems caused by the need to resolve unique names for programming entities in many modern programming languages.

It provides a way of encoding additional information in the name of a function, structure, class or another datatype in order to pass more semantic information from the compilers to linkers.

The need arises where the language allows different entities to be named with the same identifier as long as they occupy a different namespace (where a namespace is typically defined by a module, class, or explicit "namespace" directive) or have different signatures (such as function overloading).

Any object code produced by compilers is usually linked with other pieces of object code (produced by the same or another compiler) by a type of program called a linker. The linker needs a great deal of information on each program entity. For example, to correctly link a function it needs its name, the number of arguments and their types, and so on.

Although name mangling is not generally required or used by languages that do not support function overloading (such as C and classic Pascal), they use it in some cases to provide additional information about a function.
For example, compilers targeted at Microsoft Windows platforms support a variety of calling conventions, which determine the manner in which parameters are sent to subroutines and results returned. Because the different calling conventions are not compatible with one another, compilers mangle symbols with codes detailing which convention should be used to call the specific routine.

The mangling scheme was established by Microsoft, and has been informally followed by other compilers including Digital Mars, Borland, and GNU GCC, when compiling code for the Windows platforms. The scheme even applies to other languages, such as Pascal, D, Delphi, Fortran, and C#. This allows subroutines written in those languages to call, or be called by, existing Windows libraries using a calling convention different from their default.

When compiling the following C examples:
32 bit compilers emit, respectively:

In the and mangling schemes, the function is encoded as codice_1 and codice_2 respectively, where is the number of bytes, in decimal, of the argument(s) in the parameter list (including those passed in registers, for fastcall). In the case of , the function name is merely prefixed by an underscore.

The 64-bit convention on Windows (Microsoft C) has no leading underscore. This difference may in some rare cases lead to unresolved externals when porting such code to 64 bits. For example, Fortran code can use 'alias' to link against a C method by name as follows:

This will compile and link fine under 32 bits, but generate an unresolved external codice_3 under 64 bits. One workaround for this is not to use 'alias' at all (in which the method names typically need to be capitalized in C and Fortran). Another is to use the BIND option:

C++ compilers are the most widespread users of name mangling. The first C++ compilers were implemented as translators to C source code, which would then be compiled by a C compiler to object code; because of this, symbol names had to conform to C identifier rules. Even later, with the emergence of compilers which produced machine code or assembly directly, the system's linker generally did not support C++ symbols, and mangling was still required.

The C++ language does not define a standard decoration scheme, so each compiler uses its own. C++ also has complex language features, such as classes, templates, namespaces, and operator overloading, that alter the meaning of specific symbols based on context or usage. Meta-data about these features can be disambiguated by mangling (decorating) the name of a symbol. Because the name-mangling systems for such features are not standardized across compilers, few linkers can link object code that was produced by different compilers.

A single C++ translation unit might define two functions named :

These are distinct functions, with no relation to each other apart from the name. The C++ compiler therefore will encode the type information in the symbol name, the result being something resembling:

Even though its name is unique, is still mangled: name mangling applies to all symbols.

The mangled symbols in this example, in the comments below the respective identifier name, are those produced by the GNU GCC 3.x compilers:

All mangled symbols begin with codice_4 (note that an identifier beginning with an underscore followed by a capital is a reserved identifier in C, so conflict with user identifiers is avoided); for nested names (including both namespaces and classes), this is followed by codice_5, then a series of <length, id> pairs (the length being the length of the next identifier), and finally codice_6. For example, codice_7 becomes

For functions, this is then followed by the type information; as is a function, this is simply codice_8; hence:

For , the standard type (which is a for codice_9) is used, which has the special alias codice_10; a reference to this type is therefore codice_11, with the complete name for the function being:

There isn't a standard scheme by which even trivial C++ identifiers are mangled, and consequently different compilers (or even different versions of the same compiler, or the same compiler on different platforms) mangle public symbols in radically different (and thus totally incompatible) ways. Consider how different C++ compilers mangle the same functions:
Notes:

The job of the common C++ idiom:

is to ensure that the symbols within are "unmangled" – that the compiler emits a binary file with their names undecorated, as a C compiler would do. As C language definitions are unmangled, the C++ compiler needs to avoid mangling references to these identifiers.

For example, the standard strings library, usually contains something resembling:

Thus, code such as:

uses the correct, unmangled and . If the had not been used, the (SunPro) C++ compiler would produce code equivalent to:

Since those symbols do not exist in the C runtime library ("e.g." libc), link errors would result.

Though it would seem that standardised name mangling in the C++ language would lead to greater interoperability between compiler implementations, such a standardization by itself would not suffice to guarantee C++ compiler interoperability and it might even create a false impression that interoperability is possible and safe when it isn't. Name mangling is only one of several application binary interface (ABI) details that need to be decided and observed by a C++ implementation. Other ABI aspects like exception handling, virtual table layout, structure and stack frame padding, "etc." also cause differing C++ implementations to be incompatible. Further, requiring a particular form of mangling would cause issues for systems where implementation limits (e.g., length of symbols) dictate a particular mangling scheme. A standardised "requirement" for name mangling would also prevent an implementation where mangling was not required at all — for example, a linker which understood the C++ language.

The C++ standard therefore does not attempt to standardise name mangling. On the contrary, the "Annotated C++ Reference Manual" (also known as "ARM", , section 7.2.1c) actively encourages the use of different mangling schemes to prevent linking when other aspects of the ABI, such as exception handling and virtual table layout, are incompatible.

Nevertheless, as detailed in the section above, on some platforms the full C++ ABI has been standardized, including name mangling.

Because C++ symbols are routinely exported from DLL and shared object files, the name mangling scheme is not merely a compiler-internal matter. Different compilers (or different versions of the same compiler, in many cases) produce such binaries under different name decoration schemes, meaning that symbols are frequently unresolved if the compilers used to create the library and the program using it employed different schemes. For example, if a system with multiple C++ compilers installed (e.g., GNU GCC and the OS vendor's compiler) wished to install the Boost C++ Libraries, it would have to be compiled multiple times (once for GCC and once for the vendor compiler).

It is good for safety purposes that compilers producing incompatible object codes (codes based on different ABIs, regarding e.g., classes and exceptions) use different name mangling schemes. This guarantees that these incompatibilities are detected at the linking phase, not when executing the software (which could lead to obscure bugs and serious stability issues).

For this reason name decoration is an important aspect of any C++-related ABI.

Output: 

In Java, the signature of a method or a class contains its name and the types of its method arguments and return value where applicable. The format of signatures is documented, as the language, compiler, and .class file format were all designed together (and had object-orientation and universal interoperability in mind from the start).

The scope of anonymous classes is confined to their parent class, so the compiler must produce a "qualified" public name for the inner class, to avoid conflict where other classes with the same name (inner or not) exist in the same namespace. Similarly, anonymous classes must have "fake" public names generated for them (as the concept of anonymous classes only exists in the compiler, not the runtime). So, compiling the following java program

will produce three .class files:

All of these class names are valid (as $ symbols are permitted in the JVM specification) and these names are "safe" for the compiler to generate, as the Java language definition advices, not to use $ symbols in normal java class definitions.

Name resolution in Java is further complicated at runtime, as fully qualified class names are unique only inside a specific classloader instance. Classloaders are ordered hierarchically and each Thread in the JVM has a so-called context class loader, so in cases where two different classloader instances contain classes with the same name, the system first tries to load the class using the root (or system) classloader and then goes down the hierarchy to the context class loader.

Java's native method support allows Java language programs to call out to programs written in another language (generally either C or C++). There are two name-resolution concerns here, neither of which is implemented in a particularly standard manner:


In Python, mangling is used for "private" class members which are designated as such by giving them a name with two leading underscores and no more than one trailing underscore. For example, codice_13 will be mangled, as will codice_14 and codice_15, but codice_16 and codice_17 will not. Python's runtime does not restrict access to such members, the mangling only prevents name collisions if a derived class defines a member with the same name.

On encountering name mangled attributes, Python transforms these names by prepending a single underscore and the name of the enclosing class, for example:

To avoid name mangling in Pascal, use:

Free Pascal supports function and operator overloading, thus it also uses name mangling to support these features. On the other hand, Free Pascal is capable of calling symbols defined in external modules created with another language and exporting its own symbols to be called by another language. For further information, consult Chapter 6.2 and Chapter 7.1 of Free Pascal Programmer's Guide.

Name mangling is also necessary in Fortran compilers, originally because the language is case insensitive. Further mangling requirements were imposed later in the evolution of the language because of the addition of modules and other features in the Fortran 90 standard. The case mangling, especially, is a common issue that must be dealt with in order to call Fortran libraries (such as LAPACK) from other languages (such as C).

Because of the case insensitivity, the name of a subroutine or function "FOO" must be converted to a canonical case and format by the Fortran compiler so that it will be linked in the same way regardless of case. Different compilers have implemented this in various ways, and no standardization has occurred. The AIX and HP-UX Fortran compilers convert all identifiers to lower case ("foo"), while the Cray Unicos Fortran compilers converted identifiers
all upper case ("FOO"). The GNU g77 compiler converts identifiers to lower case plus an underscore ("foo_"), except that identifiers already containing an underscore ("FOO_BAR") have two underscores appended ("foo_bar__"), following a convention established by f2c. Many other compilers, including SGI's IRIX compilers, GNU Fortran, and Intel's Fortran compiler (except on Microsoft Windows), convert all identifiers to lower case plus an underscore ("foo_" and "foo_bar_"). On Microsoft Windows, the Intel Fortran compiler defaults to uppercase without an underscore.

Identifiers in Fortran 90 modules must be further mangled, because the same procedure name may occur in different modules. Since the Fortran 2003 Standard requires that module procedure names not conflict with other external symbols, compilers tend to use the module name and the procedure name, with a distinct marker in between. For example, in the following module

The name of the function will be mangled as (e.g., GNU Fortran), (e.g., Intel's ifort), (e.g., Oracle's sun95), etc. Since Fortran does not allow overloading the name of a procedure, but uses generic interface blocks and generic type-bound procedures instead, the mangled names do not need to incorporate clues about the arguments.

The Fortran 2003 BIND option overrides any name mangling done by the compiler, as shown above.

Function names are mangled by default in Rust. However, this can be disabled by the function attribute. This attribute can be used to export functions to C, C++, or Objective-C. Additionally, along with the function attribute or the crate attribute, it allows the user to define a C-style entry point for the program. Starting from Rust 1.9, Rust uses a C++-style name-mangling scheme (which partly follows the Itanium C++ ABI).

Essentially two forms of method exist in Objective-C, the class ("static") method, and the instance method. A method declaration in Objective-C is of the following form
Class methods are signified by +, instance methods use -. A typical class method declaration may then look like:

with instance methods looking like

Each of these method declarations have a specific internal representation. When compiled, each method is named according to the following scheme for class methods:
and this for instance methods:

The colons in the Objective-C syntax are translated to underscores. So, the Objective-C class method , if belonging to the codice_18 class would translate as codice_19, and the instance method (belonging to the same class) would translate to codice_20.

Each of the methods of a class are labeled in this way. However, in order to look up a method that a class may respond to would be tedious if all methods are represented in this fashion. Each of the methods is assigned a unique symbol (such as an integer). Such a symbol is known as a "selector". In Objective-C, one can manage selectors directly — they have a specific type in Objective-C — codice_21.

During compilation, a table is built that maps the textual representation (such as codice_20) to selectors (which are given a type codice_21). Managing selectors is more efficient than manipulating the textual representation of a method. Note that a selector only matches a method's name, not the class it belongs to — different classes can have different implementations of a method with the same name. Because of this, implementations of a method are given a specific identifier too — these are known as implementation pointers, and are given a type also, codice_24.

Message sends are encoded by the compiler as calls to the function, or one of its cousins, where codice_25 is the receiver of the message, and codice_21 determines the method to call. Each class has its own table that maps selectors to their implementations — the implementation pointer specifies where in memory the actual implementation of the method resides. There are separate tables for class and instance methods. Apart from being stored in the codice_21 to codice_24 lookup tables, the functions are essentially anonymous.

The codice_21 value for a selector does not vary between classes. This enables polymorphism.

The Objective-C runtime maintains information about the argument and return types of methods. However, this information is not part of the name of the method, and can vary from class to class.

Since Objective-C does not support namespaces, there is no need for mangling of class names (that do appear as symbols in generated binaries).

Swift keeps metadata about functions (and more) in the mangled symbols referring to them. This metadata includes the function's name, attributes, module name, parameter types, return type, and more. For example:

The mangled name for a method codice_30 of a codice_31 class in module codice_32 is _TFC4test7MyClass9calculatefS0_FT1xSi_Si. The components and their meanings are as follows:

codice_33: The prefix for all Swift symbols. Everything will start with this.

codice_34: Non-curried function.

codice_35: Function of a class. (method)

codice_36: The module name, with a prefixed length.

codice_37: The class name the function belongs to, again, with a prefixed length.

codice_38: The function name.

codice_39: The function attribute. In this case it's ‘f’, which is a normal function.

codice_40: Designates the type of the first parameter (namely the class instance) as the first in the type stack (here codice_31 is not nested and thus has index 0).

codice_42: This begins the type list for the parameter tuple of the function.

codice_43: External name of first parameter of the function.

codice_44: Indicates builtin Swift type codice_45 for the first parameter.

codice_46: The return type; again codice_45.




</doc>
<doc id="30196706" url="https://en.wikipedia.org/wiki?curid=30196706" title="GNU E">
GNU E

GNU E is an extension of C++ designed for writing software systems to
support persistent applications. It was designed as part of the
Exodus project.



</doc>
<doc id="31218" url="https://en.wikipedia.org/wiki?curid=31218" title="Template (C++)">
Template (C++)

Templates are a feature of the C++ programming language that allows functions and classes to operate with generic types. This allows a function or class to work on many different data types without being rewritten for each one.

Templates are of great utility to programmers in C++, especially when combined with multiple inheritance and operator overloading. The C++ Standard Library provides many useful functions within a framework of connected templates.

Major inspirations for C++ templates were the parameterized modules provided by CLU and the generics provided by Ada.

There are three kinds of templates: "function templates", "class templates" and, since C++14, "variable templates". Since C++11, templates may be either variadic or non-variadic; in earlier versions of C++ they are always non-variadic.

A "function template" behaves like a function except that the template can have arguments of many different types (see example). In other words, a function template represents a family of functions. The format for declaring function templates with type parameters is:

template <class identifier> function_declaration;
template <typename identifier> function_declaration;

Both expressions have the same meaning and behave in exactly the same way. The latter form was introduced to avoid confusion, since a type parameter need not be a class. (It can also be a basic type such as codice_1 or codice_2.)

For example, the C++ Standard Library contains the function template codice_3 which returns the larger of codice_4 and codice_5. That function template could be defined like this:

template <typename T>
inline T max(T a, T b) {

This single function definition works with many data types. Specifically, it works with all data types for which > (the greater-than operator) is defined. The usage of a function template saves space in the source code file in addition to limiting changes to one function description and making the code easier to read.

A template does not produce smaller object code, though, compared to writing separate functions for all the different data types used in a specific program. For example, if a program uses both an codice_1 and a codice_2 version of the codice_8 function template shown above, the compiler will create an object code version of codice_8 that operates on codice_1 arguments and another object code version that operates on codice_2 arguments. The compiler output will be identical to what would have been produced if the source code had contained two separate non-templated versions of codice_8, one written to handle codice_1 and one written to handle codice_2.

Here is how the function template could be used:


int main()

In the first two cases, the template argument codice_15 is automatically deduced by the compiler to be codice_1 and codice_2, respectively. In the third case automatic deduction of codice_18 would fail because the type of the parameters must in general match the template arguments exactly. Therefore, we explicitly instantiate the codice_2 version with codice_20.

This function template can be instantiated with any copy-constructible type for which the expression codice_21 is valid. For user-defined types, this implies that the greater-than operator (codice_22) must be overloaded in the type.

A class template provides a specification for generating classes based on parameters. Class templates are generally used to implement containers. A class template is instantiated by passing a given set of types to it as template arguments. The C++ Standard Library contains many class templates, in particular the containers adapted from the Standard Template Library, such as codice_23.

In C++14, templates can be also used for variables, as in the following example:

template<typename T> constexpr T pi = T(3.141592653589793238462643383L);

When a function or class is instantiated from a template, a specialization of that template is created by the compiler for the set of arguments used, and the specialization is referred to as being a generated specialization.

Sometimes, the programmer may decide to implement a special version of a function (or class) for a given set of template type arguments which is called an explicit specialization. In this way certain template types can have a specialized implementation that is optimized for the type or a more meaningful implementation than the generic implementation.

Explicit specialization is used when the behavior of a function or class for particular choices of the template parameters must deviate from the generic behavior: that is, from the code generated by the main template, or templates. For example, the template definition below defines a specific implementation of codice_8 for arguments of type codice_25:

template <>
bool max<bool>(bool a, bool b) {

C++11 introduced variadic templates, which can take a variable number of arguments in a manner somewhat similar to variadic functions such as codice_26. Function templates, class templates and (in C++14) variable templates can all be variadic.

C++11 introduced template aliases, which act like parameterized typedefs.

The following code shows the definition of a template alias codice_27. This allows, for example, codice_28 to be used as shorthand for codice_29.
template<class T>
using StrMap = std::unordered_map<T, std::string>;

Some uses of templates, such as the codice_8 function mentioned above, were previously fulfilled by function-like preprocessor macros. For example, the following is a C++ codice_8 macro that evaluates to the maximum of its two arguments as defined by the < operator:
Both macros and templates are expanded at compile time. Macros are always expanded inline, while templates are only expanded inline when the compiler deems it appropriate. When expanded inline, macro functions and function templates have no extraneous runtime overhead. Template functions with many lines of code will incur runtime overhead when they are not expanded inline, but the reduction in code size may help the code to fit into the CPU's instruction cache.

Macro arguments are not evaluated prior to expansion. The expression using the macro defined above

may evaluate to a negative number (because std::rand() will be called twice as specified in the macro, using different random numbers for comparison and output respectively), while the call to template function

will always evaluate to a non-negative number.

As opposed to macros, templates are considered type-safe; that is, they require type-checking at compile time. Hence, the compiler can determine at compile time whether the type associated with a template definition can perform all of the functions required by that template definition.

By design, templates can be utilized in very complex problem spaces, whereas macros are substantially more limited.

There are fundamental drawbacks to the use of templates:

Additionally, the use of the "less than" and "greater than" signs as delimiters is problematic for tools (such as text editors) which analyze source code syntactically. It is difficult for such tools to determine whether a use of these tokens is as comparison operators or template delimiters. For example, this line of code:
may be a function call with two parameters, each the result of a comparison expression. Alternatively, it could be a declaration of a constructor for class codice_32 taking a parameter codice_33 whose type is the parameterized codice_34.

Initially, the concept of templates was not included in some languages, such as Java and C# 1.0. Java's adoption of generics mimics the behavior of templates, but is technically different. C# added generics (parameterized types) in .NET 2.0. The generics in Ada predate C++ templates.

Although C++ templates, Java generics, and .NET generics are often considered similar, generics only mimic the basic behavior of C++ templates. Some of the advanced template features utilized by libraries such as Boost and STLSoft, and implementations of the STL itself, for template metaprogramming (explicit or partial specialization, default template arguments, template non-type arguments, template template arguments, ...) are not available with generics.

In C++ templates, compile-time cases were historically performed by pattern matching over the template arguments. For example, the template base class in the Factorial example below is implemented by matching 0 rather than with an inequality test, which was previously unavailable. However, the arrival in C++11 of standard library features such as std::conditional has provided another, more flexible way to handle conditional template instantiation.

// Induction

template <unsigned N>
struct Factorial {

// Base case via template specialization:

template <>
struct Factorial<0> {

With these definitions, one can compute, say 6! at compile time using the expression codice_35.
Alternatively, constexpr in C++11 can be used to calculate such values directly using a function at compile-time.




</doc>
<doc id="374664" url="https://en.wikipedia.org/wiki?curid=374664" title="Virtual function">
Virtual function

In object-oriented programming, in languages such as C++, and Object Pascal, a virtual function or virtual method is an inheritable and overridable function or method for which dynamic dispatch is facilitated. This concept is an important part of the (runtime) polymorphism portion of object-oriented programming (OOP). In short, a virtual function defines a target function to be executed, but the target might not be known at compile time.

The concept of the virtual function solves the following problem:

In object-oriented programming, when a derived class inherits from a base class, an object of the derived class may be referred to via a pointer or reference of the base class type instead of the derived class type. If there are base class methods overridden by the derived class, the method actually called by such a reference or pointer can be bound either 'early' (by the compiler), according to the declared type of the pointer or reference, or 'late' (i.e., by the runtime system of the language), according to the actual type of the object referred to.

Virtual functions are resolved 'late'. If the function in question is 'virtual' in the base class, the most-derived class's implementation of the function is called according to the actual type of the object referred to, regardless of the declared type of the pointer or reference. If it is not 'virtual', the method is resolved 'early' and the function called is selected according to the declared type of the pointer or reference.

Virtual functions allow a program to call methods that don't necessarily even exist at the moment the code is compiled.

In C++, "virtual methods" are declared by prepending the keyword to the function's declaration in the base class. This modifier is inherited by all implementations of that method in derived classes, meaning that they can continue to over-ride each other and be late-bound. And even if methods owned by the base class call the virtual method, they will instead be calling the derived method. Overloading occurs when two or more methods in one class have the same method name but different parameters. Overriding means having two methods with the same method name and parameters. Overloading is also referred to as dynamic function mapping and overriding as function matching.

For example, a base class codice_1 could have a virtual function codice_2. Subclass codice_3 would implement codice_2 differently than subclass codice_5, but one can invoke codice_2 on any class instance referred to as Animal, and get the codice_2 behavior of the specific subclass.

This allows a programmer to process a list of objects of class codice_1, telling each in turn to eat (by calling codice_2), without needing to know what kind of animal may be in the list, how each animal eats, or what the complete set of possible animal types might be.

We can better see how virtual functions work by implementing the above example in C
A pure virtual function or pure virtual method is a virtual function that is required to be implemented by a derived class if the derived class is not abstract. Classes containing pure virtual methods are termed "abstract" and they cannot be instantiated directly. A subclass of an abstract class can only be instantiated directly if all inherited pure virtual methods have been implemented by that class or a parent class. Pure virtual methods typically have a declaration (signature) and no definition (implementation).

As an example, an abstract base class codice_10 may provide a pure virtual function codice_11, and derived classes codice_12 and codice_13 implement codice_11 to provide concrete implementations. Implementing codice_11 would not make sense in the codice_10 class, as codice_10 is an abstract concept whose behaviour is defined solely for each given kind (subclass) of codice_10. Similarly, a given subclass of codice_10 would not be complete without an implementation of
codice_11.

Although pure virtual methods typically have no implementation in the class that declares them, pure virtual methods in C++ are permitted to contain an implementation in their declaring class, providing fallback or default behaviour that a derived class can delegate to, if appropriate.

Pure virtual functions can also be used where the method declarations are being used to define an interface - similar to what the interface keyword in Java explicitly specifies. In such a use, derived classes will supply all implementations. In such a design pattern, the abstract class which serves as an interface will contain "only" pure virtual functions, but no data members or ordinary methods. In C++, using such purely abstract classes as interfaces works because C++ supports multiple inheritance. However, because many OOP languages do not support multiple inheritance, they often provide a separate interface mechanism. An example is the Java programming language.

Languages differ in their behaviour while the constructor or destructor of an object is running. For some languages, notably C++, the virtual dispatching mechanism has different semantics during construction and destruction of an object. While it is recommended that virtual function calls in constructors should be avoided for C++, in some other languages, for example C# and Java, the derived implementation can be called during construction and design patterns such as the Abstract Factory Pattern actively promote this usage in languages supporting the ability.

Object-oriented languages typically manage memory allocation and de-allocation automatically when objects are created and destroyed. However, some object-oriented languages allow a custom destructor method to be implemented, if desired. If the language in question uses automatic memory management, the custom destructor (generally called a finalizer in this context) that is called is certain to be the appropriate one for the object in question. For example, if an object of type Wolf that inherits Animal is created, and both have custom destructors, the one called will be the one declared in Wolf.

In manual memory management contexts, the situation can be more complex, particularly in relation to static dispatch. If an object of type Wolf is created but pointed to by an Animal pointer, and it is this Animal pointer type that is deleted, the destructor called may actually be the one defined for Animal and not the one for Wolf, unless the destructor is virtual. This is particularly the case with C++, where the behaviour is a common source of programming errors.



</doc>
<doc id="3955943" url="https://en.wikipedia.org/wiki?curid=3955943" title="Static cast">
Static cast

In C++ type conversion, the codice_1 operator performs an explicit type conversion.

The "type" parameter must be a data type to which "object" can be converted via a known method, whether it be a builtin or a cast. The type can be a reference or an enumerator.
All types of conversions that are well-defined and allowed by the compiler are performed using codice_1.

The codice_3 operator can be used for operations such as:

Although codice_1 conversions are checked at compile time to prevent obvious incompatibilities, no run-time type check is performed that would prevent a cast between incompatible data types, such as pointers. Also, the result of a codice_1 from a pointer of a virtual base class to a pointer of a derived class is undefined.



</doc>
<doc id="711324" url="https://en.wikipedia.org/wiki?curid=711324" title="Boost (C++ libraries)">
Boost (C++ libraries)

Boost is a set of libraries for the C++ programming language that provide support for tasks and structures such as linear algebra, pseudorandom number generation, multithreading, image processing, regular expressions, and unit testing. It contains over eighty individual libraries.

Most of the Boost libraries are licensed under the Boost Software License, designed to allow Boost to be used with both free and proprietary software projects. Many of Boost's founders are on the C++ standards committee, and several Boost libraries have been accepted for incorporation into both the C++ Technical Report 1 and the C++11 standard.

The libraries are aimed at a wide range of C++ users and application domains. They range from general-purpose libraries like the smart pointer library, to operating system abstractions like "Boost FileSystem", to libraries primarily aimed at other library developers and advanced C++ users, like the template metaprogramming (MPL) and domain-specific language (DSL) creation (Proto).

In order to ensure efficiency and flexibility, Boost makes extensive use of templates. Boost has been a source of extensive work and research into generic programming and metaprogramming in C++.

Most Boost libraries are header based, consisting of inline functions and templates, and as such do not need to be built in advance of their use. Some Boost libraries coexist as independent libraries.

The original founders of Boost that are still active in the community include Beman Dawes and David Abrahams. Author of several books on C++, Nicolai Josuttis contributed to the Boost array library in 2001. There are mailing lists devoted to Boost library use and library development, active .

Boost is licensed under its own free, open-source license, known as the Boost Software License. It is a permissive license in the style of the BSD license and the MIT license, but without requiring attribution for redistribution in binary form. The license has been OSI-approved since February 2008 and is considered a free software license, compatible with the GNU General Public License, by the Free Software Foundation.




</doc>
<doc id="3634404" url="https://en.wikipedia.org/wiki?curid=3634404" title="New and delete (C++)">
New and delete (C++)

In the C++ programming language, and are a pair of language constructs that perform dynamic memory allocation, object construction and object destruction.

Except for a form called the "placement new", the operator denotes a request for memory allocation on a process's heap. If sufficient memory is available, initialises the memory, calling object constructors if necessary, and returns the address to the newly allocated and initialised memory. A request, in its simplest form, looks as follows:

where is a previously declared pointer of type (or some other type to which a pointer can be assigned, such as a superclass of ). The default constructor for , if any, is called to construct a instance in the allocated memory buffer.

If not enough memory is available in the free store for an object of type , the request indicates failure by throwing an exception of type . This removes the need to explicitly check the result of an allocation.

The deallocation counterpart of is , which first calls the destructor (if any) on its argument and then returns the memory allocated by back to the free store. Every call to must be matched by a call to ; failure to do so causes memory leaks. 

calls a single-argument constructor instead of the default constructor when initializing the newly allocated buffer.

A different variant allocates and initialises arrays of objects rather than single objects:
This requests a memory buffer from the free store that is large enough to hold a contiguous array of objects of type , contiguously, and calls the default constructor on each element of the array.

Memory allocated with the must be deallocated with the operator, rather than . Using the inappropriate form results in undefined behavior. C++ compilers are not required to generate a diagnostic message for using the wrong form.

The C++11 standard specifies an additional syntax,

that initializes each to .

If cannot find sufficient memory to service an allocation request, it can report its error in three distinct ways. Firstly, the ISO C++ standard allows programs to register a custom function called a with the C++ runtime; if it does, then this function is called whenever encounters an error. The may attempt to make more memory available, or terminate the program if it can't.

If no is installed, instead throws an exception of type . Thus, the program does not need to check the value of the returned pointer, as is the habit in C; if no exception was thrown, the allocation succeeded.

The third method of error handling is provided by the variant form , which specifies that no exception should be thrown; instead, a null pointer is returned to signal an allocation error.

The operator can be overloaded so that specific types (classes) use custom memory allocation algorithms for their instances. For example, the following is a variant of the singleton pattern where the first call allocates an instance and all subsequent calls return this same instance:

This feature was available from early on in C++'s history, although the specific overloading mechanism changed. It was added to the language because object-oriented C++ programs tended to allocate many small objects with , which internally used the C allocator (see ); that, however, was optimized for the fewer and larger allocations performed by typical C programs. Stroustrup reported that in early applications, the C function was "the most common performance bottleneck in real systems", with programs spending up to 50% of their time in this function.

The C++ language construct that only allocates memory is called void *operator new(size_t size). It is used by new in the allocation phase. It can be overridden per class or globally to define a specific memory allocator.

Since standard C++ subsumes the C standard library, the C dynamic memory allocation routines , , and are also available to C++ programmers. The use of these routines is discouraged for most uses, since they do not perform object initialization and destruction. and were, in fact, introduced in the first version of C++ (then called "C with Classes") to avoid the necessity of manual object initialization.

In contrast to the C routines, which allow growing or shrinking an allocated array with , it is not possible to change the size of a memory buffer allocated by . The C++ standard library instead provides a dynamic array that can be extended or reduced in its template class.

The C++ standard does not specify any relation between / and the C memory allocation routines, but and are typically implemented as wrappers around and . Mixing the two families of operations, e.g., 'ing 'ly allocated memory or 'ing 'd memory, causes undefined behavior and in practice can lead to various catastrophic results such as failure to release locks and thus deadlock.



</doc>
<doc id="29128470" url="https://en.wikipedia.org/wiki?curid=29128470" title="C++ Report">
C++ Report

C++ Report was a bi-monthly professional computer magazine published by SIGS Publications Group. It was edited by Robert Murray, Stanley B. Lippman, Douglas C. Schmidt, Brad Appleton, Robert Cecil Martin, and Herb Sutter and aimed to cover various issues related to C++ programming language. It was recognized as an important publication related to C++.



</doc>
<doc id="35256368" url="https://en.wikipedia.org/wiki?curid=35256368" title="Outline of C++">
Outline of C++

The following outline is provided as an overview of and topical guide to C++:

C++ is a statically typed, free-form, multi-paradigm, compiled, general-purpose programming language. It is regarded as an intermediate-level language, as it comprises a combination of both high-level and low-level language features. It was developed by Bjarne Stroustrup starting in 1979 at Bell Labs as an enhancement to the C language.

C++ can be described as all of the following:




The C++ standard library is a collection of utilities that are shipped with C++ for use by any C++ programmer.
It includes input and output, multi-threading, time, regular expressions, algorithms for common tasks, and less common ones (find, for_each, swap, etc.) and lists, maps and hash maps (and the equivalent for sets) and a class called vector that is a resizable array. Many other functions are provided by the standard library, but mainly in a form designed for building on top of to create third party libraries.







The C++ standardisation committee discourages dialects (with a preference that the problem is solved by new functionality in the standard library, as is done with items like multi-threading for parallel programming), however some dialects have been created, for various reasons (to remove features that are harder to implement, response to a programming trend, etc.):



</doc>
<doc id="20858004" url="https://en.wikipedia.org/wiki?curid=20858004" title="C++03">
C++03

C++03 is a version of an international standard for the programming language C++. It is defined by two standards organizations, the International Organization for Standardization (ISO) and the International Electrotechnical Commission (IEC), in standard ISO/IEC 14882:2003.

C++03 replaced the prior revision of the C++ standard, called C++98, and was later replaced by C++11. C++03 was primarily a bug fix release for the implementers to ensure greater consistency and portability. This revision addressed 92 core language defect reports, 125 library defect reports, and included only one new language feature: value initialization

Among the more noteworthy defect reports addressed by C++03 was the library defect report 69, whose resolution added the requirement that elements in a vector are stored contiguously. This codifies the common expectation that a C++ codice_1 object uses a memory layout similar to an array. While most implementations satisfied this expectation, it was not required by C++98.



</doc>
<doc id="42922" url="https://en.wikipedia.org/wiki?curid=42922" title="Comparison of Java and C++">
Comparison of Java and C++

This is a comparison of Java and C++, two prominent object-oriented programming languages.

The differences between the programming languages C++ and Java can be traced to their heritage, as they have different design goals.

C++ was designed for systems and applications programming ("i.e." infrastructure programming), extending the procedural programming language C, which was designed for efficient execution. To C, C++ added support for object-oriented programming, exception handling, lifetime-based resource management (RAII), generic programming, template metaprogramming, and the C++ Standard Library which includes generic containers and algorithms (the Standard Template Library or STL), and many other general purpose facilities.

Java is a general-purpose, concurrent, class-based, object-oriented programming language that is designed to minimize implementation dependencies. It relies on a Java virtual machine to be secure and highly portable. It is bundled with an extensive library designed to provide a full abstraction of the underlying platform. Java is a statically typed object-oriented language that uses a syntax similar to (but incompatible with) C++. It includes a documentation system called Javadoc.

The different goals in the development of C++ and Java resulted in different principles and design trade-offs between the languages. The differences are as follows:







Both C++ and Java provide facilities for generic programming, templates and generics, respectively. Although they were created to solve similar kinds of problems, and have similar syntax, they are quite different.


An example comparing and exists in Wikibooks.

In addition to running a compiled Java program, computers running Java applications generally must also run the Java virtual machine (JVM), while compiled C++ programs can be run without external applications. Early versions of Java were significantly outperformed by statically compiled languages such as C++. This is because the program statements of these two closely related languages may compile to a few machine instructions with C++, while compiling into several byte codes involving several machine instructions each when interpreted by a JVM. For example:
Since performance optimizing is a very complex issue, it is very difficult to quantify the performance difference between C++ and Java in general terms, and most benchmarks are unreliable and biased. Given the very different natures of the languages, definitive qualitative differences are also difficult to draw. In a nutshell, there are inherent inefficiencies and hard limits on optimizing in Java, given that it heavily relies on flexible high-level abstractions, however, the use of a powerful JIT compiler (as in modern JVM implementations) can mitigate some issues. In any case, if the inefficiencies of Java are too great, compiled C or C++ code can be called from Java via the JNI.

Some inefficiencies that are inherent to the Java language include, mainly:


However, there are a number of benefits to Java's design, some realized, some only theorized:


Also, some performance problems occur in C++:


The C++ language is defined by "ISO/IEC 14882", an ISO standard, which is published by the "ISO/IEC JTC1/SC22/WG21" committee. The latest, post-standardization draft of C++17 is available as well.

The C++ language evolves via an open steering committee called the C++ Standards Committee. The committee is composed of the creator of C++ Bjarne Stroustrup, the convener Herb Sutter, and other prominent figures, including many representatives of industries and user-groups (i.e., the stake-holders). Being an open committee, anyone is free to join, participate, and contribute proposals for upcoming releases of the standard and technical specifications. The committee now aims to release a new standard every few years, although in the past strict review processes and discussions have meant longer delays between publication of new standards (1998, 2003, and 2011).

The Java language is defined by the "Java Language Specification", a book which is published by Oracle.

The Java language continuously evolves via a process called the Java Community Process, and the world's programming community is represented by a group of people and organizations - the Java Community members—which is actively engaged into the enhancement of the language, by sending public requests - the Java Specification Requests - which must pass formal and public reviews before they get integrated into the language.

The lack of a firm standard for Java and the somewhat more volatile nature of its specifications have been a constant source of criticism by stake-holders wanting more stability and conservatism in the addition of new language and library features. In contrast, the C++ committee also receives constant criticism, for the opposite reason, i.e., being too strict and conservative, and taking too long to release new versions.

"C++" is not a trademark of any company or organization and is not owned by any individual.
"Java" is a trademark of Oracle Corporation.



</doc>
<doc id="384289" url="https://en.wikipedia.org/wiki?curid=384289" title="C dynamic memory allocation">
C dynamic memory allocation

C dynamic memory allocation refers to performing manual memory management for dynamic memory allocation in the C programming language via a group of functions in the C standard library, namely , , and .

The C++ programming language includes these functions; however, the operators and provide similar functionality and are recommended by that language's authors. Still, there are several situations in which using codice_1 is not applicable, such as garbage collection code or performance-sensitive code, and a combination of codice_2 and codice_3 may be required instead of the higher-level codice_4 operator.

Many different implementations of the actual memory allocation mechanism, used by , are available. Their performance varies in both execution time and required memory.

The C programming language manages memory statically, automatically, or dynamically. Static-duration variables are allocated in main memory, usually along with the executable code of the program, and persist for the lifetime of the program; automatic-duration variables are allocated on the stack and come and go as functions are called and return. For static-duration and automatic-duration variables, the size of the allocation must be compile-time constant (except for the case of variable-length automatic arrays). If the required size is not known until run-time (for example, if data of arbitrary size is being read from the user or from a disk file), then using fixed-size data objects is inadequate.

The lifetime of allocated memory can also cause concern. Neither static- nor automatic-duration memory is adequate for all situations. Automatic-allocated data cannot persist across multiple function calls, while static data persists for the life of the program whether it is needed or not. In many situations the programmer requires greater flexibility in managing the lifetime of allocated memory.

These limitations are avoided by using dynamic memory allocation, in which memory is more explicitly (but more flexibly) managed, typically by allocating it from the "free store" (informally called the "heap"), an area of memory structured for this purpose. In C, the library function codice_2 is used to allocate a block of memory on the heap. The program accesses this block of memory via a pointer that codice_2 returns. When the memory is no longer needed, the pointer is passed to codice_7 which deallocates the memory so that it can be used for other purposes.

The original description of C indicated that codice_8 and codice_9 were in the standard library, but not codice_2. Code for a simple model implementation of a storage manager for Unix was given with codice_11 and codice_7 as the user interface functions, and using the codice_13 system call to request memory from the operating system. The 6 Edition Unix documentation gives codice_11 and codice_7 as the low-level memory allocation functions. The codice_2 and codice_7 routines in their modern form are completely described in the 7 Edition Unix manual.

Some platforms provide library or intrinsic function calls which allow run-time dynamic allocation from the C stack rather than the heap (e.g. codice_18). This memory is automatically freed when the calling function ends.

The C dynamic memory allocation functions are defined in codice_19 header (codice_20 header in C++).


Creating an array of ten integers with automatic scope is straightforward in C:

However, the size of the array is fixed at compile time. If one wishes to allocate a similar array dynamically, the following code can be used:

This computes the number of bytes that ten integers occupy in memory, then requests that many bytes from codice_2 and assigns the result to a pointer named codice_29 (due to C syntax, pointers and arrays can be used interchangeably in some situations).

Because codice_2 might not be able to service the request, it might return a null pointer and it is good programming practice to check for this:

When the program no longer needs the dynamic array, it must eventually call codice_7 to return the memory it occupies to the free store:
The memory set aside by codice_2 is not initialized and may contain cruft: the remnants of previously used and discarded data. After allocation with codice_2, elements of the array are uninitialized variables. The command codice_8 will return an allocation that has already been cleared:
With realloc we can resize the amount of memory a pointer points to. For example, if we have a pointer acting as an array of size formula_1 and we want to change it to an array of size formula_2, we can use realloc.

Note that realloc must be assumed to have changed the base address of the block (i.e. if it has failed to extend the size of the original block, and has therefore allocated a new larger block elsewhere and copied the old contents into it). Therefore, any pointers to addresses within the original block are also no longer valid.

codice_2 returns a void pointer (codice_36), which indicates that it is a pointer to a region of unknown data type. The use of casting is required in C++ due to the strong type system, whereas this is not the case in C. One may "cast" (see type conversion) this pointer to a specific type:

There are advantages and disadvantages to performing such a cast.



The improper use of dynamic memory allocation can frequently be a source of bugs. These can include security bugs or program crashes, most often due to segmentation faults.

Most common errors are as follows:

In addition, as an interface that preceeds ANSI C standarization, and friends have behaviors that were intentionally left to the implementation to define for themselves. One of them is the zero-length allocation, which is more of a problem with since it is more common to resize to zero. Although both POSIX and the Single Unix Specification require proper handling of zero-size allocations by either returning or something else that can safely freed, not all platforms are required to abide by these rules. Among the many double-free errors that it has lead to, the 2019 WhatsApp RCE was especially prominent. A way to wrap these functions to make them safer is by simply checking for 0-size allocations and turning them into those of size 1. (Returning has its own problems: it otherwise indicates an out-of-memory failure. In the case of it would have signaled that the original memory was not moved and freed, which again is not the case for size 0, leading to the double-free.)

The implementation of memory management depends greatly upon operating system and architecture. Some operating systems supply an allocator for malloc, while others supply functions to control certain regions of data. The same dynamic memory allocator is often used to implement both codice_2 and the operator codice_4 in C++.

Implementation of the allocator is commonly done using the heap, or data segment. The allocator will usually expand and contract the heap to fulfill allocation requests.

The heap method suffers from a few inherent flaws, stemming entirely from fragmentation. Like any method of memory allocation, the heap will become fragmented; that is, there will be sections of used and unused memory in the allocated space on the heap. A good allocator will attempt to find an unused area of already allocated memory to use before resorting to expanding the heap. The major problem with this method is that the heap has only two significant attributes: base, or the beginning of the heap in virtual memory space; and length, or its size. The heap requires enough system memory to fill its entire length, and its base can never change. Thus, any large areas of unused memory are wasted. The heap can get "stuck" in this position if a small used segment exists at the end of the heap, which could waste any amount of address space. On lazy memory allocation schemes, such as those often found in the Linux operating system, a large heap does not necessarily reserve the equivalent system memory; it will only do so at the first write time (reads of non-mapped memory pages return zero). The granularity of this depends on page size.

Doug Lea has developed the public domain dlmalloc ("Doug Lea's Malloc") as a general-purpose allocator, starting in 1987. The GNU C library (glibc) is derived from Wolfram Gloger's ptmalloc ("pthreads malloc"), a fork of dlmalloc with threading-related improvements. As of November 2019, the latest version of dlmalloc is version 2.8.6 from August 2012.

dlmalloc is a boundary tag allocator. Memory on the heap is allocated as "chunks", an 8-byte aligned data structure which contains a header, and usable memory. Allocated memory contains an 8 or 16 byte overhead for the size of the chunk and usage flags. Unallocated chunks also store pointers to other free chunks in the usable space area, making the minimum chunk size 16 bytes on 32-bit systems and 24/32 (depends on alignment) bytes on 64-bit systems.

Unallocated memory is grouped into "bins" of similar sizes, implemented by using a double-linked list of chunks (with pointers stored in the unallocated space inside the chunk). Bins are sorted by size into three classes:


Game developer Adrian Stone argues that , as a boundary-tag allocator, is unfriendly for console systems that have virtual memory but does not have demand paging. This is because its pool-shrinking and growing callbacks (sysmalloc/systrim) cannot be used to allocate and commit individual pages of virtual memory. In the absence of demand paging, fragmentation becomes a greater concern.

Since FreeBSD 7.0 and NetBSD 5.0, the old codice_2 implementation (phkmalloc) was replaced by jemalloc, written by Jason Evans. The main reason for this was a lack of scalability of phkmalloc in terms of multithreading. In order to avoid lock contention, jemalloc uses separate "arenas" for each CPU. Experiments measuring number of allocations per second in multithreading application have shown that this makes it scale linearly with the number of threads, while for both phkmalloc and dlmalloc performance was inversely proportional to the number of threads.

OpenBSD's implementation of the codice_2 function makes use of mmap. For requests greater in size than one page, the entire allocation is retrieved using codice_60; smaller sizes are assigned from memory pools maintained by codice_2 within a number of "bucket pages," also allocated with codice_60. On a call to codice_7, memory is released and unmapped from the process address space using codice_64. This system is designed to improve security by taking advantage of the address space layout randomization and gap page features implemented as part of OpenBSD's codice_60 system call, and to detect use-after-free bugs—as a large memory allocation is completely unmapped after it is freed, further use causes a segmentation fault and termination of the program.

Hoard is an allocator whose goal is scalable memory allocation performance. Like OpenBSD's allocator, Hoard uses codice_60 exclusively, but manages memory in chunks of 64 kilobytes called superblocks. Hoard's heap is logically divided into a single global heap and a number of per-processor heaps. In addition, there is a thread-local cache that can hold a limited number of superblocks. By allocating only from superblocks on the local per-thread or per-processor heap, and moving mostly-empty superblocks to the global heap so they can be reused by other processors, Hoard keeps fragmentation low while achieving near linear scalability with the number of threads.

Every thread has a thread-local storage for small allocations. For large allocations mmap or sbrk can be used. TCMalloc, a "malloc" developed by Google, has garbage-collection for local storage of dead threads. The TCMalloc is considered to be more than twice as fast as glibc's ptmalloc for multithreaded programs.

Operating system kernels need to allocate memory just as application programs do. The implementation of codice_2 within a kernel often differs significantly from the implementations used by C libraries, however. For example, memory buffers might need to conform to special restrictions imposed by DMA, or the memory allocation function might be called from interrupt context. This necessitates a codice_2 implementation tightly integrated with the virtual memory subsystem of the operating system kernel.

Because codice_2 and its relatives can have a strong impact on the performance of a program, it is not uncommon to override the functions for a specific application by custom implementations that are optimized for application's allocation patterns. The C standard provides no way of doing this, but operating systems have found various ways to do this by exploiting dynamic linking. One way is to simply link in a different library to override the symbols. Another, employed by Unix System V.3, is to make codice_2 and codice_7 function pointers that an application can reset to custom functions.

The largest possible memory block codice_2 can allocate depends on the host system, particularly the size of physical memory and the operating system implementation. Theoretically, the largest number should be the maximum value that can be held in a codice_73 type, which is an implementation-dependent unsigned integer representing the size of an area of memory. In the C99 standard and later, it is available as the codice_74 constant from codice_75. Although not guaranteed by ISO C, it is usually .

The C library implementations shipping with various operating systems and compilers may come with alternatives and extensions to the standard codice_2 package. Notable among these is:





</doc>
<doc id="7983939" url="https://en.wikipedia.org/wiki?curid=7983939" title="Substitution failure is not an error">
Substitution failure is not an error

Substitution failure is not an error (SFINAE) refers to a situation in C++ where an invalid substitution of template parameters is not in itself an error. David Vandevoorde first introduced the acronym SFINAE to describe related programming techniques.

Specifically, when creating a candidate set for overload resolution, some (or all) candidates of that set may be the result of instantiated templates with (potentially deduced) template arguments substituted for the corresponding template parameters. If an error occurs during the substitution of a set of arguments for any given template, the compiler removes the potential overload from the candidate set instead of stopping with a compilation error, provided the substitution error is one the C++ standard grants such treatment. If one or more candidates remain and overload resolution succeeds, the invocation is well-formed.

The following example illustrates a basic instance of SFINAE:

Here, attempting to use a non-class type in a qualified name (codice_1) results in a deduction failure for codice_2 because codice_3 has no nested type named codice_4, but the program is well-formed because a valid function remains in the set of candidate functions.

Although SFINAE was initially introduced to avoid creating ill-formed programs when unrelated template declarations were visible (e.g., through the inclusion of a header file), many developers later found the behavior useful for compile-time introspection. Specifically, it allows a template to determine certain properties of its template arguments at instantiation time.

For example, SFINAE can be used to determine if a type contains a certain typedef:

When codice_5 has the nested type codice_6 defined, the instantiation of the first codice_7 works and the null pointer constant is successfully passed. (And the resulting type of the expression is codice_8.) If it does not work, the only available function is the second codice_7, and the resulting type of the expression is codice_10. An ellipsis is used not only because it will accept any argument, but also because its conversion rank is lowest, so a call to the first function will be preferred if it is possible; this removes ambiguity.

In C++11, the above code could be simplified to:

With the standardisation of the detection idiom in the Library fundamental v2 (n4562) proposal, the above code could be re-written as follows:

The developers of Boost used SFINAE in boost::enable_if and in other ways.


</doc>
<doc id="3893690" url="https://en.wikipedia.org/wiki?curid=3893690" title="Trait (computer programming)">
Trait (computer programming)

In computer programming, a trait is a concept used in object-oriented programming, which represents a set of methods that can be used to extend the functionality of a class.

Traits both provide a set of methods that implement behaviour to a class, and require that the class implement a set of methods that parameterize the provided behaviour.

For inter-object communication, traits are somewhat between an object-oriented protocol (interface) and a mixin. An interface may define one or more behaviors via method signatures, while a trait defines behaviors via full method definitions: i.e., it includes the body of the methods. In contrast, mixins include full method definitions and may also carry state through member variable, while traits usually don't.

Hence an object defined as a trait is created as the composition of methods, which can be used by other classes without requiring multiple inheritance. In case of a naming collision, when more than one trait to be used by a class has a method with the same name, the programmer must explicitly disambiguate which one of those methods will be used in the class; thus manually solving the "diamond problem" of multiple inheritance. This is different from other composition methods in object-oriented programming, where conflicting names are automatically resolved by scoping rules.

Whereas mixins can be composed only using the inheritance operation, traits offer a much wider selection of operations, including:

Traits are composed in the following ways:

Traits come originally from the programming language Self and are supported by the following programming languages:


On C# 8.0, it is possible to define an implementation as a member of an interface.
using System;

namespace CSharp8NewFeatures

This example uses a trait to enhance other classes:
This allows simulating aspects of multiple inheritance:
A trait in Rust declares a set of methods that a type must implement. Rust compilers require traits to be explicated, which ensures the safety of generics in Rust. It also helps to avoid major problems of templates in C++.
// type T must have the "Ord" trait
// so that ">" and "<" operations can be done
fn get_max<T: Ord>(a: &[T]) -> Option<&T> {

To simplify tedious and repeated implementation of traits like codice_3 and codice_4, codice_5 can be used to request compilers to generate certain implementations automatically. Derivable traits include: codice_6, codice_7, codice_3, codice_9, codice_10, codice_11, codice_12, codice_4 and codice_14.



</doc>
<doc id="34626879" url="https://en.wikipedia.org/wiki?curid=34626879" title="C++/CX">
C++/CX

C++/CX "(C++ component extensions)" is a language projection for Microsoft's Windows Runtime platform. It takes the form of a language extension for C++ compilers, and it enables C++ programmers to write programs that call Windows Runtime (WinRT) APIs. C++/CX is superseded by the C++/WinRT language projection, which is "not" an extension to the C++ language; rather, it's an entirely standard modern ISO C++17 header-file-based library.

The language extensions borrow syntax from C++/CLI but target the Windows Runtime Universal Windows Platform native code instead of the Common Language Runtime and managed code. It brings a set of syntax and library abstractions that project COM's WRL subset-based WinRT programming model in a way that is intuitive to C++/CLI managed extensions' coders.

It is possible to call the Windows Runtime from native ISO C++ via the lower level Windows Runtime C++ Template Library (WRL). However, WRL is also superseded by C++/WinRT.

C++/CX introduces syntax extensions for programming for the Windows Runtime. The overall non platform-specific syntax is compatible with the C++11 standard.

WinRT objects are created, or "activated", using codice_1 and assigned to variables declared with the codice_2 (hat) notation inherited from C++/CLI.
A WinRT variable is simply a pair of a pointer to virtual method table and pointer to the object's internal data.

A WinRT object is reference counted and thus handles similarly to ordinary C++ objects enclosed in shared_ptrs. An object will be deleted when there are no remaining references that lead to it.

There is no garbage collection involved. Nevertheless, the keyword codice_3 has been reserved for possible future use.

There are special kinds of "runtime classes" that may contain component extension constructs. These are simply referred to as "ref classes" because they are declared using codice_4.
C++/CX introduces the concept of partial classes. The feature allows a single class definition to be split across multiple files, mainly to enable the XAML graphical user interface design tools to auto-generate code in a separate file in order not to break the logic written by the developer. The parts are later merged at compilation.

.NET languages like C# have had this feature for many years. Partial classes have not yet made it into the C++ standard and cannot therefore be used in pure C++11.

A file that is generated and updated by the GUI-designer, and thus should not be modified by the programmer. Note the keyword codice_5.
The file where the programmer writes user-interface logic. The header in which the compiler-generated part of the class is defined is imported. Note that the keyword codice_5 is not necessary.
This is the file in which the members of the partial class are implemented. 
Windows Runtime and thus C++/CX supports runtime-based generics. Generic type information is contained in the metadata and instantiated at runtime, unlike C++ templates which are compile-time constructs. Both are supported by the compiler and can be combined.
All WinRT programs expose their declared classes and members through metadata. The format is the same that was standardized as part of the Common Language Infrastructure (CLI), the standard created from the .NET Framework. Because of this, code can be shared across C++/CX, CLI languages, and JavaScript that target Windows Runtime.

The C++/CX has a set of libraries that target the Windows Runtime. These help bridge the functionality of the C++ Standard Library and WinRT.

You can detect if C++/CX extension is turned on by testing existence of codice_7 preprocessor symbol.




</doc>
<doc id="35281326" url="https://en.wikipedia.org/wiki?curid=35281326" title="Input/output (C++)">
Input/output (C++)

In the C++ programming language, input/output library refers to a family of class templates and supporting functions in the C++ Standard Library that implement stream-based input/output capabilities. It is an object-oriented alternative to C's FILE-based streams from the C standard library.

Bjarne Stroustrup, the creator of C++, wrote the first version of the stream I/O library in 1984, as a type-safe and extensible alternative to C's I/O library. The library has undergone a number of enhancements since this early version, including the introduction of manipulators to control formatting, and templatization to allow its use with character types other than codice_1.

Standardization in 1998 saw the library moved into the codice_2 namespace, and the main header changed from codice_3 to codice_4. It is this standardized version that is covered in the rest of the article.

Most of the classes in the library are actually very generalized class templates. Each template can operate on various character types, and even the operations themselves, such as how two characters are compared for equality, can be customized. However, the majority of code needs to do input and output operations using only one or two character types, thus most of the time the functionality is accessed through several typedefs, which specify names for commonly used combinations of template and character type.

For example, codice_5 refers to the generic class template that implements input/output operations on file streams. It is usually used as codice_6 which is an alias for codice_7, or, in other words, codice_8 working on characters of type codice_1 with the default character operation set.

The classes in the library could be divided into roughly two categories: abstractions and implementations. Classes, that fall into abstractions category, provide an interface which is sufficient for working with any type of a stream. The code using such classes doesn't depend on the exact location the data is read from or is written to. For example, such code could write data to a file, a memory buffer or a web socket without a recompilation. The implementation classes inherit the abstraction classes and provide an implementation for concrete type of data source or sink. The library provides implementations only for file-based streams and memory buffer-based streams.

The classes in the library could also be divided into two groups by whether it implements low-level or high-level operations. The classes that deal with low-level stuff are called stream buffers. They operate on characters without providing any formatting functionality. These classes are very rarely used directly. The high-level classes are called streams and provide various formatting capabilities. They are built on top of stream buffers.

The following table lists and categorizes all classes provided by the input-output library.

The classes of the input/output library reside in several headers.

There are twelve stream buffer classes defined in the C++ language as the table.

codice_11 and codice_12 are two classes that manage the lower-level bits of a stream. codice_11 stores formatting information and the state of the stream. codice_12 manages the associated stream-buffer. codice_12 is commonly known as simply codice_37 or codice_38, which are two typedefs for codice_12 with a specific character type. codice_12 and codice_11 are very rarely used directly by programmers. Usually, their functionality is accessed through other classes such as codice_42 which inherit them.

C++ input/output streams are primarily defined by codice_42, a header file that is part of the C++ standard library (the name stands for Input/Output Stream). In C++ and its predecessor, the C programming language, there is no special syntax for streaming data input or output. Instead, these are combined as a library of functions. Like the codice_44 header inherited from C's stdio.h, codice_42 provides basic input and output services for C++ programs. iostream uses the objects codice_46, codice_47, codice_48, and codice_49 for sending data to and from the standard streams input, output, error (unbuffered), and log (buffered) respectively. As part of the C++ standard library, these objects are a part of the codice_2 namespace.

The codice_47 object is of type codice_52, which overloads the left bit-shift operator to make it perform an operation completely unrelated to bitwise operations, and notably evaluate to the value of the left argument, allowing multiple operations on the same ostream object, essentially as a different syntax for method cascading, exposing a fluent interface. The codice_48 and codice_49 objects are also of type codice_52, so they overload that operator as well. The codice_46 object is of type codice_57, which overloads the right bit-shift operator. The directions of the bit-shift operators make it seem as though data is flowing towards the output stream or flowing away from the input stream.

Manipulators are objects that can modify a stream using the codice_58 or codice_59 operators.

Other manipulators can be found using the header codice_60.

Some environments do not provide a shared implementation of the C++ library. These include embedded systems and Windows systems running programs built with MinGW. Under these systems, the C++ standard library must be statically linked to a program, which increases the size of the program, or distributed as a shared library alongside the program.
Some implementations of the C++ standard library have significant amounts of dead code. For example, GNU libstdc++ automatically constructs a locale when building an codice_52 even if a program never uses any types (date, time or money) that a locale affects,
and a statically linked "Hello, World!" program that uses codice_4 of GNU libstdc++ produces an executable an order of magnitude larger than an equivalent program that uses codice_63.

There exist partial implementations of the C++ standard library designed for space-constrained environments; their codice_4 may leave out features that programs in such environments may not need, such as locale support.

The canonical "Hello, World!" program can be expressed as follows:
This program would output "Hello, world!" followed by a newline and standard output stream buffer flush.

The following example creates a file called 'file.txt' and puts the text 'Hello, world!' followed by a newline into it.



</doc>
<doc id="5195468" url="https://en.wikipedia.org/wiki?curid=5195468" title="Exception safety">
Exception safety

Exception safety guarantees, originally formalized by David Abrahams, are a set of contractual guidelines that class library implementers and clients can use when reasoning about exception handling safety in any programming language that uses exceptions, particularly C++.

There are several levels of exception safety (in decreasing order of safety):

Usually, at least basic exception safety is required to write robust code in such languages. Higher levels of safety can sometimes be difficult to achieve, and might incur an overhead due to extra copying. A key mechanism for exception safety is a codice_1 clause, or similar exception handling syntax, which ensure that certain code is "always" run when a block is exited, including by exceptions. Several languages have constructs that simplify this, notably using the dispose pattern, named as codice_2, codice_3, or codice_4-with-resources.

Consider a smart vector type, such as C++'s or Java's . When an item is added to a vector , the vector must actually add to the internal list of objects and update a count field that says how many objects are in . It may also need to allocate new memory if the existing capacity isn't sufficient.

Exception safety alternatives:



</doc>
<doc id="5481447" url="https://en.wikipedia.org/wiki?curid=5481447" title="C++11">
C++11

C++11 is a version of the standard for the programming language C++. It was approved by International Organization for Standardization (ISO) on 12 August 2011, replacing C++03, superseded by C++14 on 18 August 2014 and later, by C++17. The name follows the tradition of naming language versions by the publication year of the specification, though it was formerly named "C++0x" because it was expected to be published before 2010.

Although one of the design goals was to prefer changes to the libraries over changes to the core language, C++11 does make several additions to the core language. Areas of the core language that were significantly improved include multithreading support, generic programming support, uniform initialization, and performance. Significant changes were also made to the C++ Standard Library, incorporating most of the C++ Technical Report 1 (TR1) libraries, except the library of mathematical special functions.

C++11 was published as "ISO/IEC 14882:2011" in September 2011 and is available for a fee. The working draft most similar to the published C++11 standard is N3337, dated 16 January 2012; it has only editorial corrections from the C++11 standard.

The design committee attempted to stick to a number of goals in designing C++11:

Attention to beginners is considered important, because most computer programmers will always be such, and because many beginners never widen their knowledge, limiting themselves to work in aspects of the language in which they specialize.

One function of the C++ committee is the development of the language core. Areas of the core language that were significantly improved include multithreading support, generic programming support, uniform initialization, and performance.

These language features primarily exist to provide some kind of performance benefit, either of memory or of computational speed.

In C++03 (and before), temporaries (termed "rvalues", as they often lie on the right side of an assignment) were intended to never be modifiable — just as in C — and were considered to be indistinguishable from codice_1 types; nevertheless, in some cases, temporaries could have been modified, a behavior that was even considered to be a useful loophole. C++11 adds a new non-const reference type called an , identified by codice_2. This refers to temporaries that are permitted to be modified after they are initialized, for the purpose of allowing "move semantics".

A chronic performance problem with C++03 is the costly and unneeded deep copies that can happen implicitly when objects are passed by value. To illustrate the issue, consider that an codice_3 is, internally, a wrapper around a C-style array with a defined size. If an codice_3 temporary is created or returned from a function, it can be stored only by creating a new codice_3 and copying all the rvalue's data into it. Then the temporary and all its memory is destroyed. (For simplicity, this discussion neglects the return value optimization.)

In C++11, a of codice_3 that takes an rvalue reference to an codice_3 can copy the pointer to the internal C-style array out of the rvalue into the new codice_3, then set the pointer inside the rvalue to null. Since the temporary will never again be used, no code will try to access the null pointer, and because the pointer is null, its memory is not deleted when it goes out of scope. Hence, the operation not only forgoes the expense of a deep copy, but is safe and invisible.

Rvalue references can provide performance benefits to existing code without needing to make any changes outside the standard library. The type of the returned value of a function returning an codice_3 temporary does not need to be changed explicitly to codice_10 to invoke the move constructor, as temporaries are considered rvalues automatically. (However, if codice_3 is a C++03 version without a move constructor, then the copy constructor will be invoked with an codice_12, incurring a significant memory allocation.)

For safety reasons, some restrictions are imposed. A named variable will never be considered to be an rvalue even if it is declared as such. To get an rvalue, the function template codice_13 should be used. Rvalue references can also be modified only under certain circumstances, being intended to be used primarily with move constructors.

Due to the nature of the wording of rvalue references, and to some modification to the wording for lvalue references (regular references), rvalue references allow developers to provide perfect function forwarding. When combined with variadic templates, this ability allows for function templates that can perfectly forward arguments to another function that takes those particular arguments. This is most useful for forwarding constructor parameters, to create factory functions that will automatically call the correct constructor for those particular arguments. This is seen in the emplace_back set of the C++ standard library methods.

C++ has always had the concept of constant expressions. These are expressions such as codice_14 that will always yield the same results, at compile time and at run time. Constant expressions are optimization opportunities for compilers, and compilers frequently execute them at compile time and hardcode the results in the program. Also, in several places, the C++ specification requires using constant expressions. Defining an array requires a constant expression, and enumerator values must be constant expressions.

However, a constant expression has never been allowed to contain a function call or object constructor. So a piece of code as simple as this is invalid:

This was not valid in C++03, because codice_15 is not a constant expression. A C++03 compiler has no way of knowing if codice_16 actually is constant at runtime. In theory, this function could affect a global variable, call other non-runtime constant functions, etc.

C++11 introduced the keyword codice_17, which allows the user to guarantee that a function or object constructor is a compile-time constant. The above example can be rewritten as follows:

This allows the compiler to understand, and verify, that codice_16 is a compile-time constant.

Using codice_17 on a function imposes some limits on what that function can do. First, the function must have a non-void return type. Second, the function body cannot declare variables or define new types. Third, the body may contain only declarations, null statements and a single return statement. There must exist argument values such that, after argument substitution, the expression in the return statement produces a constant expression.

Before C++11, the values of variables could be used in constant expressions only if the variables are declared const, have an initializer which is a constant expression, and are of integral or enumeration type. C++11 removes the restriction that the variables must be of integral or enumeration type if they are defined with the codice_17 keyword:

Such data variables are implicitly const, and must have an initializer which must be a constant expression.

To construct constant expression data values from user-defined types, constructors can also be declared with codice_17. A codice_17 constructor's function body can contain only declarations and null statements, and cannot declare variables or define types, as with a codice_17 function. There must exist argument values such that, after argument substitution, it initializes the class's members with constant expressions. The destructors for such types must be trivial.

The copy constructor for a type with any codice_17 constructors should usually also be defined as a codice_17 constructor, to allow objects of the type to be returned by value from a constexpr function. Any member function of a class, such as copy constructors, operator overloads, etc., can be declared as codice_17, so long as they meet the requirements for constexpr functions. This allows the compiler to copy objects at compile time, perform operations on them, etc.

If a constexpr function or constructor is called with arguments which aren't constant expressions, the call behaves as if the function were not constexpr, and the resulting value is not a constant expression. Likewise, if the expression in the return statement of a constexpr function does not evaluate to a constant expression for a given invocation, the result is not a constant expression.

In C++03, a class or struct must follow a number of rules for it to be considered a plain old data (POD) type. Types that fit this definition produce object layouts that are compatible with C, and they could also be initialized statically. The C++03 standard has restrictions on what types are compatible with C or can be statically initialized despite there being no technical reason a compiler couldn't accept the program; if someone were to create a C++03 POD type and add a non-virtual member function, this type would no longer be a POD type, could not be statically initialized, and would be incompatible with C despite no change to the memory layout.

C++11 relaxed several of the POD rules, by dividing the POD concept into two separate concepts: "trivial" and "standard-layout".

A type that is "trivial" can be statically initialized. It also means that it is valid to copy data around via codice_27, rather than having to use a copy constructor. The lifetime of a "trivial" type begins when its storage is defined, not when a constructor completes.

A trivial class or struct is defined as one that:


Constructors are trivial only if there are no virtual member functions of the class and no virtual base classes. Copy/move operations also require all non-static data members to be trivial.

A type that is "standard-layout" means that it orders and packs its members in a way that is compatible with C. A class or struct is standard-layout, by definition, provided:


A class/struct/union is considered POD if it is trivial, standard-layout, and all of its non-static data members and base classes are PODs.

By separating these concepts, it becomes possible to give up one without losing the other. A class with complex move and copy constructors may not be trivial, but it could be standard-layout and thus interoperate with C. Similarly, a class with public and private non-static data members would not be standard-layout, but it could be trivial and thus codice_27-able.

In C++03, the compiler must instantiate a template whenever a fully specified template is encountered in a translation unit. If the template is instantiated with the same types in many translation units, this can dramatically increase compile times. There is no way to prevent this in C++03, so C++11 introduced extern template declarations, analogous to extern data declarations.

C++03 has this syntax to oblige the compiler to instantiate a template:

C++11 now provides this syntax:

which tells the compiler "not" to instantiate the template in this translation unit.

These features exist for the primary purpose of making the language easier to use. These can improve type safety, minimize code repetition, make erroneous code less likely, etc.

C++03 inherited the initializer-list feature from C. A struct or array is given a list of arguments in braces, in the order of the members' definitions in the struct. These initializer-lists are recursive, so an array of structs or struct containing other structs can use them.

This is very useful for static lists, or initializing a struct to some value. C++ also provides constructors to initialize an object, but they are often not as convenient as the initializer list. However, C++03 allows initializer-lists only on structs and classes that conform to the Plain Old Data (POD) definition; C++11 extends initializer-lists, so they can be used for all classes including standard containers like codice_30.

C++11 binds the concept to a template, called codice_31. This allows constructors and other functions to take initializer-lists as parameters. For example:

This allows codice_32 to be constructed from a sequence of integers, such as:

This constructor is a special kind of constructor, called an initializer-list-constructor. Classes with such a constructor are treated specially during uniform initialization (see below)

The template class codice_33 is a first-class C++11 standard library type. They can be constructed statically by the C++11 compiler via use of the codice_34 syntax without a type name in contexts where such braces will deduce to an codice_31, or by explicitly specifying the type like codice_36 (and so on for other varieties of construction syntax).

The list can be copied once constructed, which is cheap and will act as a copy-by-reference (the class is typically implemented as a pair of begin/end pointers). An codice_31 is constant: its members cannot be changed once it is created, and nor can the data in those members be changed (which rules out moving from them, requiring copies into class members, etc.).

Although its construction is specially treated by the compiler, an codice_31 is a real type, and so it can be used in other places besides class constructors. Regular functions can take typed codice_31s as arguments. For example:

Examples of this in the standard library include the codice_40 and codice_41 templates taking codice_31s of numeric type.

Standard containers can also be initialized in these ways:
C++03 has a number of problems with initializing types. Several ways to do this exist, and some produce different results when interchanged. The traditional constructor syntax, for example, can look like a function declaration, and steps must be taken to ensure that the compiler's most vexing parse rule will not mistake it for such. Only aggregates and POD types can be initialized with aggregate initializers (using codice_43).

C++11 provides a syntax that allows for fully uniform type initialization that works on any object. It expands on the initializer list syntax:

The initialization of codice_44 behaves exactly as though it were aggregate-initialization. That is, each data member of an object, in turn, will be copy-initialized with the corresponding value from the initializer-list. Implicit type conversion will be used where needed. If no conversion exists, or only a narrowing conversion exists, the program is ill-formed. The initialization of codice_45 invokes the constructor.

One can also do this:

Uniform initialization does not replace constructor syntax, which is still needed at times. If a class has an initializer list constructor (codice_46), then it takes priority over other forms of construction, provided that the initializer list conforms to the sequence constructor's type. The C++11 version of codice_30 has an initializer list constructor for its template type. Thus this code:

will call the initializer list constructor, not the constructor of codice_30 that takes a single size parameter and creates the vector with that size. To access the latter constructor, the user will need to use the standard constructor syntax directly.

In C++03 (and C), to use a variable, its type must be specified explicitly. However, with the advent of template types and template metaprogramming techniques, the type of something, particularly the well-defined return value of a function, may not be easily expressed. Thus, storing intermediates in variables is difficult, possibly needing knowledge of the internals of a given metaprogramming library.

C++11 allows this to be mitigated in two ways. First, the definition of a variable with an explicit initialization can use the codice_49 keyword. This creates a variable of the specific type of the initializer:

The type of codice_50 is simply whatever the particular template function override of codice_51 returns for those particular arguments. This type is easily determined procedurally by the compiler as part of its semantic analysis duties, but is not easy for the user to determine upon inspection.
The type of codice_52 is also well-defined, but it is easier for the user to determine. It is an codice_53, which is the same type as the integer literal.

This use of the keyword codice_49 in C++ re-purposes the semantics of this keyword, which was originally used in the typeless predecessor language B in a related role of denoting an untyped automatic variable definition.

Further, the keyword codice_55 can be used to determine the type of expression at compile-time. For example:

This is more useful in conjunction with codice_49, since the type of auto variable is known only to the compiler. However, codice_55 can also be very useful for expressions in code that makes heavy use of operator overloading and specialized types.

codice_49 is also useful for reducing the verbosity of the code. For instance, instead of writing

the programmer can use the shorter

which can be further compacted since "myvec" implements begin/end iterators:
This difference grows as the programmer begins to nest containers, though in such cases codice_59s are a good way to decrease the amount of code.

The type denoted by codice_55 can be different from the type deduced by codice_49.
C++11 extends the syntax of the codice_62 statement to allow for easy iteration over a range of elements:

This form of codice_62, called the “range-based for”, will iterate over each element in the list. It will work for C-style arrays, initializer lists, and any type that has codice_64 and codice_65 functions defined for it that return iterators. All the standard library containers that have begin/end pairs will work with the range-based for statement.

C++11 provides the ability to create anonymous functions, called lambda functions.
These are defined as follows:

The return type (codice_66 in this example) can be omitted as long as all codice_67 expressions return the same type.
A lambda can optionally be a closure.

Standard C function declaration syntax was perfectly adequate for the feature set of the C language. As C++ evolved from C, it kept the basic syntax and extended it where needed. However, as C++ grew more complex, it exposed several limits, especially regarding template function declarations. For example, in C++03 this is disallowed:

The type codice_68 is whatever the addition of types codice_69 and codice_70 will produce. Even with the aforementioned C++11 functionality of codice_55, this is not possible:

This is not valid C++ because codice_72 and codice_73 have not yet been defined; they will not be valid identifiers until after the parser has parsed the rest of the function prototype.

To work around this, C++11 introduced a new function declaration syntax, with a "trailing-return-type":

This syntax can be used for more mundane function declarations and definitions:

Use of the keyword “auto” in this case is only part of the syntax and does not perform automatic type deduction.

In C++03, constructors of a class are not allowed to call other constructors in an initializer list of that class. Each constructor must construct all of its class members itself or call a common member function, as follows:

Constructors for base classes cannot be directly exposed to derived classes; each derived class must implement constructors even if a base class constructor would be appropriate. Non-constant data members of classes cannot be initialized at the site of the declaration of those members. They can be initialized only in a constructor.

C++11 provides solutions to all of these problems.

C++11 allows constructors to call other peer constructors (termed delegation). This allows constructors to utilize another constructor's behavior with a minimum of added code. Delegation has been used in other languages e.g., Java, Objective-C.

This syntax is as follows:

Notice that, in this case, the same effect could have been achieved by making codice_74 a defaulting parameter. The new syntax, however, allows the default value (42) to be expressed in the implementation rather than the interface — a benefit to maintainers of library code since default values for function parameters are “baked in” to call sites, whereas constructor delegation allows the value to be changed without recompilation of the code using the library.

This comes with a caveat: C++03 considers an object to be constructed when its constructor finishes executing, but C++11 considers an object constructed once "any" constructor finishes execution. Since multiple constructors will be allowed to execute, this will mean that each delegating constructor will be executing on a fully constructed object of its own type. Derived class constructors will execute after all delegation in their base classes is complete.

For base-class constructors, C++11 allows a class to specify that base class constructors will be inherited. Thus, the C++11 compiler will generate code to perform the inheritance and the forwarding of the derived class to the base class. This is an all-or-nothing feature: either all of that base class's constructors are forwarded or none of them are. Also, an inherited constructor will be shadowed if it matches the signature of a constructor of the derived class, and restrictions exist for multiple inheritance: class constructors cannot be inherited from two classes that use constructors with the same signature.

The syntax is as follows:

For member initialization, C++11 allows this syntax:

Any constructor of the class will initialize codice_75 with 5, if the constructor does not override the initialization with its own. So the above empty constructor will initialize codice_75 as the class definition states, but the constructor that takes an int will initialize it to the given parameter.

It can also use constructor or uniform initialization, instead of the assignment initialization shown above.

In C++03, it is possible to accidentally create a new virtual function, when one intended to override a base class function. For example:

Suppose the codice_77 is intended to replace the base class version. But instead, because it has a different signature, it creates a second virtual function. This is a common problem, particularly when a user goes to modify the base class.

C++11 provides syntax to solve this problem.

The codice_78 special identifier means that the compiler will check the base class(es) to see if there is a virtual function with this exact signature. And if there is not, the compiler will indicate an error.

C++11 also adds the ability to prevent inheriting from classes or simply preventing overriding methods in derived classes. This is done with the special identifier codice_79. For example:

In this example, the codice_80 statement declares a new virtual function, but it also prevents derived classes from overriding it. It also has the effect of preventing derived classes from using that particular function name and parameter combination.

Note that neither codice_78 nor codice_79 are language keywords. They are technically identifiers for declarator attributes:

For the purposes of this section and this section alone, every occurrence of “codice_83” is meant as “a constant expression which evaluates to codice_83, which is of type int”. In reality, the constant expression can be of any integral type.

Since the dawn of C in 1972, the constant codice_83 has had the double role of constant integer and null pointer constant. The ambiguity inherent in the double meaning of codice_83 was dealt with in C by using the preprocessor macro codice_87, which commonly expands to either codice_88 or codice_83. C++ forbids implicit conversion from codice_90 to other pointer types, thus removing the benefit of casting codice_83 to codice_90. As a consequence, only codice_83 is allowed as a null pointer constant. This interacts poorly with function overloading:

If codice_87 is defined as codice_83 (which is usually the case in C++), the statement codice_96 will call codice_97, which is almost certainly not what the programmer intended, and not what a superficial reading of the code suggests.

C++11 corrects this by introducing a new keyword to serve as a distinguished null pointer constant: codice_98. It is of type codice_99, which is implicitly convertible and comparable to any pointer type or pointer-to-member type. It is not implicitly convertible or comparable to integral types, except for codice_100. While the original proposal specified that an rvalue of type codice_99 should not be convertible to codice_100, the core language working group decided that such a conversion would be desirable, for consistency with regular pointer types. The proposed wording changes were unanimously voted into the Working Paper in June 2008.

For backwards compatibility reasons, codice_83 remains a valid null pointer constant.

In C++03, enumerations are not type-safe. They are effectively integers, even when the enumeration types are distinct. This allows the comparison between two enum values of different enumeration types. The only safety that C++03 provides is that an integer or a value of one enum type does not convert implicitly to another enum type. Further, the underlying integral type is implementation-defined; code that depends on the size of the enumeration is thus non-portable. Lastly, enumeration values are scoped to the enclosing scope. Thus, it is not possible for two separate enumerations in the same scope to have matching member names.

C++11 allows a special classification of enumeration that has none of these issues. This is expressed using the codice_104 (codice_105 is also accepted as a synonym) declaration:

This enumeration is type-safe. Enum class values are not implicitly converted to integers. Thus, they cannot be compared to integers either (the expression codice_106 gives a compile error).

The underlying type of enum classes is always known. The default type is codice_53; this can be overridden to a different integral type as can be seen in this example:

With old-style enumerations the values are placed in the outer scope. With new-style enumerations they are placed within the scope of the enum class name. So in the above example, codice_108 is undefined, but codice_109 is defined.

There is also a transitional syntax to allow old-style enumerations to provide explicit scoping, and the definition of the underlying type:

In this case the enumerator names are defined in the enumeration's scope (codice_110), but for backwards compatibility they are also placed in the enclosing scope.

Forward-declaring enums is also possible in C++11. Formerly, enum types could not be forward-declared because the size of the enumeration depends on the definition of its members. As long as the size of the enumeration is specified either implicitly or explicitly, it can be forward-declared:

C++03's parser defines “codice_111” as the right shift operator or stream extraction operator in all cases. However, with nested template declarations, there is a tendency for the programmer to neglect to place a space between the two right angle brackets, thus causing a compiler syntax error.

C++11 improves the specification of the parser so that multiple right angle brackets will be interpreted as closing the template argument list where it is reasonable. This can be overridden by using parentheses around parameter expressions using the “codice_112”, “codice_113” or “codice_111” binary operators:

C++98 added the codice_115 keyword as a modifier on constructors to prevent single-argument constructors from being used as implicit type conversion operators. However, this does nothing for actual conversion operators. For example, a smart pointer class may have an codice_116 to allow it to act more like a primitive pointer: if it includes this conversion, it can be tested with codice_117 (which would be true if the pointer was non-null and false otherwise). However, this allows other, unintended conversions as well. Because C++ codice_100 is defined as an arithmetic type, it can be implicitly converted to integral or even floating-point types, which allows for mathematical operations that are not intended by the user.

In C++11, the codice_115 keyword can now be applied to conversion operators. As with constructors, it prevents using those conversion functions in implicit conversions. However, language contexts that specifically need a boolean value (the conditions of if-statements and loops, and operands to the logical operators) count as explicit conversions and can thus use a bool conversion operator.

For example, this feature solves cleanly the issue.

In C++03, it is possible to define a typedef only as a synonym for another type, including a synonym for a template specialization with all actual template arguments specified. It is not possible to create a typedef template. For example:

This will not compile.

C++11 adds this ability with this syntax:

The codice_120 syntax can also be used as type aliasing in C++11:
In C++03, there are restrictions on what types of objects can be members of a codice_121. For example, unions cannot contain any objects that define a non-trivial constructor or destructor. C++11 lifts some of these restrictions.

If a codice_121 member has a non trivial special member function, the compiler will not generate the equivalent member function for the codice_121 and it must be manually defined.

This is a simple example of a union permitted in C++11:
The changes will not break any existing code since they only relax current rules.

These features allow the language to do things that were formerly impossible, exceedingly verbose, or needed non-portable libraries.

In C++11, templates can take variable numbers of template parameters. This also allows the definition of type-safe variadic functions.

C++03 offers two kinds of string literals. The first kind, contained within double quotes, produces a null-terminated array of type codice_124. The second kind, defined as codice_125, produces a null-terminated array of type codice_126, where codice_127 is a wide-character of undefined size and semantics. Neither literal type offers support for string literals with UTF-8, UTF-16, or any other kind of Unicode encodings.

The definition of the type codice_128 has been modified to explicitly express that it's at least the size needed to store an eight-bit coding of UTF-8, and large enough to contain any member of the compiler's basic execution character set. It was formerly defined as only the latter in the C++ standard itself, then relying on the C standard to guarantee at least 8 bits.

C++11 supports three Unicode encodings: UTF-8, UTF-16, and UTF-32. Along with the formerly noted changes to the definition of codice_128, C++11 adds two new character types: codice_130 and codice_131. These are designed to store UTF-16 and UTF-32 respectively.

Creating string literals for each of these encodings can be done thusly:

The type of the first string is the usual codice_132. The type of the second string is codice_133 (note lower case 'u' prefix). The type of the third string is codice_134 (upper case 'U' prefix).

When building Unicode string literals, it is often useful to insert Unicode code points directly into the string. To do this, C++11 allows this syntax:

The number after the codice_135 is a hexadecimal number; it does not need the usual codice_136 prefix. The identifier codice_135 represents a 16-bit Unicode code point; to enter a 32-bit code point, use codice_138 and a 32-bit hexadecimal number. Only valid Unicode code points can be entered. For example, code points on the range U+D800–U+DFFF are forbidden, as they are reserved for surrogate pairs in UTF-16 encodings.

It is also sometimes useful to avoid escaping strings manually, particularly for using literals of XML files, scripting languages, or regular expressions. C++11 provides a raw string literal:

In the first case, everything between the codice_139 and the codice_140 is part of the string. The codice_141 and codice_142 characters do not need to be escaped. In the second case, the codice_143 starts the string, and it ends only when codice_144 is reached. The string codice_145 can be any string up to 16 characters in length, including the empty string. This string cannot contain spaces, control characters, codice_146, codice_147, or the codice_142 character. Using this delimiter string allows the user to have codice_147 characters within raw string literals. For example, codice_150 is equivalent to codice_151.

Raw string literals can be combined with the wide literal or any of the Unicode literal prefixes:

C++03 provides a number of literals. The characters codice_152 are a literal that is resolved by the compiler as a type codice_153 with the value of 12.5. However, the addition of the suffix codice_154, as in codice_155, creates a value of type codice_156 that contains the value 12.5. The suffix modifiers for literals are fixed by the C++ specification, and C++03 code cannot create new literal modifiers.

By contrast, C++11 enables the user to define new kinds of literal modifiers that will construct objects based on the string of characters that the literal modifies.

Transformation of literals is redefined into two distinct phases: raw and cooked. A raw literal is a sequence of characters of some specific type, while the cooked literal is of a separate type. The C++ literal codice_157, as a raw literal, is this sequence of characters codice_158, codice_159, codice_160, codice_161. As a cooked literal, it is the integer 1234. The C++ literal codice_162 in raw form is codice_163, codice_164, codice_165, while in cooked form it is the integer 10.

Literals can be extended in both raw and cooked forms, with the exception of string literals, which can be processed only in cooked form. This exception is due to the fact that strings have prefixes that affect the specific meaning and type of the characters in question.

All user-defined literals are suffixes; defining prefix literals is not possible. All suffixes starting with any character except underscore (codice_166) are reserved by the standard. Thus, all user-defined literals must have suffixes starting with an underscore (codice_166).

User-defined literals processing the raw form of the literal are defined via a literal operator, which is written as codice_168. An example follows:

The assignment statement codice_169 executes the code defined by the user-defined literal function. This function is passed codice_170 as a C-style string, so it has a null terminator.

An alternative mechanism for processing integer and floating point raw literals is via a variadic template:

This instantiates the literal processing function as codice_171. In this form, there is no null character terminating the string. The main purpose for doing this is to use C++11's codice_17 keyword to ensure that the compiler will transform the literal entirely at compile time, assuming codice_173 is a constexpr-constructible and copyable type, and the literal processing function is a codice_17 function.

For numeric literals, the type of the cooked literal is either codice_175 for integral literals or codice_176 for floating point literals. (Note: There is no need for signed integral types because a sign-prefixed literal is parsed as an expression containing the sign as a unary prefix operator and the unsigned number.) There is no alternative template form:

In accord with the formerly mentioned new string prefixes, for string literals, these are used:

There is no alternative template form. Character literals are defined similarly.

C++11 standardizes support for multithreaded programming.

There are two parts involved: a memory model which allows multiple threads to co-exist in a program and library support for interaction between threads. (See this article's section on threading facilities.)

The memory model defines when multiple threads may access the same memory location, and specifies when updates by one thread become visible to other threads.

In a multi-threaded environment, it is common for every thread to have some unique variables. This already happens for the local variables of a function, but it does not happen for global and static variables.

A new "thread-local" storage duration (in addition to the existing "static", "dynamic" and "automatic") is indicated by the storage specifier codice_177.

Any object which could have static storage duration (i.e., lifetime spanning the entire execution of the program) may be given thread-local duration instead. The intent is that like any other static-duration variable, a thread-local object can be initialized using a constructor and destroyed using a destructor.

In C++03, the compiler provides, for classes that do not provide them for themselves, a default constructor, a copy constructor, a copy assignment operator (codice_178), and a destructor. The programmer can override these defaults by defining custom versions. C++ also defines several global operators (such as codice_179) that work on all classes, which the programmer can override.

However, there is very little control over creating these defaults. Making a class inherently non-copyable, for example, requires declaring a private copy constructor and copy assignment operator and not defining them. Attempting to use these functions is a violation of the One Definition Rule (ODR). While a diagnostic message is not required,<ref name="C++03 3.2/3">ISO/IEC (2003). "ISO/IEC 14882:2003(E): Programming Languages – C++ §3.2 One definition rule [basic.def.odr]" para. 3</ref> violations may result in a linker error.

In the case of the default constructor, the compiler will not generate a default constructor if a class is defined with "any" constructors. This is useful in many cases, but it is also useful to be able to have both specialized constructors and the compiler-generated default.

C++11 allows the explicit defaulting and deleting of these special member functions. For example, this type explicitly declares that it is using the default constructor:

Alternatively, certain features can be explicitly disabled. For example, this type is non-copyable:

The codice_180 specifier can be used to prohibit calling any function, which can be used to disallow calling a member function with particular parameters. For example:
An attempt to call codice_181 with an codice_53 will be rejected by the compiler, instead of performing a silent conversion to codice_153. This can be generalized to disallow calling the function with any type other than codice_153 as follows:
In C++03, the largest integer type is codice_186. It is guaranteed to have at least as many usable bits as codice_53. This resulted in codice_186 having size of 64 bits on some popular implementations and 32 bits on others. C++11 adds a new integer type codice_185 to address this issue. It is guaranteed to be at least as large as a codice_186, and have no fewer than 64 bits. The type was originally introduced by C99 to the standard C, and most C++ compilers supported it as an extension already.

C++03 provides two methods to test assertions: the macro codice_191 and the preprocessor directive codice_192. However, neither is appropriate for use in templates: the macro tests the assertion at execution-time, while the preprocessor directive tests the assertion during preprocessing, which happens before instantiation of templates. Neither is appropriate for testing properties that are dependent on template parameters.

The new utility introduces a new way to test assertions at compile-time, using the new keyword codice_193.
The declaration assumes this form:

Here are some examples of how codice_193 can be used:

When the constant expression is codice_195 the compiler produces an error message. The first example is similar to the preprocessor directive codice_192, although the preprocessor does only support integral types. In contrast, in the second example the assertion is checked at every instantiation of the template class codice_197.

Static assertions are useful outside of templates also. For instance, a given implementation of an algorithm might depend on the size of a codice_198 being larger than an codice_53, something the standard does not guarantee. Such an assumption is valid on most systems and compilers, but not all.

In C++03, the codice_200 operator can be used on types and objects. But it cannot be used to do this:

This should return the size of codice_202. C++03 disallows this, so it is a compile error. C++11 allows it. It is also allowed for the codice_203 operator introduced in C++11.

C++11 allows variable alignment to be queried and controlled with codice_203 and codice_205.

The codice_203 operator takes the type and returns the power of 2 byte boundary on which the type instances must be allocated (as a codice_207). When given a reference type codice_203 returns the referenced type's alignment; for arrays it returns the element type's alignment.

The codice_205 specifier controls the memory alignment for a variable. The specifier takes a constant or a type; when supplied a type codice_210 is shorthand for codice_211. For example, to specify that a char array should be properly aligned to hold a float:
Prior C++ standards provided for programmer-driven garbage collection via codice_212, but gave no definition of object reachability for the purpose of automatic garbage collection. C++11 defines conditions under which pointer values are "safely derived" from other values. An implementation may specify that it operates under "strict pointer safety", in which case pointers that are not derived according to these rules can become invalid.

C++11 provides a standardized syntax for compiler/tool extensions to the language. Such extensions were traditionally specified using codice_213 directive or vendor-specific keywords (like codice_214 for GNU and codice_215 for Microsoft). With the new syntax, added information can be specified in a form of an attribute enclosed in double square brackets. An attribute can be applied to various elements of source code:

In the example above, attribute codice_216 applies to the type of variable codice_217, codice_218 and codice_219 apply to the variable itself, codice_220 applies to the codice_221 statement and codice_222 applies to the return statement. In general (but with some exceptions), an attribute specified for a named entity is placed after the name, and before the entity otherwise, as shown above, several attributes may be listed inside one pair of double square brackets, added arguments may be provided for an attribute, and attributes may be scoped by vendor-specific attribute namespaces.

It is recommended that attributes have no language semantic meaning and do not change the sense of a program when ignored. Attributes can be useful for providing information that, for example, helps the compiler to issue better diagnostics or optimize the generated code.

C++11 provides two standard attributes itself: codice_223 to specify that a function does not return, and codice_224 to help optimizing multi-threaded code by indicating that function arguments or return value carry a dependency.

A number of new features were introduced in the C++11 standard library. Many of these could have been implemented under the old standard, but some rely (to a greater or lesser extent) on new C++11 core features.

A large part of the new libraries was defined in the document "C++ Standards Committee's Library Technical Report" (called TR1), which was published in 2005. Various full and partial implementations of TR1 are currently available using the namespace codice_225. For C++11 they were moved to namespace codice_226. However, as TR1 features were brought into the C++11 standard library, they were upgraded where appropriate with C++11 language features that were not available in the initial TR1 version. Also, they may have been enhanced with features that were possible under C++03, but were not part of the original TR1 specification.

C++11 offers a number of new language features that the currently existing standard library components can benefit from. For example, most standard library containers can benefit from Rvalue reference based move constructor support, both for quickly moving heavy containers around and for moving the contents of those containers to new memory locations. The standard library components were upgraded with new C++11 language features where appropriate. These include, but are not necessarily limited to:


Further, much time has passed since the prior C++ standard. Much code using the standard library has been written. This has revealed parts of the standard libraries that could use some improving. Among the many areas of improvement considered were standard library allocators. A new scope-based model of allocators was included in C++11 to supplement the prior model.

While the C++03 language provides a memory model that supports threading, the primary support for actually using threading comes with the C++11 standard library.

A thread class (codice_231) is provided, which takes a function object (and an optional series of arguments to pass to it) to run in the new thread. It is possible to cause a thread to halt until another executing thread completes, providing thread joining support via the codice_232 member function. Access is provided, where feasible, to the underlying native thread object(s) for platform-specific operations by the codice_233 member function.

For synchronization between threads, appropriate mutexes (codice_234, codice_235, etc.) and condition variables (codice_236 and codice_237) are added to the library. These are accessible via Resource Acquisition Is Initialization (RAII) locks (codice_238 and codice_239) and locking algorithms for easy use.

For high-performance, low-level work, communicating between threads is sometimes needed without the overhead of mutexes. This is done using atomic operations on memory locations. These can optionally specify the minimum memory visibility constraints needed for an operation. Explicit memory barriers may also be used for this purpose.

The C++11 thread library also includes futures and promises for passing asynchronous results between threads, and codice_240 for wrapping up a function call that can generate such an asynchronous result. The futures proposal was criticized because it lacks a way to combine futures and check for the completion of one promise inside a set of promises.

Further high-level threading facilities such as thread pools have been remanded to a future C++ technical report. They are not part of C++11, but their eventual implementation is expected to be built entirely on top of the thread library features.

The new codice_241 facility provides a convenient method of running tasks and tying them to a codice_242. The user can choose whether the task is to be run asynchronously on a separate thread or synchronously on a thread that waits for the value. By default, the implementation can choose, which provides an easy way to take advantage of hardware concurrency without oversubscription, and provides some of the advantages of a thread pool for simple usages.

Tuples are collections composed of heterogeneous objects of pre-arranged dimensions. A tuple can be considered a generalization of a struct's member variables.

The C++11 version of the TR1 tuple type benefited from C++11 features like variadic templates. To implement reasonably, the TR1 version required an implementation-defined maximum number of contained types, and substantial macro trickery. By contrast, the implementation of the C++11 version requires no explicit implementation-defined maximum number of types. Though compilers will have an internal maximum recursion depth for template instantiation (which is normal), the C++11 version of tuples will not expose this value to the user.

Using variadic templates, the declaration of the tuple class looks as follows:
An example of definition and use of the tuple type:
It’s possible to create the tuple codice_243 without defining its contents, but only if the tuple elements' types possess default constructors. Moreover, it’s possible to assign a tuple to another tuple: if the two tuples’ types are the same, each element type must possess a copy constructor; otherwise, each element type of the right-side tuple must be convertible to that of the corresponding element type of the left-side tuple or that the corresponding element type of the left-side tuple has a suitable constructor.
Just like codice_244 for codice_245, there exists codice_246 to automatically create codice_247s using type deduction and codice_49 helps to declare such a tuple. codice_249 creates tuples of lvalue references to help unpack tuples. codice_250 also helps here. See the example:

Relational operators are available (among tuples with the same number of elements), and two expressions are available to check a tuple’s characteristics (only during compilation):

Including hash tables (unordered associative containers) in the C++ standard library is one of the most recurring requests. It was not adopted in C++03 due to time constraints only. Although hash tables are less efficient than a balanced tree in the worst case (in the presence of many collisions), they perform better in many real applications.

Collisions are managed only via "linear chaining" because the committee didn't consider it to be opportune to standardize solutions of "open addressing" that introduce quite a lot of intrinsic problems (above all when erasure of elements is admitted). To avoid name clashes with non-standard libraries that developed their own hash table implementations, the prefix “unordered” was used instead of “hash”.

The new library has four types of hash tables, differentiated by whether or not they accept elements with the same key (unique keys or equivalent keys), and whether they map each key to an associated value. They correspond to the four existing binary search tree based associative containers, with an unordered_ prefix.

The new classes fulfill all the requirements of a container class, and have all the methods needed to access elements: codice_256, codice_257, codice_258, codice_259.

This new feature didn't need any C++ language core extensions (though implementations will take advantage of various C++11 language features), only a small extension of the header codice_260 and the introduction of headers codice_261 and codice_262. No other changes to any existing standard classes were needed, and it doesn’t depend on any other extensions of the standard library.

The new library, defined in the new header codice_263, is made of a couple of new classes:
The function codice_266 is used for searching, while for ‘search and replace’ the function codice_267 is used which returns a new string.
The algorithms codice_266 and codice_267 take a regular expression and a string and write the occurrences found in the struct codice_265.

Here is an example of the use of codice_265:
Note the use of double backslashes, because C++ uses backslash as an escape character. The C++11 raw string feature could be used to avoid the problem.

The library codice_263 requires neither alteration of any existing header (though it will use them where appropriate) nor an extension of the core language. In POSIX C, regular expressions are also available the C POSIX library#regex.h.

C++11 provides , and improvements to and from TR1. is deprecated.

The C standard library provides the ability to generate pseudorandom numbers via the function codice_273. However, the algorithm is delegated entirely to the library vendor. C++ inherited this functionality with no changes, but C++11 provides a new method for generating pseudorandom numbers.

C++11's random number functionality is split into two parts: a generator engine that contains the random number generator's state and produces the pseudorandom numbers; and a distribution, which determines the range and mathematical distribution of the outcome. These two are combined to form a random number generator object.

Unlike the C standard codice_273, the C++11 mechanism will come with three base generator engine algorithms:

C++11 also provides a number of standard distributions:

The generator and distributions are combined as in this example:

A wrapper reference is obtained from an instance of the template class codice_298. Wrapper references are similar to normal references (‘codice_299’) of the C++ language. To obtain a wrapper reference from any object the function template codice_300 is used (for a constant reference codice_301 is used).

Wrapper references are useful above all for function templates, where references to parameters rather than copies are needed:
This new utility was added to the existing codice_302 header and didn't need further extensions of the C++ language.

Polymorphic wrappers for function objects are similar to function pointers in semantics and syntax, but are less tightly bound and can indiscriminately refer to anything which can be called (function pointers, member function pointers, or functors) whose arguments are compatible with those of the wrapper.

An example can clarify its characteristics:
The template class codice_303 was defined inside the header codice_260, without needing any change to the C++ language.

Metaprogramming consists of creating a program that creates or modifies another program (or itself). This can happen during compilation or during execution. The C++ Standards Committee has decided to introduce a library that allows metaprogramming during compiling via templates.

Here is an example of a meta-program, using the C++03 standard: a recursion of template instances for calculating integer exponents:

Many algorithms can operate on different types of data; C++'s templates support generic programming and make code more compact and useful. Nevertheless, it is common for algorithms to need information on the data types being used. This information can be extracted during instantiation of a template class using "type traits".

"Type traits" can identify the category of an object and all the characteristics of a class (or of a struct). They are defined in the new header codice_305.

In the next example there is the template function ‘elaborate’ that, depending on the given data types, will instantiate one of the two proposed algorithms (codice_306).

Via "type traits", defined in header codice_305, it’s also possible to create type transformation operations (codice_308 and codice_309 are insufficient inside a template).

This type of programming produces elegant and concise code; however the weak point of these techniques is the debugging: uncomfortable during compilation and very difficult during program execution.

Determining the return type of a template function object at compile-time is not intuitive, particularly if the return value depends on the parameters of the function. As an example:

Instantiating the class template codice_310, the function object of codice_311 will have always the same return type as the function object of codice_312. However, given class codice_313 below:
Attempting to instantiate codice_314 will cause the return type of codice_315 to not be the same as that of class codice_313. The compiler may generate warnings about the conversion from codice_53 to codice_153 and vice versa.

TR1 introduces, and C++11 adopts, the template class codice_319 that allows one to determine and use the return type of a function object for every declaration. The object codice_320 uses the codice_319 object to derive the return type of the function object:

In this way in instances of function object of codice_322 there are no conversions, warnings, or errors.

The only change from the TR1 version of codice_319 is that the TR1 version allowed an implementation to fail to be able to determine the result type of a function call. Due to changes to C++ for supporting codice_55, the C++11 version of codice_319 no longer needs these special cases; implementations are required to compute a type in all cases.

For compatibility with C, from C99, these were added:


Heading for a separate TR:
Postponed:

The term sequence point was removed, being replaced by specifying that either one operation is sequenced before another, or that two operations are unsequenced.

The former use of the keyword codice_336 was removed. The keyword itself remains, being reserved for potential future use.

Dynamic exception specifications are deprecated. Compile-time specification of non-exception-throwing functions is available with the codice_337 keyword, which is useful for optimization.

codice_338 is deprecated, having been superseded by codice_339.

Function object base classes (codice_340, codice_341), adapters to pointers to functions and adapters to pointers to members, and binder classes are all deprecated.




</doc>
<doc id="1418679" url="https://en.wikipedia.org/wiki?curid=1418679" title="Barton–Nackman trick">
Barton–Nackman trick

Barton–Nackman trick is a term coined by the C++ standardization committee (ISO/IEC JTC1/SC22 WG21) to refer to an idiom introduced by John Barton and Lee Nackman as "Restricted Template Expansion".

The idiom is characterized by an in-class friend function definition appearing in the base class template component of the curiously recurring template pattern (CRTP).

When a class template like codice_1 is instantiated, the in-class friend definitions produce "nontemplate" (and nonmember) functions (operator functions in this case). At the time the idiom was introduced (1994) the C++ language did not define a partial ordering for overloaded function templates and as a result overloading function templates often resulted in ambiguities. For example, trying to capture a generic definition for codice_2 as

would essentially be incompatible with another definition like

The Barton–Nackman trick, then, achieves the goal of providing a generic user-defined equality operator without having to deal with such ambiguities. The adjective "restricted" in the idiom name refers to the fact that the provided in-class function definition is restricted (only applies) to specializations of the given class template.

The term is sometimes mistakenly used to refer to the Curiously Recurring Template Pattern (CRTP). As explained above, the Barton–Nackman trick is a distinct idiom (that relies on the CRTP).

When the compiler encounters the expression

where codice_3 and codice_4 are of type codice_5, it attempts argument-dependent lookup (ADL) for codice_2. This lookup includes consideration of friend functions declared in codice_5 and its base classes. (Note that if codice_5 were an incomplete template instance, ADL would trigger its complete instantiation.)

The Barton–Nackman trick originally relied not on ADL but on a C++ feature called "friend name injection", in which an in-class declaration of a friend function made the function name visible in the immediately surrounding namespace scope (possibly the global scope). When investigating the possibility of removing friend name injection from the C++ programming language, Barton and Nackman's idiom was found to be the only reasonable use of that language rule. Eventually, the rules for argument-dependent lookup were adjusted to replace friend name injection by a less drastic mechanism, described above, that maintained the validity of Barton and Nackman's technique. It is worth noting that, as a consequence of this change, the expression

is no longer valid, because qualified names aren't subject to ADL and friend declarations aren't found via ordinary lookup. Note that this implies that the codice_9 specifier is essential, even if the defined friend functions do not actually need to access nonpublic members of the befriending class.

The C++11 Concepts generic programming specification would have made the Barton–Nackman trick obsolete. Concepts have since been removed from the final C++11 language standard, but are proposed for inclusion in C++20.



</doc>
<doc id="39180972" url="https://en.wikipedia.org/wiki?curid=39180972" title="Stack (C++)">
Stack (C++)

A stack is a standard C++ container adapter, designed to be used in a LIFO context, and is implemented with an interface/wrapper to the type passed to it as a template argument, which defaults to a deque. It is so simple, that it can be described with just a sample interface:


</doc>
<doc id="39700922" url="https://en.wikipedia.org/wiki?curid=39700922" title="As-if rule">
As-if rule

The standard for the C++ programming language allows compilers for this language to apply any optimizing transformation to a program during compilation, provided that such optimizations make no change in the "observable behavior" of the program, as specified in the standard; this mostly means that any actions the program performs on its environment occur in the specified order. This rule is commonly referred to as the as-if rule.

The rule has three main exceptions. The first is that programs exhibiting undefined behavior are exempt; since the observable behavior is not well-defined anyway, "any" transformation is valid. The other two exceptions concern the copying of objects, and are called copy elision and the return value optimization.

The effect of the as-if rule depends on the specific compiler implementation. As an example, in the Microsoft C++ compiler, it causes omission of certain optimizations such as instruction reordering around calls to library functions, since such calls may cause input/output actions or accesses to memory locations marked , and changes in the order of those change observable behavior.

The as-if rule is not specific to C++; many other programming languages, including C, Rust, Go, Ocaml, etc. have a similar rule, to permit optimization (notably inlining).


</doc>
<doc id="1230835" url="https://en.wikipedia.org/wiki?curid=1230835" title="Sequence point">
Sequence point

A sequence point defines any point in a computer program's execution at which it is guaranteed that all side effects of previous evaluations will have been performed, and no side effects from subsequent evaluations have yet been performed. They are often mentioned in reference to C and C++, because they are a core concept for determining the validity and, if valid, the possible results of expressions. Adding more sequence points is sometimes necessary to make an expression defined and to ensure a single valid order of evaluation.

With C++11, usage of the term sequence point has been replaced by sequencing. There are three possibilities:


The execution of unsequenced evaluations can overlap, with catastrophic undefined behavior if they share state. This situation can arise in parallel computations, causing race conditions. However, it can already arise in simple non-concurrent situations like codice_1, where part of the assignment to codice_2 (eg., half of the bits) may happen before codice_3, and the rest afterwards, such that after evaluation of the expression, codice_4 may contain a meaningless intermediate state of codice_2.

Consider two functions codice_6 and codice_7. In C and C++, the codice_8 operator is not associated with a sequence point, and therefore in the expression codice_9 it is possible that either codice_6 or codice_7 will be executed first. The comma operator introduces a sequence point, and therefore in the code codice_12 the order of evaluation is defined: first codice_6 is called, and then codice_7 is called.

Sequence points also come into play when the same variable is modified more than once within a single expression. An often-cited example is the C expression codice_15, which apparently both assigns codice_16 its previous value and increments codice_16. The final value of codice_16 is ambiguous, because, depending on the order of expression evaluation, the increment may occur before, after, or interleaved with the assignment. The definition of a particular language might specify one of the possible behaviors or simply say the behavior is undefined. In C and C++, evaluating such an expression yields undefined behavior. Other languages, such as C#, define the precedence of the assignment and increment operator in such a way that the result of the expression codice_15 is guaranteed.

In C and C++, sequence points occur in the following places. (In C++, overloaded operators act like functions, and thus operators that have been overloaded introduce sequence points in the same way as function calls.)




</doc>
<doc id="8548841" url="https://en.wikipedia.org/wiki?curid=8548841" title="Libt2n">
Libt2n

libt2n is a free Inter-process communication (IPC) library which offers a simple way for C++ applications to communicate with one another.

libt2n is an inter-process communication (IPC) system which is focused on ease of use and a minimum of code-lines needed to export and use methods. This is achieved by reducing the feature-set and relying on the serialization library developed at Boost. 

The goals of libt2n development are:

The limitations of the current libt2n implementation:

libt2n is divided in two parts:

The code generator does not use an Interface description language (IDL), but parses the source code of the server for special tags. It produces the code needed to handle the calls on the server and a ready-to-use library for the client.

If a remote function is called, the client library creates an object describing the call, including all parameters. This object is serialized using the Boost serialization library and transferred to the server. Currently this can be done using Unix domain sockets or TCP. The server deserializes the object and calls the corresponding method. The result (return value or exception) is again serialized and sent back to the client.

t2n is an abbreviation for 'talk to neighbor'.



</doc>
<doc id="41197861" url="https://en.wikipedia.org/wiki?curid=41197861" title="High Integrity C++">
High Integrity C++

High Integrity C++ (HIC++ or formerly HICPP) is a software coding standard for the C++ programming language developed by Programming Research Limited, now part of Perforce Software. HIC++ was first published in October 2003. The latest revision, version 4.0, was released in October 2013 and documents 155 rules that restrict the use of ISO C++ language to improve software maintenance and reliability in high reliability or safety critical applications.

The Motor Industry Software Reliability Association (MISRA) C++ coding standard reference list includes High Integrity C++ .

Notable tools that check for compliance with High Integrity C++ are:



</doc>
<doc id="585336" url="https://en.wikipedia.org/wiki?curid=585336" title="Operators in C and C++">
Operators in C and C++

This is a list of operators in the C and C++ programming languages. All the operators listed exist in C++; the fourth column "Included in C", states whether an operator is also present in C. Note that C does not support operator overloading.

When not overloaded, for the operators codice_1, codice_2, and codice_3 (the comma operator), there is a sequence point after the evaluation of the first operand.

C++ also contains the type conversion operators codice_4, codice_5, codice_6, and codice_7. The formatting of these operators means that their precedence level is unimportant.

Most of the operators available in C and C++ are also available in other languages such as C#, D, Java, Perl, and PHP with the same precedence, associativity, and semantics.

For the purposes of these tables, codice_8, codice_9, and codice_10 represent valid values (literals, values from variables, or return value), object names, or lvalues, as appropriate. codice_11, codice_12 and codice_13 stand for any type(s), and codice_14 for a class type or enumerated type.

Notes:
The following is a table that lists the precedence and associativity of all the operators in the C and C++ languages (when the operators also exist in Java, Perl, PHP and many other recent languages, the precedence is the same as that given). Operators are listed top to bottom, in descending precedence. Descending precedence refers to the priority of the grouping of operators and operands. Considering an expression, an operator which is listed on some row will be grouped prior to any operator that is listed on a row further below it. Operators that are in the same cell (there may be several rows of operators listed in a cell) are grouped with the same precedence, in the given direction. An operator's precedence is unaffected by overloading.

The syntax of expressions in C and C++ is specified by a phrase structure grammar. The table given here has been inferred from the grammar. For the ISO C 1999 standard, section 6.5.6 note 71 states that the C grammar provided by the specification defines the precedence of the C operators, and also states that the operator precedence resulting from the grammar closely follows the specification's section ordering:

"The [C] syntax [i.e., grammar] specifies the precedence of operators in the evaluation of an expression, which is the same as the order of the major subclauses of this subclause, highest precedence first."

A precedence table, while mostly adequate, cannot resolve a few details. In particular, note that the ternary operator allows any arbitrary expression as its middle operand, despite being listed as having higher precedence than the assignment and comma operators. Thus codice_15 is interpreted as codice_16, and not as the meaningless codice_17. So, the expression in the middle of the conditional operator (between codice_18 and codice_19) is parsed as if parenthesized. Also, note that the immediate, unparenthesized result of a C cast expression cannot be the operand of codice_20. Therefore, codice_21 is interpreted as codice_22 and not codice_23.

The precedence table determines the order of binding in chained expressions, when it is not expressly specified by parentheses.


Many of the operators containing multi-character sequences are given "names" built from the operator name of each character. For example, codice_35 and codice_36 are often called "plus equal(s)" and "minus equal(s)", instead of the more verbose "assignment by addition" and "assignment by subtraction".
The binding of operators in C and C++ is specified (in the corresponding Standards) by a factored language grammar, rather than a precedence table. This creates some subtle conflicts. For example, in C, the syntax for a conditional expression is:

while in C++ it is:

Hence, the expression:

is parsed differently in the two languages. In C, this expression is a syntax error, because the syntax for an assignment expression in C is:

In C++, it is parsed as:

which is a valid expression.

The precedence of the bitwise logical operators has been criticized. Conceptually, & and | are arithmetic operators like * and +.

The expression is syntactically parsed as whereas the expression is parsed as . This requires parentheses to be used more often than they otherwise would.

Historically, there was no syntactic distinction between the bitwise and logical operators. In BCPL, B and early C, the operators didn't exist. Instead had different meaning depending on whether they are used in a ‘truth-value context’ (i.e. when a Boolean value was expected, for example in it behaved as a logical operator, but in it behaved as a bitwise one). It was retained so as to keep backward compatibility with existing installations.

Moreover, in C++ (and later versions of C) equality operations, with the exception of the three-way comparison operator, yield bool type values which are conceptually a single bit (1 or 0) and as such do not properly belong in "bitwise" operations.

C++ defines certain keywords to act as aliases for a number of operators:
These can be used exactly the same way as the punctuation symbols they replace, as they are not the same operator under a different name, but rather simple token replacements for the "name" (character string) of the respective operator. This means that the expressions and have identical meanings. It also means that, for example, the codice_37 keyword may be used to replace not only the "bitwise-and" operator but also the "address-of" operator, and it can even be used to specify reference types (e.g., ). The ISO C specification makes allowance for these keywords as preprocessor macros in the header file . For compatibility with C, C++ provides the header , the inclusion of which has no effect.




</doc>
<doc id="28115039" url="https://en.wikipedia.org/wiki?curid=28115039" title="Include directive">
Include directive

Many programming languages and other computer files have a directive, often called codice_1 (as well as codice_2 and codice_3), that causes the contents of a second file to be inserted into the original file. These included files are called copybooks or s. They are often used to define the physical layout of program data, pieces of procedural code and/or forward declarations while promoting encapsulation and the reuse of code.

The codice_1 directive allows libraries of code to be developed which help to:

An example situation which benefits from the use of an include directive is when referring to functions in a different file. Suppose we have a function codice_5 in one file, which is then declared (with a function prototype) and then referred to in a second source file as follows:
One drawback of this method is that the prototype must be present in all files that use the function. Another drawback is that if the return type or arguments of the function are changed, these prototypes will have to be updated. Putting the prototype in a single, separate file avoids these problems. Assuming the prototype is moved to the file codice_6, the second source file can then become:
Now, every time the code is compiled, the latest function prototypes in codice_6 will be included in the files using them, avoiding potentially disastrous errors.

In C and C++, the codice_8 preprocessor directive causes the compiler to replace that line with the entire text of the contents of the named source file (if included in quotes: "") or named header (if included in angle brackets: <>); note that a header need not be a source file. Inclusion continues recursively on these included contents, up to an implementation-defined nesting limit. Headers need not have names corresponding to files: in C++ standard headers are typically identified with words, like "vector", hence codice_9 while in C standard headers have identifiers in the form of filenames with a ".h" extension, as in codice_10. A "source file" can be any file, with a name of any form, but is most commonly named with a ".h" extension and called a "header file" (sometimes ".hpp" or ".hh" to distinguish C++ headers), though files with .c, .cc, and .cpp extensions may also be included (particularly in the Single Compilation Unit technique), and sometimes other extensions are used.

These two forms of codice_8 directive can determine which header or source file to include in an implementation-defined way. In practice, what is usually done is that the angle-brackets form searches for "source files" in a standard system directory (or set of directories), and then searches for source files in local or project-specific paths (specified on the command line, in an environment variable, or in a Makefile or other build file), while the form with quotes does not search in a standard system directory, only searching in local or project-specific paths. In case there is no clash, the angle-brackets form can also be used to specify project-specific includes, but this is considered poor form. The fact that headers need not correspond to files is primarily an implementation technicality, and used to omit the .h extension in including C++ standard headers; in common use "header" means "header file".

For example:
In C and C++, problems may be faced if two (or more) include files both in turn include the same third file. One solution is to avoid include files from including any other files, possibly requiring the programmer to manually add extra include directives to the original file. Another solution is to use include guards.

COBOL (and also RPG IV) allows programmers to copy copybooks into the source of the program in a similar way to header files, but it also allows replacing certain text in them with other text. The COBOL keyword for inclusion is codice_12, and replacement is done using the codice_13 clause. An include directive has been present in COBOL since COBOL 60, but changed from the original codice_14 to codice_12 by 1968.

Fortran does not require header files "per se". However, Fortran 90 and later has two related features: codice_1 statements and modules. The former can be used to share a common file containing procedure interfaces, much like a C header, although the specification of an interface is not required for all varieties of Fortran procedures. This approach is not commonly used; instead procedures are generally grouped into modules that can then be referenced with a codice_17 statement within other regions of code. For modules, header-type interface information is automatically generated by the compiler, and typically put into separate module files, although some compilers have placed this information directly into object files. The language specification itself does not mandate the creation of any extra files, even though module procedure interfaces are almost universally propagated in this manner.

In PHP, the codice_1 directive causes another PHP file to be included and evaluated. Similar commands are codice_19, which upon failure to include will produce a fatal exception and halt the script, and codice_20 and codice_21, which cause a file to not be included or required again if it has already been included or required, avoiding the C's double inclusion problem.

There are many forms of the include directive, such as:


Modern languages (e.g. Haskell and Java) tend to avoid copybooks or includes, preferring modules and import/export systems for namespace control. Some of these languages (such as Java and C#) do not use forward declarations and, instead, identifiers are recognized automatically from source files and read directly from dynamic library symbols (typically referenced with codice_3 or codice_35 directives), meaning header files are not needed.




</doc>
<doc id="13142178" url="https://en.wikipedia.org/wiki?curid=13142178" title="Pro*C">
Pro*C

Pro*C (also known as Pro*C/C++) is an embedded SQL programming language used by Oracle Database management systems. Pro*C uses either C or C++ as its host language. During compilation, the embedded SQL statements are interpreted by a precompiler and replaced by C or C++ function calls to their respective SQL library. The output from the Pro*C precompiler is standard C or C++ code that is then compiled by any one of several C or C++ compilers into an executable.



</doc>
<doc id="515992" url="https://en.wikipedia.org/wiki?curid=515992" title="Undefined behavior">
Undefined behavior

In computer programming, undefined behavior (UB) is the result of executing computer code whose behavior is not prescribed by the language specification to which the code adheres, for the current state of the program. This happens when the translator of the source code makes certain assumptions, but these assumptions are not satisfied during execution.

The behavior of some programming languages—most famously C and C++—is undefined in some cases. In the standards for these languages the semantics of certain operations is described as "undefined". These cases typically represent unambiguous bugs in the code, for example indexing an array outside of its bounds. An implementation is allowed to assume that such operations never occur in correct standard-conforming program code. In the case of C/C++, the compiler is allowed to give a compile-time diagnostic in these cases, but is not required to: the implementation will be considered correct whatever it does in such cases, analogous to don't-care terms in digital logic. It is the responsibility of the programmer to write code that never invokes undefined behavior, although compiler implementations are allowed to issue diagnostics when this happens. This assumption can make various program transformations valid or simplify their proof of correctness, giving flexibility to the implementation. As a result, the compiler can often make more optimizations. It also allows more compile-time checks by both compilers and static program analysis. 

In the C community, undefined behavior may be humorously referred to as "nasal demons", after a comp.std.c post that explained undefined behavior as allowing the compiler to do anything it chooses, even "to make demons fly out of your nose". Under some circumstances there can be specific restrictions on undefined behavior. For example, the instruction set specifications of a CPU might leave the behavior of some forms of an instruction undefined, but if the CPU supports memory protection then the specification will probably include a blanket rule stating that no user-accessible instruction may cause a hole in the operating system's security; so an actual CPU would be permitted to corrupt user registers in response to such an instruction, but would not be allowed to, for example, switch into supervisor mode.

Documenting an operation as undefined behavior allows compilers to assume that this operation will never happen in a conforming program. This gives the compiler more information about the code and this information can lead to more optimization opportunities.

An example for the C language:

The value of codice_1 cannot be negative and, given that signed integer overflow is undefined behavior in C, the compiler can assume that codice_2 will always be false. Thus the codice_3 statement, including the call to the function codice_4, can be ignored by the compiler since the test expression in the codice_3 has no side effects and its condition will never be satisfied. The code is therefore semantically equivalent to:

Had the compiler been forced to assume that signed integer overflow has "wraparound" behavior, then the transformation above would not have been legal.

Such optimizations become hard to spot by humans when the code is more complex and other optimizations, like inlining, take place. For example, another function may call the above function:

The compiler is free to optimize away the codice_6-loop here by applying value range analysis: by inspecting codice_7, it knows that the initial value pointed to by codice_8 cannot possibly exceed 47 (as any more would trigger undefined behavior in codice_7), therefore the initial check of codice_10 will always be false in a conforming program. Going further, since the result z is now never used and codice_7 has no side-effects, the compiler can optimize codice_12 to be an empty function that returns immediately. The disappearance of the codice_6-loop may be especially surprising if codice_7 is defined in a separately compiled object file.

Another benefit from allowing signed integer overflow to be undefined is that it makes it possible to store and manipulate a variable's value in a processor register that is larger than the size of the variable in the source code. For example, if the type of a variable as specified in the source code is narrower than the native register width (such as "int" on a 64-bit machine, a common scenario), then the compiler can safely use a signed 64-bit integer for the variable in the machine code it produces, without changing the defined behavior of the code. If a program depended on the behavior of a 32-bit integer overflow, then a compiler would have to insert additional logic when compiling for a 64-bit machine, because the overflow behavior of most machine instructions depends on the register width.

A further important benefit of undefined signed integer overflow is that it enables, though does not require, erroneous overflows to be detected at compile-time or by static program analysis, or by run-time checks such as the Clang and GCC sanitizers and valgrind; if such overflow were defined with semantics such as wrap-around then compile-time checks would not be possible.

C and C++ standards have several forms of undefined behavior throughout, which offer increased liberty in compiler implementations and compile-time checks at the expense of undefined run-time behavior if present. In particular, the ISO C standard has an appendix listing common sources of undefined behavior. Moreover, compilers are not required to diagnose code that relies on undefined behavior. Hence, it is common for programmers, even experienced ones, to rely on undefined behavior either by mistake, or simply because they are not well-versed in the rules of the language that can span hundreds of pages. This can result in bugs that are exposed when a different compiler, or different settings, are used. Testing or fuzzing with dynamic undefined behavior checks enabled, e.g. the Clang sanitizers, can help to catch undefined behavior not diagnosed by the compiler or static analyzers.

In scenarios where security is critical, undefined behavior can lead to security vulnerabilities in software. When GCC's developers changed their compiler in 2008 such that it omitted certain overflow checks that relied on undefined behavior, CERT issued a warning against the newer versions of the compiler. Linux Weekly News pointed out that the same behavior was observed in PathScale C, Microsoft Visual C++ 2005 and several other compilers; the warning was later amended to warn about various compilers.

The major forms of undefined behavior in C can be broadly classified as : spatial memory safety violations, temporal memory safety violations, integer overflow, strict aliasing violations, alignment violations, unsequenced modifications, data races, and loops that neither perform I/O nor terminate.

In C the use of any automatic variable before it has been initialized yields undefined behavior, as does integer division by zero, signed integer overflow, indexing an array outside of its defined bounds (see buffer overflow), or null pointer dereferencing. In general, any instance of undefined behavior leaves the abstract execution machine in an unknown state, and causes the behavior of the entire program to be undefined. 

Attempting to modify a string literal causes undefined behavior:<ref name="C++03 2.13.4/2">ISO/IEC (2003). "ISO/IEC 14882:2003(E): Programming Languages - C++ §2.13.4 String literals [lex.string]" para. 2</ref>
Integer division by zero results in undefined behavior:<ref name="C++03 5.6/4">ISO/IEC (2003). "ISO/IEC 14882:2003(E): Programming Languages - C++ §5.6 Multiplicative operators [expr.mul]" para. 4</ref>

Certain pointer operations may result in undefined behavior:<ref name="C++03 5.6/5">ISO/IEC (2003). "ISO/IEC 14882:2003(E): Programming Languages - C++ §5.7 Additive operators [expr.add]" para. 5</ref>
In C and C++, the comparison of pointers to objects is only strictly defined if the pointers point to members of the same object, or elements of the same array.<ref name="C++03 5.9/2">ISO/IEC (2003). "ISO/IEC 14882:2003(E): Programming Languages - C++ §5.9 Relational operators [expr.rel]" para. 2</ref> Example:
Reaching the end of a value-returning function (other than main()) without a return statement results in undefined behavior if the value of the function call is used by the caller:<ref name="C99 6.9.1/12">ISO/IEC (2007). "ISO/IEC 9899:2007(E): Programming Languages - C §6.9 External definitions" para. 1</ref>
Modifying an object between two sequence points more than once produces undefined behavior. There are considerable changes in what causes undefined behavior in relation to sequence points as of C++11. The following example will however cause undefined behavior in both C++ and C. 

When modifying an object between two sequence points, reading the value of the object for any other purpose than determining the value to be stored is also undefined behavior.<ref name="C99 6.5/2">ISO/IEC (1999). "ISO/IEC 9899:1999(E): Programming Languages - C §6.5 Expressions" para. 2</ref>

In C/C++ bitwise shifting a value by a number of bits which is either a negative number or is greater than or equal to the total number of bits in this value results in undefined behavior. The safest way (regardless a compiler vendor) is to always keep the number of bits to shift (the right operand of the « and » bitwise operators) within the range: <codice_15> (where codice_16 is the left operand).




</doc>
<doc id="37908563" url="https://en.wikipedia.org/wiki?curid=37908563" title="C++14">
C++14

C++14 is a version of the ISO/IEC 14882 standard for the programming language C++. It is intended to be a small extension over C++11, featuring mainly bug fixes and small improvements. Its approval was announced on August 18, 2014. C++14 was released on December 15, 2014.

Because earlier C++ standard revisions were noticeably late, the name "C++1y" was sometimes used instead until its approval, similarly to how the C++11 standard used to be termed "C++0x" with the expectation of its release before 2010 (although in fact it slipped into 2010 and finally 2011).

These are the features added to the core language of C++14.

C++11 allowed lambda functions to deduce the return type based on the type of the expression given to the return statement. C++14 provides this ability to all functions. It also extends these facilities to lambda functions, allowing return type deduction for functions that are not of the form codice_1.

In order to induce return type deduction, the function must be declared with codice_2 as the return type, but without the trailing return type specifier in C++11:

If multiple return expressions are used in the function's implementation, then they must all deduce the same type.

Functions that deduce their return types can be forward declared, but they cannot be used until they have been defined. Their definitions must be available to the translation unit that uses them.

Recursion can be used with a function of this type, but the recursive call must happen after at least one return statement in the definition of the function:

In C++11, two methods of type deduction were added. codice_2 was a way to create a variable of the appropriate type, based on a given expression. codice_4 was a way to compute the type of a given expression. However, codice_4 and codice_2 deduce types in different ways. In particular, codice_2 always deduces a non-reference type, as though by using codice_8, while codice_9 always deduces a reference type. However, codice_4 can be prodded into deducing a reference or non-reference type, based on the value category of the expression and the nature of the expression it is deducing:

C++14 adds the codice_11 syntax. This allows codice_2 declarations to use the codice_4 rules on the given expression.

The codice_11 syntax can also be used with return type deduction, by using codice_11 syntax instead of codice_2 for the function's return type deduction.

C++11 introduced the concept of a constexpr-declared function; a function which could be executed at compile time. Their return values could be consumed by operations that require constant expressions, such as an integer template argument. However, C++11 constexpr functions could only contain a single expression that is returned (as well as codice_17s and a small number of other declarations).

C++14 relaxes these restrictions. Constexpr-declared functions may now contain the following:


codice_25 statements are forbidden in C++14 relaxed constexpr-declared functions.

Also, C++11 stated that all non-static member functions that were declared codice_24 were also implicitly declared codice_23, with respect to codice_28. That has since been removed; non-static member functions may be non-codice_23. However, per the restrictions above, a non-codice_23 codice_24 member function can only modify a class member if that object's lifetime began within the constant expression evaluation.

In prior versions of C++, only functions, classes or type aliases could be templated. C++14 now allows the creation of variables that are templated. An example given in the proposal is a variable codice_32 that can be read to get the value of pi for various types (e.g., codice_33 when read as an integral type; the closest value possible with codice_34, codice_35 or codice_36 precision when read as codice_34, codice_35 or codice_36, respectively; etc.).

The usual rules of templates apply to such declarations and definitions, including specialization.

C++11 added member initializers, expressions to be applied to members at class scope if a constructor did not initialize the member itself. The definition of aggregates was changed to explicitly exclude any class with member initializers; therefore, they are not allowed to use aggregate initialization.

C++14 relaxes this restriction, allowing aggregate initialization on such types. If the braced init list does not provide a value for that argument, the member initializer takes care of it.

Numeric literals in C++14 can be specified in binary form. The syntax uses the prefixes codice_40 or codice_41. The syntax is also used in other languages e.g. Java, C#, Swift, Go, Scala, Ruby, Python, OCaml, and as an unofficial extension in some C compilers since at least 2007.

In C++14, the single-quote character may be used arbitrarily as a digit separator in numeric literals, both integer literals and floating point literals. This can make it easier for human readers to parse large numbers through subitizing.

In C++11, lambda function parameters need to be declared with concrete types. C++14 relaxes this requirement, allowing lambda function parameters to be declared with the codice_2 type specifier.

Concerning codice_2 type deduction, generic lambdas follow the rules of template argument deduction (which are similar, but not identical in all respects). The code above is equivalent to this:

Generic lambdas are essentially templated functor lambdas.

C++11 lambda functions capture variables declared in their outer scope by value-copy or by reference. This means that value members of a lambda cannot be move-only types. C++14 allows captured members to be initialized with arbitrary expressions. This allows both capture by value-move and declaring arbitrary members of the lambda, without having a correspondingly named variable in an outer scope.

This is done via the use of an initializer expression:

The lambda function codice_44 returns 1, which is what codice_45 was initialized with. The declared capture deduces the type from the initializer expression as if by codice_2.

This can be used to capture by move, via the use of the standard codice_47 function:

The codice_49 attribute allows marking an entity deprecated, which makes it still legal to use but puts users on notice that use is discouraged and may cause a warning message to be printed during compilation. An optional string literal can appear as the argument of codice_49, to explain the rationale for deprecation and/or to suggest a replacement.

C++14 adds a shared timed mutex and a companion shared lock type.

The C++ Standard Library defines four associative container classes. These classes allow the user to look up a value based on a value of that type. The map containers allow the user to specify a key and a value, where lookup is done by key and returns a value. However, the lookup is always done by the specific key type, whether it is the key as in maps or the value itself as in sets.

C++14 allows the lookup to be done via an arbitrary type, so long as the comparison operator can compare that type with the actual key type. This would allow a map from codice_51 to some value to compare against a codice_52 or any other type for which an codice_53 overload is available. It is also useful for indexing composite objects in a codice_54 by the value of a single member without forcing the user of codice_55 to create a dummy object (for example creating an entire codice_56 to find a person by name).

To preserve backwards compatibility, heterogeneous lookup is only allowed when the comparator given to the associative container allows it. The standard library classes codice_57 and codice_58 are augmented to allow heterogeneous lookup.

C++11 defined the syntax for user-defined literal suffixes, but the standard library did not use any of them. C++14 adds the following standard literals:


The two "s" literals do not interact, as the string one only operates on string literals, and the one for seconds operates only on numbers.

The codice_64 type introduced in C++11 allows an aggregate of typed values to be indexed by a compile-time constant integer. C++14 extends this to allow fetching from a tuple by type instead of by index. If the tuple has more than one element of the type, a compile-time error results:

codice_65 can be used like codice_66 for codice_67 objects.

codice_68 gained an codice_69 overload to return the constant value.

The class template codice_70 and related alias templates were added for representing compile-time integer sequences, such as the indices of elements in a parameter pack.

The global codice_71/codice_72 functions were augmented with codice_73/codice_74 functions, which return constant iterators, and codice_75/codice_76 and codice_77/codice_78 which return reverse iterators.

The codice_79 function template assigns a new value to a variable and returns the old value.

New overloads of codice_80, codice_81, and codice_82 take a pair of iterators for the second range, so that the caller does not need to separately check that the two ranges are of the same length.

The codice_83 type trait detects if a class is marked codice_84.

The codice_85 stream I/O manipulator allows inserting and extracting strings with embedded spaces, by placing delimiters (defaulting to double-quotes) on output and stripping them on input, and escaping any embedded delimiters.

Clang finished support for C++14 in 3.4 though under the standard name c++1y, and made C++14 the default C++ standard in Clang 6. GCC finished support for C++14 in GCC 5, and made C++14 the default C++ standard in GCC 6. Microsoft Visual Studio 2017 also has implemented "almost all" C++14 features.



</doc>
<doc id="44230614" url="https://en.wikipedia.org/wiki?curid=44230614" title="C++17">
C++17

C++17 is a revision of the ISO/IEC 14882 standard for the C++ programming language. As of 2019, this is the most recent revision, while the successor C++20 is under preparation.

Before the C++ Standards Committee fixed a 3-year release cycle, C++17's release date was uncertain. In that time period, the C++17 revision was also called C++1z, following C++0x or C++1x for C++11 and C++1y for C++14. The C++17 specification reached the Draft International Standard (DIS) stage in March 2017. This DIS was unanimously approved, with only editorial comments, and the final standard was published in December 2017. Few changes were made to the C++ Standard Template Library, although some algorithms in the codice_1 header were given support for explicit parallelization and some syntactic enhancements were made.

This revision of C++ not only added new features but also removed a few. 

C++17 introduced many new features. The following lists may be incomplete.







</doc>
<doc id="2253076" url="https://en.wikipedia.org/wiki?curid=2253076" title="Destructor (computer programming)">
Destructor (computer programming)

In object-oriented programming, a destructor (sometimes abbreviated dtor) is a method which is automatically invoked when the object is destroyed. It can happen when its lifetime is bound to scope and the execution leaves the scope, when it is embedded in another object whose lifetime ends, or when it was allocated dynamically and is released explicitly. Its main purpose is to free the resources (memory allocations, open files or sockets, database connections, resource locks, etc.) which were acquired by the object during its life and/or deregister from other entities which may keep references to it. Use of destructors is needed for the process of Resource Acquisition Is Initialization (RAII).

In a language with an automatic garbage collection mechanism, it would be difficult to deterministically ensure the invocation of a destructor, and hence these languages are generally considered unsuitable for RAII. In such languages, unlinking an object from existing resources must be done by an explicit call of an appropriate function (usually called codice_1). This method is also recommended for freeing resources, rather than using finalizers for that.


The destructor has the same name as the class, but with a tilde (~) before it. For example, a class called foo will have the destructor . Additionally, destructors have neither parameters nor return types. As stated above, a destructor for an object is called whenever the object's lifetime ends. If the object was created as an automatic variable, its lifetime ends and the destructor is called automatically when the object goes out of scope. Because C++ does not have garbage collection, if the object was created with a codice_12 statement (dynamically on the heap), then its destructor is called when the codice_12 operator is applied to a pointer to the object. Usually that operation occurs within another destructor, typically the destructor of a smart pointer object.

In inheritance hierarchies, the declaration of a virtual destructor in the base class ensures that the destructors of derived classes are invoked properly when an object is deleted through a pointer-to-base-class. Objects that may be deleted in this way need to inherit a virtual destructor.

A destructor should never throw an exception.

Objects which cannot be safely copied and/or assigned should be disabled from such semantics by declaring their corresponding functions as deleted within a public encapsulation level. A detailed description of this method can be found in Scott Meyers' popular book, "Effective Modern C++" (Item 11: "Prefer deleted functions to private undefined ones.").

The GNU Compiler Collection's C compiler comes with 2 extensions that allow implementing destructors:

Destructors in Xojo (REALbasic) can be in one of two forms. Each form uses a regular method declaration with a special name (with no parameters and no return value). The older form uses the same name as the Class with a ~ (tilde) prefix. The newer form uses the name codice_16. The newer form is preferred because it makes refactoring the class easier.



</doc>
<doc id="693532" url="https://en.wikipedia.org/wiki?curid=693532" title="Resource acquisition is initialization">
Resource acquisition is initialization

Resource acquisition is initialization (RAII) is a programming idiom used in several object-oriented languages to describe a particular language behavior. In RAII, holding a resource is a class invariant, and is tied to object lifetime: resource allocation (or acquisition) is done during object creation (specifically initialization), by the constructor, while resource deallocation (release) is done during object destruction (specifically finalization), by the destructor. In other words, resource acquisition must succeed for initialization to succeed. Thus the resource is guaranteed to be held between when initialization finishes and finalization starts (holding the resources is a class invariant), and to be held only when the object is alive. Thus if there are no object leaks, there are no resource leaks.

RAII is associated most prominently with C++ where it originated, but also D, Ada, Vala, and Rust. The technique was developed for exception-safe resource management in C++ during 1984–89, primarily by Bjarne Stroustrup and Andrew Koenig, and the term itself was coined by Stroustrup. RAII is generally pronounced as an initialism, sometimes pronounced as "R, A, double I".

Other names for this idiom include "Constructor Acquires, Destructor Releases" (CADRe) and one particular style of use is called "Scope-based Resource Management" (SBRM). This latter term is for the special case of automatic variables. RAII ties resources to object "lifetime," which may not coincide with entry and exit of a scope. (Notably variables allocated on the free store have lifetimes unrelated to any given scope.) However, using RAII for automatic variables (SBRM) is the most common use case.

The following C++11 example demonstrates usage of RAII for file access and mutex locking:
This code is exception-safe because C++ guarantees that all stack objects are destroyed at the end of the enclosing scope, known as stack unwinding. The destructors of both the "lock" and "file" objects are therefore guaranteed to be called when returning from the function, whether an exception has been thrown or not.

Local variables allow easy management of multiple resources within a single function: they are destroyed in the reverse order of their construction, and an object is destroyed only if fully constructed—that is, if no exception propagates from its constructor.

Using RAII greatly simplifies resource management, reduces overall code size and helps ensure program correctness. RAII is therefore highly recommended in C++, and most of the C++ standard library follows the idiom.

The advantages of RAII as a resource management technique are that it provides encapsulation, exception safety (for stack resources), and locality (it allows acquisition and release logic to be written next to each other).

Encapsulation is provided because resource management logic is defined once in the class, not at each call site. Exception safety is provided for stack resources (resources that are released in the same scope as they are acquired) by tying the resource to the lifetime of a stack variable (a local variable declared in a given scope): if an exception is thrown, and proper exception handling is in place, the only code that will be executed when exiting the current scope are the destructors of objects declared in that scope. Finally, locality of definition is provided by writing the constructor and destructor definitions next to each other in the class definition.

Resource management therefore needs to be tied to the lifespan of suitable objects in order to gain automatic allocation and reclamation. Resources are acquired during initialization, when there is no chance of them being used before they are available, and released with the destruction of the same objects, which is guaranteed to take place even in case of errors.

Comparing RAII with the codice_1 construct used in Java, Stroustrup wrote that “In realistic systems, there are far more resource acquisitions than kinds of resources, so the 'resource acquisition is initialization' technique leads to less code than use of a 'finally' construct.”

The RAII design is often used for controlling mutex locks in multi-threaded applications. In that use, the object releases the lock when destroyed. Without RAII in this scenario the potential for deadlock would be high and the logic to lock the mutex would be far from the logic to unlock it. With RAII, the code that locks the mutex essentially includes the logic that the lock will be released when execution leaves the scope of the RAII object.

Another typical example is interacting with files: We could have an object that represents a file that is open for writing, wherein the file is opened in the constructor and closed when execution leaves the object's scope. In both cases, RAII ensures only that the resource in question is released appropriately; care must still be taken to maintain exception safety. If the code modifying the data structure or file is not exception-safe, the mutex could be unlocked or the file closed with the data structure or file corrupted.

Ownership of dynamically allocated objects (memory allocated with new in C++) can also be controlled with RAII, such that the object is released when the RAII (stack-based) object is destroyed. For this purpose, the C++11 standard library defines the smart pointer classes codice_2 for single-owned objects and codice_3 for objects with shared ownership. Similar classes are also available through codice_4 in C++98, and codice_5 in the Boost libraries.

Both Clang and GNU Compiler Collection implement a non-standard extension to the C language to support RAII: the "cleanup" variable attribute. The following macro annotates a variable with a given destructor function that it will call when the variable goes out of scope:

This macro can then be used as follows:

In this example, the compiler arranges for the "fclosep" function to be called on "logfile" before "example_usage" returns.

RAII only works for resources acquired and released (directly or indirectly) by stack-allocated objects,
where there "is" a well-defined static object lifetime.
Heap-allocated objects which themselves acquire and release resources are common in many languages, including C++. RAII depends on heap-based objects to be implicitly or explicitly deleted along all possible execution paths, in order to trigger its resource-releasing destructor (or equivalent). This can be achieved by using smart pointers to manage all heap objects, with weak-pointers for cyclically referenced objects.

In C++, stack unwinding is only guaranteed to occur if the exception is caught somewhere. This is because "If no matching handler is found in a program, the function terminate() is called; whether or not the stack is unwound before this call to terminate() is implementation-defined (15.5.1)." (C++03 standard, §15.3/9). This behavior is usually acceptable, since the operating system releases remaining resources like memory, files, sockets, etc. at program termination.

Perl, Python (in the CPython implementation), and PHP manage object lifetime by reference counting, which makes it possible to use RAII. Objects that are no longer referenced are immediately destroyed or finalized and released, so a destructor or finalizer can release the resource at that time. However, it is not always idiomatic in such languages, and is specifically discouraged in Python (in favor of context managers and "finalizers" from the "weakref" package).

However, object lifetimes are not necessarily bound to any scope, and objects may be destroyed non-deterministically or not at all. This makes it possible to accidentally leak resources that should have been released at the end of some scope. Objects stored in a static variable (notably a global variable) may not be finalized when the program terminates, so their resources are not released; CPython makes no guarantee of finalizing such objects, for instance. Further, objects with circular references will not be collected by a simple reference counter, and will live indeterminately long; even if collected (by more sophisticated garbage collection), destruction time and destruction order will be non-deterministic. In CPython there is a cycle detector which detects cycles and finalizes the objects in the cycle, though prior to CPython 3.4, cycles are not collected if any object in the cycle has a finalizer.



</doc>
<doc id="44285155" url="https://en.wikipedia.org/wiki?curid=44285155" title="Type qualifier">
Type qualifier

In the C, C++, and D programming languages, a type qualifier is a keyword that is applied to a type, resulting in a "qualified type." For example, codice_1 is a qualified type representing a constant integer, while codice_2 is the corresponding unqualified type, simply an integer. In D these are known as "type constructors," by analogy with constructors in object-oriented programming.

Type qualifiers are a way of expressing additional information about a value through the type system, and ensuring correctness in the use of the data. Type qualifiers are not generally used outside the C/C++ family of languages: many languages have a notion of constants, but express this by the name binding being constant (a "variable that doesn't vary"), rather than through the type system; see alternatives, below.

 and C11, there are four type qualifiers in standard C: codice_3 (C89), codice_4 (C89), codice_5 (C99) and codice_6 (C11) – the latter has a private name to avoid clashing with user-defined names. The first two of these, codice_3 and codice_4, are also present in C++, and are the only type qualifiers in C++. Thus in C++ the term ""cv"-qualified type" (for const and volatile) is often used for "qualified type", while the terms ""c"-qualified type" and ""v"-qualified type" are used when only one of the qualifiers is relevant.

Of these, codice_3 is by far the best-known and most used, appearing in the C and C++ standard libraries and encountered in any significant use of these languages, which must satisfy const-correctness. The other qualifiers are used for low-level programming, and while widely used there, are rarely used by typical programmers. For a time however codice_4 was used by some C++ programmers for synchronization during threading, though this was discouraged and is now broken in most compilers.

In D the type constructors are codice_3, codice_12, codice_13, and codice_14. codice_12 is a stronger variant of codice_3, indicating data that can "never" change its value, while codice_3 indicates data that cannot be changed through this reference: it is a constant "view" on possibly mutable data. codice_13 is used for shared data in multi-threading (as codice_4 was briefly used for in C++). codice_14 is a wildcard used to allow functions that do not modify data (and thus are only concerned with the unqualified type of the data) to return the same "qualified" type as the input. codice_3 and codice_12 can also be used as storage class specifiers.

In C and C++, a type is given in a function declaration or variable declaration by giving one or more type specifiers, and optionally type qualifiers. For example, an integer variable can be declared as:

where codice_2 is the type specifier. An unsigned integer variable can be declared as:

where both codice_24 and codice_2 are type specifiers. A constant unsigned integer variable can be declared as:

where codice_3 is a type qualifier, which the qualified type of codice_27 is codice_28 and the unqualified type is codice_29.

Variable declarations further have an optional storage class specifier. Properly this is a separate topic, distinct from the type, though codice_3 on a variable declaration is "also" taken to have implications for the storage class, namely that it can be stored in read-only memory.

The other qualifier in C and C++, codice_4, indicates that an object may be changed by something external to the program at any time and so must be re-read from memory every time it is accessed.

The qualifier is most often found in code that manipulates hardware directly (such as in embedded systems and device drivers) and in multithreaded applications (though often used incorrectly in that context; see external links at volatile variable). It can be used in exactly the same manner as codice_3 in declarations of variables, pointers, references, and member functions, and in fact, codice_4 is sometimes used to implement a similar design-by-contract strategy which Andrei Alexandrescu calls codice_4-correctness, though this is far less common than codice_3-correctness. The codice_4 qualifier also can be stripped by codice_37, and it can be combined with the codice_3 qualifier as in this sample:

Because codice_39 is codice_4, there is no guarantee that it will hold the same value on two successive reads even though the programmer cannot modify it. The semantics here indicate that the register's value is read-only but not necessarily unchanging.

The notion of a type qualifier was introduced, along with the example of codice_41 (later renamed codice_3) by Bjarne Stroustrup in a Bell Labs internal Technical Memorandum of 1981, and implemented in C with Classes, the predecessor to C++. As to motivation, Stroustrup writes:

codice_3 was then adopted in C as part of standardization, and appears in C89 (and subsequent versions) along with another type qualifier, codice_4, which was invented by the ANSI C standard committee (X3J11). codice_4 appeared by 1985; and an early use was in compiling the UNIX kernel for MIPS, to allow optimized compiling by preventing usual optimizations from being applied to volatile variables. A further qualifier, codice_46, was suggested at the December 1987 meeting of the X3J11 committee, but was rejected; its goal was ultimately fulfilled by the codice_5 qualifier in C99. The motivation for codice_46 was complementary to codice_4, namely that it indicated that even normally unsafe optimizations could be performed. Ritchie was not very supportive of type qualifiers, arguing that they did not "carry their weight", but ultimately did not argue for their removal from the standard; he did oppose codice_46 however, and it was dropped from the draft.

Java does not have type qualifiers, and conspicuously omitted codice_3: a 1999 proposal to add it was rejected, notably because adding it after the fact and then changing the standard library to use it consistently would have broken compatibility. However, Java initially left open the possibility of implementing codice_3, noticeable in that codice_3 is a reserved word, though it is not actually used as a keyword. Instead, Java has the object-oriented keyword codice_54, which is used to qualify attributes (and thence also for local variables) as constant, but not to qualify types.

Other languages take a different approach, considering constancy a property of an "identifier" (or name binding), not a "type." Such languages thus have constant identifiers (corresponding to "variables" that do not vary) with single assignment, but do not have a notion of const-correctness: since constancy is not part of the type, there is no possibility of type mismatch. Examples include Ada 83 with constant objects and a codice_55 keyword, and Java with the codice_54 keyword.



</doc>
<doc id="21004211" url="https://en.wikipedia.org/wiki?curid=21004211" title="Erase–remove idiom">
Erase–remove idiom

The erase–remove idiom is a common C++ technique to eliminate elements that fulfill a certain criterion from a C++ Standard Library container.

A common programming task is to remove all elements that have a certain value or fulfill a certain criterion from a collection. In C++, this can be achieved using a hand-written loop. It is, however, preferable to use an algorithm from the C++ Standard Library for such tasks.

codice_1 can be used to delete an element from a collection, but for containers which are based on an array, such as codice_2, all elements after the deleted element have to be moved forward to avoid "gaps" in the collection. Calling erase multiple times on the same container generates lots of overhead from moving the elements.

The codice_3 library provides the codice_4 and codice_5 algorithms for this. Because these algorithms operate on a range of elements denoted by two forward iterators, they have no knowledge of the underlying container or collection. 

These algorithms do not remove elements from the container, but move all elements that don't fit the removal criteria to the front of the range, keeping the relative order of the elements. This is done in a single pass through the data range. 

As no elements are actually removed and the container retains the same size, the tail of the array has a length equal to the number of "removed" items; these items remain in memory but in an unspecified state. codice_4 returns an iterator pointing to the first of these tail elements so that they can be deleted using a single call to codice_1. 

Doing the same using only codice_1 results in as many passes as there are elements to remove. For each of these passes, all elements after the erased element have to be moved, which is more time-consuming than shifting elements in a single pass.

The erase–remove idiom cannot be used for containers that return codice_9 (e.g.: set)

codice_10 and codice_11 do not maintain elements that are removed (unlike codice_12, codice_13). Thus, erase–remove can only be used with containers holding elements with full value semantics without incurring resource leaks.


</doc>
<doc id="12268473" url="https://en.wikipedia.org/wiki?curid=12268473" title="Comma operator">
Comma operator

In the C and C++ programming languages, the comma operator (represented by the token codice_1) is a binary operator that evaluates its first operand and discards the result, and then evaluates the second operand and returns this value (and type); there is a sequence point between these evaluations.

The use of the comma token as an is distinct from its use in function calls and definitions, variable declarations, enum declarations, and similar constructs, where it acts as a .

The comma operator separates "expressions" (which have value) in a way analogous to how the semicolon terminates "statements," and sequences of expressions are enclosed in parentheses analogously to how sequences of statements are enclosed in braces: codice_2 is a sequence of expressions, separated by commas, which evaluates to the last expression codice_3 while codice_4 is a sequence of statements, and does not evaluate to any value. A comma can only occur between two expressions – commas "separate" expressions – unlike the semicolon, which occurs at the end of a (non-block) statement – semicolons "terminate" statements.

The comma operator has the lowest precedence of any C operator, and acts as a sequence point. In a combination of commas and semicolons, semicolons have lower precedence than commas, as semicolons separate statements but commas occur within statements, which accords with their use as ordinary punctuation: codice_5 is grouped as codice_6 because these are two separate statements.

In this example, the differing behavior between the second and third lines is due to the comma operator having lower precedence than assignment. The last example differs as well since the return expression must be fully evaluated before the function can return. 
The comma operator has relatively limited use cases. Because it discards its first operand, it is generally only useful where the first operand has desirable side effects that must be "sequenced before" the second operand. Further, because it is rarely used outside of specific idioms, and easily mistaken with other commas or the semicolon, it is potentially confusing and error-prone. Nevertheless, there are certain circumstances where it is commonly used, notably in for loops and in SFINAE. For embedded systems which may have limited debugging capabilities, the comma operator can be used in combination with a macro to seamlessly override a function call, to insert code just before the function call.

The most common use is to allow multiple assignment statements without using a block statement, primarily in the initialization and the increment expressions of a for loop. This is the only idiomatic use in elementary C programming. In the following example, the order of the loop's initializers is significant:

An alternative solution to this problem in other languages is parallel assignment, which allows multiple assignments to occur within a single statement, and also uses a comma, though with different syntax and semantics. This is used in Go in its analogous for loop.

Outside of for loop initializers (which have a special use of semicolons), the comma might be used instead of a semicolon, particularly when the statements in question function similarly to a loop increment (e.g. at the end of a while loop):

However, because there is a sequence point between the evaluations of these expressions, there may be negative consequence for the performance of such code; strictly speaking, when using the comma operator, codice_7 must complete before codice_8 may be evaluated (there is no such requirement when these expressions are evaluated as individual statements that are separated by a semicolon). Because modern machines are capable of executing such expressions in parallel, this unnecessary synchronization is probably undesirable.

The comma can be used in preprocessor macros to perform multiple operations in the space of a single syntactic expression.

One common use is to provide custom error messages in failed assertions. This is done by passing a parenthesized expression list to the codice_9 macro, where the first expression is an error string and the second expression is the condition being asserted. The codice_9 macro outputs its argument verbatim on an assertion failure. The following is an example:
Output:

However the assert macro is usually disabled in production code, so use it only for debug purposes.

The comma can be used within a condition (of an if, while, do while, or for) to allow auxiliary computations, particularly calling a function and using the result, with block scoping:

A similar idiom exists in Go, where the syntax of the if statement explicitly allows an optional statement.

The comma can be used in return statements, to assign to a global variable or out parameter (passed by reference). This idiom suggests that the assignments are part of the return, rather than auxiliary assignments in a block that terminates with the actual return. For example, in setting a global error number:

This can be written more verbosely as:
For brevity, the comma can be used to avoid a block and associated braces, as in:

instead of:
In the OCaml and Ruby programming languages, the semicolon (";") is used for this purpose. JavaScript and Perl utilize the comma operator in the same way C/C++ does. In Java, the comma is a separator used to separate elements in a list in various contexts. It is not an operator and does not evaluate to the last element in the list.





</doc>
<doc id="10824089" url="https://en.wikipedia.org/wiki?curid=10824089" title="Comparison of ALGOL 68 and C++">
Comparison of ALGOL 68 and C++

C++ doesn't have:

ALGOL 68 doesn't have:

Assigning values into an A68 codice_1 variable is automatic, 
the type is "tagged" to the variable, but pulling the value back out is 
syntactically awkward as a "conformity-clause" is required.

ALGOL 68 example:
C/C++ example:

The net effect of "type-tagging" is that Algol68's strong typing
"half" encroaches into the codice_1.

A new mode (type) may be declared using a codice_3 declaration:

This has the similar effect as the following C++ code:

const int max=99;
typedef struct { 
} newtype[9+1][max+1];

Note that for ALGOL 68 only the newtype name appears to the left of the equality, and most notably the construction is made - and can be read - from left to right without regard to priorities.



</doc>
<doc id="49208772" url="https://en.wikipedia.org/wiki?curid=49208772" title="Criticism of C++">
Criticism of C++

C++ is a general-purpose programming language with imperative, object-oriented, and generic programming features. Many criticisms have been leveled at C++'s design by well-known software developers including Linus Torvalds, Richard Stallman, Joshua Bloch, Rob Pike, Ken Thompson, and Donald Knuth.

C++ is a multi-paradigm programming language with extensive, but not complete, backward compatibility with C. This article focuses not on C features like pointer arithmetic, operator precedence or preprocessor macros, but on pure C++ features that are often criticized.

The natural interface between source files in C/C++ are header files. Each time a header file is modified, all source files that include the header file should recompile their code. Header files are slow because they are textual and context-dependent as a consequence of the preprocessor. C only has limited amounts of information in header files, the most important being struct declarations and function prototypes. C++ stores its classes in header files and they not only expose their public variables and public functions (like C with its structs and function prototypes) but also their private functions. This forces unnecessary recompiles of all source files that include the header file, each time when changing these private functions. This problem is magnified where the classes are written as templates, forcing all of their code into the slow header files, which is the case with the whole C++ standard library. Large C++ projects can therefore be relatively slow to compile. The problem is largely solved by precompiled headers in modern compilers.

One suggested solution is to use a module system.

C++ <iostream> unlike C <stdio.h> relies on a global format state. This fits very poorly together with exceptions, when a function must interrupt the control flow, after an error, but before resetting the global format state. One fix for this is to use Resource Acquisition Is Initialization (RAII) which is implemented in Boost but is not a part of the C++ Standard Library.

The global state of <iostream> uses static constructors which causes overhead. Another source of bad performance is the use of std::endl instead of '\n' when doing output, because of it calling flush as a side effect. C++ <iostream> is by default synchronized with <stdio.h> which can cause performance problems. Shutting it off can improve performance but forces giving up thread safety.

Here follows an example where an exception interrupts the function before std::cout can be restored from hexadecimal to decimal. The error number in the catch statement will be written out in hexadecimal which probably isn't what one wants: 
It is acknowledged even by some members of the C++ standards body that the iostreams interface is an aging interface that needs to be replaced eventually. This design forces the library implementers to adopt solutions that impact performance greatly.

After the inclusion of the STL in C++, its templated containers were promoted while the traditional C arrays were strongly discouraged. One important feature of containers like std::string and std::vector is them having their memory on the heap instead of on the stack like C arrays. To stop them from allocating on the heap, one would be forced to write a custom allocator, which isn't standard. Heap allocation is slower than stack allocation which makes claims about the classical C++ containers being "just as fast" as C arrays somewhat untrue. They are just as fast to use, but not to construct. One way to solve this problem was to introduce stack allocated containers like boost::array or std::array.

As for strings there is the possibility to use SSO (short string optimization) where only strings exceeding a certain size are allocated on the heap. There is however no standard way in C++ for the user to decide this SSO limit and it remains hard-coded and implementation-specific.

The philosophy of the Standard Template Library (STL) embedded in the C++ Standard Library is to use generic algorithms in the form of templates using iterators. Early compilers optimized small objects such as iterators poorly, which Alexander Stepanov characterized as the "abstraction penalty", although modern compilers optimize away such small abstractions well. The interface using pairs of iterators to denote ranges of elements has also been criticized, and ranges have been proposed for the C++ standard library.

One big problem is that iterators often deal with heap allocated data in the C++ containers and become invalid if the data is independently moved by the containers. Functions that change the size of the container often invalidate all iterators pointing to it, creating dangerous cases of undefined behavior. Here is an example where the iterators in the for loop get invalidated because of the std::string container changing its size on the heap:

The C++11 uniform initialization syntax and std::initializer_list share the same syntax which are triggered differently depending on the internal workings of the classes. If there is a std::initializer_list constructor then this is called. Otherwise the normal constructors are called with the uniform initialization syntax. This can be confusing for beginners and experts alike

There have been concerns that the zero-overhead principle isn't compatible with exceptions. Most modern implementations have a zero performance overhead when exceptions are enabled but not used, but do have an overhead during exception handling and in binary size due to the need to unroll tables. Many compilers support disabling exceptions from the language to save the binary overhead. Exceptions have also been criticized for being unsafe for state-handling, this safety issue has led to the invention of the RAII idiom, which has proven useful beyond making C++ exceptions safe.

C++ string literals, like those of C, do not consider the character encoding of the text within them: they are merely a sequence of bytes, and the C++ codice_1 class follows the same principle. Although source code can (since C++11) request an encoding for a literal, the compiler does not attempt to validate that the chosen encoding of the source literal is "correct" for the bytes being put into it, and the runtime does not enforce character encoding. Programmers who are used to other languages such as Java, Python or C# which try to enforce character encodings often consider this to be a defect of the language.

The example program below illustrates the phenomenon. 
Despite the presence of the C++11 'u8' prefix, meaning "Unicode UTF-8 string literal", the output of this program actually depends on the source file's text encoding (or the compiler's settings - most compilers can be told to convert source files to a specific encoding before compiling them). When the source file is encoded using UTF-8, and the output is run on a terminal that's configured to treat its input as UTF-8, the following output is obtained:

Note that the output terminal has stripped the invalid UTF-8 bytes from display in the ISO-8859 example string. Passing the program's output through a Hex_dump utility will reveal that they are still present in the program output, and it is the terminal application that removed them. 

However, when the same source file is instead saved in ISO-8859-1 and re-compiled, the output of the program on the same terminal becomes:

Some older implementations of C++ have been accused of generating code bloat.



</doc>
<doc id="49717495" url="https://en.wikipedia.org/wiki?curid=49717495" title="Reheapification">
Reheapification

Reheapification is a term promoted by some C++ textbooks to describe the process of fixing a binary search tree heap data structure, after a node is either removed or added. Other authors refer to the process of bubble up or bubble down.


</doc>
<doc id="715379" url="https://en.wikipedia.org/wiki?curid=715379" title="Variadic macro">
Variadic macro

A variadic macro is a feature of some computer programming languages, especially the C preprocessor, whereby a macro may be declared to accept a varying number of arguments. 

Variable-argument macros were introduced in 1999 in the "ISO/IEC 9899:1999" (C99) revision of the C language standard, and in 2011 in "ISO/IEC 14882:2011" (C++11) revision of the C++ language standard. Support for variadic macros with no arguments was added in C++20.

The declaration syntax is similar to that of variadic functions: a sequence of three full stops "" is used to indicate that one or more arguments must be passed. During macro expansion each occurrence of the special identifier in the macro replacement list is replaced by the passed arguments.

No means is provided to access individual arguments in the variable argument list, nor to find out how many were passed. However, macros can be written to count the number of arguments that have been passed.

Both the C99 and C++11 standards require at least one argument, but since C++20 this limitation has been lifted through the functional macro. The macro is replaced by its argument when arguments are present, and omitted otherwise. Common compilers also permit passing zero arguments before this addition, however.

Several compilers support variable-argument macros when compiling C and C++ code: the GNU Compiler Collection 3.0, Clang (all versions), Visual Studio 2005, C++Builder 2006, and Oracle Solaris Studio (formerly Sun Studio) Forte Developer 6 update 2 (C++ version 5.3). GCC also supports such macros when compiling Objective-C.

Support for the macro to support zero arguments has been added in GNU Compiler Collection 8, Clang 6, but notably not Visual Studio 2017.

If a codice_1-like function were desired, which would take the file and line number from which it was called as arguments, the following solution applies.

// Our implemented function
void realdbgprintf (const char *SourceFilename,

// Due to limitations of the variadic macro support in C++11 the following
// straightforward solution can fail and should thus be avoided:
// #define dbgprintf(cformat, ...) \
// realdbgprintf (__FILE__, __LINE__, cformat, __VA_ARGS__)
// The reason is that
// dbgprintf("Hallo")
// gets expanded to
// realdbgprintf (__FILE__, __LINE__, "Hallo", )
// where the comma before the closing brace will result in a syntax error.
// GNU C++ supports a non-portable extension which solves this.
// #define dbgprintf(cformat, ...) \
// realdbgprintf (__FILE__, __LINE__, cformat, ##__VA_ARGS__)
// C++20 eventually supports the following syntax.
// #define dbgprintf(cformat, ...) \
// realdbgprintf (__FILE__, __LINE__, cformat __VA_OPT__(,) __VA_ARGS__)
// By using the 'cformat' string as part of the variadic arguments we can
// circumvent the abovementioned incompatibilities. This is tricky but
// portable.
 could then be called as

dbgprintf ("Hello, world");

which expands to

realdbgprintf (__FILE__, __LINE__, "Hello, world");
Another example is

dbgprintf("%d + %d = %d", 2, 2, 5);

which expands to

realdbgprintf(__FILE__, __LINE__, "%d + %d = %d", 2, 2, 5);
Without variadic macros, writing wrappers to codice_1 is not directly possible. The standard workaround is to use the stdargs functionality of C/C++, and have the function call codice_3 instead.

There is a portability issue with generating a trailing comma with empty args for variadic macros in C99. Some compilers (e.g., Visual Studio) will silently eliminate the trailing comma. Other compilers (e.g.: GCC) support putting in front of .

The following application works

MYLOG("Too many balloons %u", 42);

which expands to

fprintf (stderr, "%s(%u): " "Too many balloons %u" "\n", __FILE__, __LINE__, 42);

which is equivalent to

fprintf (stderr, "%s(%u): Too many balloons %u\n", __FILE__, __LINE__, 42);

But look at this application:

MYLOG("Attention!");

which expands to

fprintf (stderr, "%s(%u): " "Attention!" "\n", __FILE__, __LINE__, );

which generates a syntax error with GCC.

GCC supports the following (non-portable) extension:


which removes the trailing comma when is empty.

Before the existence of variable-arguments in C99, it was quite common to use doubly nested parentheses to exploit the variable number of arguments that could be supplied to the function:

dbgprintf (("Hello, world %d", 27));

which expands to:

realdbgprintf ("Hello, world %d", 27);



</doc>
<doc id="23708477" url="https://en.wikipedia.org/wiki?curid=23708477" title="Concepts (C++)">
Concepts (C++)

Concepts are an extension to the templates feature provided by the C++ programming language. Published as an ISO Technical Specification ISO/IEC TS 19217:2015, concepts are named Boolean predicates on template parameters, evaluated at compile time. A concept may be associated with a template (class template, function template, or member function of a class template), in which case it serves as a "constraint": it limits the set of arguments that are accepted as template parameters.

The main uses of concepts are:


The following is a declaration of the concept "EqualityComparable" from the concept-enabled C++ standard library (which is a separate ISO Technical Specification, ISO/IEC DTS 21425). This concept is satisfied by any type codice_1 such that for lvalues codice_2 and codice_3 of type codice_1, the expressions codice_5 and codice_6 compile and their results are convertible to a type that satisfies the concept "Boolean":

A function template constrained on this concept may be declared as follows:

And may be called as usual:

If a programmer attempts to use a template argument that does not satisfy the requirements of the template, the compiler will generate an error. When concepts are not used, such errors are often difficult to understand because the error is not reported in the context of the call, but rather in an internal, often deeply nested, implementation context where the type was used.

For example, requires that its first two arguments be random-access iterators. If an argument is not an iterator, or is an iterator of a different category, an error will occur when std::sort attempts to use its parameters as bidirectional iterators:
Typical compiler diagnostic without concepts is over 50 lines of output, beginning with a failure to compile an expression that attempts to subtract two iterators:

If concepts are used, the error can be detected and reported in the context of the call:

Concepts can be used to choose function template overloads and class template specializations based on properties of their template arguments, as an alternative to SFINAE and tag dispatching. If an argument satisfies more than one concept, the overload associated with the more constrained concept is chosen.

Concepts may be used instead of the unconstrained type deduction placeholder in variable declarations and function return types:
Concepts, as specified in ISO/IEC TS 19217:2015, are implemented in GCC 6.

A different form of Concepts, popularly known as "C++0x Concepts," was temporarily accepted into the working paper for C++11 but was removed in 2009. In addition to concepts themselves, "C++0x Concepts" included "concept maps" (a feature that could make it possible, for example, for the concept "Stack" to accept , automatically mapping "Stack" operations such as `push()` to differently named operations on `std::vector`, such as `push_back()`) and "axioms" (a facility to specify semantic properties such as associativity or commutativity, allowing the compiler to take advantage of these properties without proof).

In contrast to this abandoned proposal, the C++20 version of Concepts is sometimes referred to as "Concepts Lite."

During the C++ standards committee meeting in March 2016, the evolution working group moved to merge Concepts into the mainline C++17 standard, but the motion was defeated in full committee.

Concepts v1 was merged into the C++20 draft.

"The One Range" version of Range feature that depend on concepts was also merged into C++20.





</doc>
<doc id="49517831" url="https://en.wikipedia.org/wiki?curid=49517831" title="Move assignment operator">
Move assignment operator

In the C++ programming language, the move assignment operator codice_1 is used for transferring a temporary object to an existing object. The move assignment operator, like most C++ operators, can be overloaded. Like the copy assignment operator it is a special member function.

If the move assignment operator is not explicitly defined, the compiler generates an implicit move assignment operator (C++11 and newer). The parameter of a move assignment operator is an rvalue reference (T&&) to type "T", where "T" is the object that defines the move assignment operator. The move assignment operator is different than a move constructor because a move assignment operator is called on an existing object, while a move constructor is called on an object created by the operation. Thereafter, the other object's data is no longer valid.

To overload the move assignment operator, the signature of the function must be:
T& operator=(T&& data)
To successfully overload the move assignment operator, the following conditions must be met:

Consider the following move assignment operator for a simple string class:
class String {


</doc>
<doc id="39287846" url="https://en.wikipedia.org/wiki?curid=39287846" title="Static (keyword)">
Static (keyword)

In the C programming language (and its close descendants such as C++ and Objective-C), codice_1 is a reserved word controlling both lifetime (as a static variable) and visibility (depending on "linkage"). The word codice_1 is also used in languages influenced by C, such as Java.

In C, codice_1 is a storage class (not to be confused with classes in object-oriented programming), as are codice_4, codice_5 and codice_6 (which are also reserved words). Every variable and function has one of these storage classes; if a declaration does not specify the storage class, a context-dependent default is used:

In these languages, the term "static variable" has two meanings which are easy to confuse:
Variables with storage class codice_4, which include variables declared at top level without an explicit storage class, are codice_1 in the first meaning but not the second.

The codice_1 keyword when prefixed while declaring a variable or a function can have other effects depending on where the declaration occurs. 
A variable declared as codice_1 at the top level of a source file (outside any function definitions) is only visible throughout that file ("file scope", also known as "internal linkage"). In this usage, the keyword codice_1 is known as an "access specifier".

Similarly, a static functiona function declared as codice_1 at the top level of a source file (outside any class definitions)is only visible throughout that file ("file scope", also known as "internal linkage").

Variables declared as codice_1 inside a function are statically allocated, thus keep their memory cell throughout all program execution, while having the same scope of visibility as automatic local variables (codice_5 and codice_6), meaning remain local to the function. Hence whatever values the function puts into its static local variables during one call will still be present when the function is called again.

In C++, member variables declared as codice_1 inside class definitions are class variables (shared between all class instances, as opposed to instance variables).

Similarly, a static methoda method declared as codice_1 inside a class definitionis meant to be relevant to all instances of a class rather than any specific instance.


</doc>
<doc id="51406524" url="https://en.wikipedia.org/wiki?curid=51406524" title="KFRlib">
KFRlib

KFRlib is an open-source cross-platform C++ DSP framework written in C++.
It is covered by a dual GPL/commercial license.

KFR is supported on the following platforms.





</doc>
<doc id="3713" url="https://en.wikipedia.org/wiki?curid=3713" title="Bjarne Stroustrup">
Bjarne Stroustrup

Bjarne Stroustrup (; ; born 30 December 1950) is a Danish computer scientist, most notable for the creation and development of the C++ programming language. He is a visiting professor at Columbia University, and works at Morgan Stanley as a Managing Director in New York.

Stroustrup has a master's degree in mathematics and computer science (1975) from Aarhus University, Denmark, and a PhD in computer science in 1979 from the University of Cambridge, England supervised by David Wheeler.

Stroustrup began developing C++ in 1979 (then called "C with Classes"), and, in his own words, "invented C++, wrote its early definitions, and produced its first implementation... chose and formulated the design criteria for C++, designed all its major facilities, and was responsible for the processing of extension proposals in the C++ standards committee." Stroustrup also wrote a textbook for the language in 1985, "The C++ Programming Language".

Stroustrup was the head of AT&T Bell Labs' Large-scale Programming Research department, from its creation until late 2002. Stroustrup was elected member of the National Academy of Engineering in 2004. He was elected a Fellow of the Association for Computing Machinery (ACM) in 1994 and the Institute of Electrical and Electronics Engineers (IEEE). From 2002 to 2014, Stroustrup was the College of Engineering Chair in Computer Science Professor at Texas A&M University. As of January 2014, Stroustrup is a Managing Director in the technology division of Morgan Stanley in New York City and a Visiting Professor in Computer Science at Columbia University.

Stroustrup has written or co-written a number of publications, including the books "A Tour of C++", "Programming: Principles and Practice Using C++", "The C++ Programming Language", "Design and Evolution of C++" and "The Annotated C++ Reference Manual".

Stroustrup has been a noble doctor at ITMO University since 2013.

Stroustrup won the Senior Dahl–Nygaard Prize in 2015. The same year, he was made a Fellow of the Computer History Museum for his invention of the C++ programming language. In 2017, the Institution of Engineering and Technology (IET) awarded him the Faraday Medal, for pioneering C++, one of the most influential programming languages in the history of computing. On January 3, 2018, Stroustrup was announced as the 2018 winner of the Charles Stark Draper Prize for Engineering, which comes with $500,000. He was named winner of 2018 Computer Pioneer Award of the IEEE Computer Society. He was awarded an honorary doctorate from the University Carlos III, Spain, on 25 January 2019.



</doc>
<doc id="3301054" url="https://en.wikipedia.org/wiki?curid=3301054" title="Pragma once">
Pragma once

In the C and C++ programming languages, codice_1 is a non-standard but widely supported preprocessor directive designed to cause the current source file to be included only once in a single compilation. Thus, codice_1 serves the same purpose as include guards, but with several advantages, including: less code, avoidance of name clashes, and sometimes improvement in compilation speed.




In this example, the inclusion of codice_3 in both codice_4 and codice_5 would ordinarily cause a compilation error, because a struct with a given name can only be defined a single time in a given compilation. The codice_1 directive serves to avoid this by ignoring subsequent inclusions of codice_3.

Using codice_1 allows the C preprocessor to include a header file when it is needed and to ignore an codice_9 directive otherwise. This has the effect of altering the behavior of the C preprocessor itself, and frees programmers to express file dependencies in a simple fashion, relieving them of the burden and tedium of manual management.

The most common alternative to codice_1 is to use codice_11 to set an #include guard macro, the name of which is picked by the programmer to be unique to that file. For example,

This approach minimally ensures that the contents of the include file are not seen more than once. This is more verbose, requires greater manual intervention, and is prone to programmer error as there are no mechanisms available to the compiler for prevention of accidental use of the same macro name in more than one file, which would result in only one of the files being included. Such errors are unlikely to remain undetected but can complicate the interpretation of a compiler error report. Since the pre-processor itself is responsible for handling codice_1, the programmer cannot make errors which cause name clashes.

In the absence of #include guards around codice_9 directives, the use of codice_1 will improve compilation speed for some compilers since it is a higher-level mechanism; the compiler itself can compare filenames or inodes without having to invoke the C preprocessor to scan the header for codice_15 and codice_16. Yet, since include guards appear very often and the overhead of opening files is significant, it is common for compilers to optimize the handling of include guards, making them as fast as codice_1.

Identifying the same file on a file system is not a trivial task. Symbolic links and especially hard links may cause the same file to be found under different names in different directories. Compilers may use a heuristic that compares file size, modification time and content. Additionally, codice_1 can do the wrong thing if the same file is intentionally copied into several parts of a project, e.g. when preparing the build. Whereas include guards would still protect from double definitions, codice_1 may or may not treat them as the same file in a compiler-dependent way. These difficulties, together with difficulties related to defining what constitutes the same file in the presence of hard links, networked file systems, etc. so far prevented the standardization of codice_1.

The use of #include guard macros allows dependent code to recognize and respond to slight differences in semantics or interfaces of competing alternatives. For example,

In this case, the direct determination for which API is available would make use of the fact that the include file had advertised itself with its #include guard macro.

The codice_9 directive is defined to represent a programmer's intention to actually include the text of a file at the point of the directive. This may occur several times within a single compilation unit, and is useful for evaluating macro-containing contents multiple times against changing definitions of the macro.

The use of codice_1, like the use of #include guard macros within an include file places the responsibility upon its authors in order to protect against undesired multiple inclusion. Over-reliance upon either mechanism on the part of programmers by direct, unprotected use of codice_9 directives without their own #include guard will lead to failure when using an include file that has not protected itself with either mechanism.



</doc>
<doc id="53972620" url="https://en.wikipedia.org/wiki?curid=53972620" title="C++20">
C++20

C++20 is the informal name for the revision of the ISO/IEC standard for the C++ programming language expected to follow C++17.
The C++ Standards Committee began planning C++20 in July 2017. The current draft is N4842.

C++20 adds more new major features than C++14 or C++17.

With the end of the summer 2019 meeting in Cologne the CD (Committee Draft) ballot phase opened. In the fall 2019 meeting in Belfast comment processing has been started in order to finalize the C++20 standard revision.

Below is a partial list of changes that have been accepted into or have been discussed for inclusion into C++20.

Changes applied to the C++20 working draft in July 2017 (Toronto) include:

Changes applied to the C++20 working draft in the fall meeting in November 2017 (Albuquerque) include:

Changes applied to the C++20 working draft in March 2018 (Jacksonville) include:

Changes applied to the C++20 working draft in the summer meeting in June 2018 (Rapperswil) include:

Changes applied to the C++20 working draft in the fall meeting in November 2018 (San Diego) include:

Changes applied to the C++20 working draft in the winter meeting in February 2019 (Kona) include:

Changes applied to the C++20 working draft in the summer meeting in July 2019 (Cologne) include:


Changes applied during the NB comment resolution in the fall meeting in November 2019 (Belfast) include:

Many new keywords added (and the new "spaceship operator", codice_2), such as codice_48, codice_18, codice_17, codice_51, codice_52, codice_53, codice_54 (plus changed meaning for codice_55), and codice_56. And codice_16 can take an expression since C++20. (Most of) the use for the codice_20 keyword has been deprecated.

In addition to keywords, there are "identifiers with special meaning", including new codice_59 and codice_60.

C++ has added a number of attributes over the years, including new in C++20, codice_8 and codice_9; and codice_7.






</doc>
<doc id="52292260" url="https://en.wikipedia.org/wiki?curid=52292260" title="SYCL">
SYCL

SYCL is a higher-level programming model for OpenCL as a single-source domain specific embedded language (DSEL) based on pure C++11 for SYCL 1.2.1 to improve programming productivity. This is a standard developed by Khronos Group, announced in March 2014.

SYCL (pronounced ‘sickle’) is a royalty-free, cross-platform abstraction layer that builds on the underlying concepts, portability and efficiency of OpenCL that enables code for heterogeneous processors to be written in a “single-source” style using completely standard C++. SYCL enables single source development where C++ template functions can contain both host and device code to construct complex algorithms that use OpenCL acceleration, and then re-use them throughout their source code on different types of data.

While originally developed for use with OpenCL and SPIR, it is actually a more general heterogeneous framework able to target other systems. For example, the hipSYCL implementation targets CUDA.

The latest version is SYCL 1.2.1 revision 6 which was published on November 14, 2019 (the first version was published on December 6, 2017).

SYCL was introduced at GDC in March 2014 with
provisional version 1.2, then the SYCL 1.2 final version was
introduced at IWOCL 2015 in May 2015.

SYCL 2.2 provisional was introduced at IWOCL 2016 in May 2016 targeting C++14 and OpenCL 2.2. But the SYCL committee preferred not to finalize this version and is working on a more flexible SYCL specification to address the increasing diversity of current accelerators, including artificial-intelligence engines.

The public version is:

The following example shows the single-source pure C++ programming model defining an implicit task graph of 3 kernels running on a default accelerator.

class init_a;
class init_b;
class matrix_add;

using namespace cl::sycl;

// Size of the matrices
constexpr size_t N = 2000;
constexpr size_t M = 3000;

int main() {

There are a few tutorials in the ComputeCpp SYCL guides.

The open standards SYCL and OpenCL are similar to vendor-specific CUDA from Nvidia.

In the Khronos Group realm, OpenCL is the low-level "non-single source" API and SYCL is the high-level "single-source" C++ domain-specific embedded language.

By comparison, the "single-source" C++ domain-specific embedded language version of CUDA, which is actually named "CUDA "Runtime" API", is somehow similar to SYCL.
But there is actually a less known "non single-source" version of CUDA which is called "CUDA "Driver" API", similar to OpenCL, and used for example by the CUDA "Runtime" API implementation itself.

SYCL extends the C++ AMP features relieving the programmer from explicitly transferring the data between the host and devices, by opposition to CUDA.

SYCL is higher-level than C++ AMP and CUDA since you do not need building an explicit dependency graph between all the kernels, and
provides you automatic asynchronous scheduling of the kernels with communication and computation overlap. This is
all done by using the concept of accessors, without requiring any compiler support.

By opposition to C++ AMP and CUDA, SYCL is a pure C++ DSEL without any C++ extension, allowing some basic CPU implementation relying on pure runtime without any specific compiler. This is very useful for debugging application or to prototype for a new architecture without having the architecture and compiler available yet.

The hipSYCL implementation adds SYCL higher-level programming to CUDA.




</doc>
<doc id="330297" url="https://en.wikipedia.org/wiki?curid=330297" title="Default argument">
Default argument

In computer programming, a default argument is an argument to a function that a programmer is not required to specify.
In most programming languages, functions may take one or more arguments. Usually, each argument must be specified in full (this is the case in the C programming language). Later languages (for example, in C++) allow the programmer to specify default arguments that always have a value, even if one is not specified when calling the function.

Consider the following function declaration:

This function takes three arguments, of which the last one has a default of twelve. The programmer may call this function in two ways:

In the first case the value for the argument called "c" is specified as normal. In the second case, the argument is omitted, and the default value of "12" will be used instead.

There is no means to know if the argument has been specified by the caller or if the default value was used.

The above-mentioned method is especially useful when one wants to set default criteria so that the function can be called with or without parameters.
Consider the following:

The function call:

will by default print "hello world!" to the standard output codice_1 (typically the screen). On the other hand, any object of type codice_2 can now be passed to the same function and the function will print to the given stream instead of to the standard output.
Because default arguments' values are "filled in" at the call site rather than in the body of the function being called, virtual functions take their default argument values from the static type of the pointer or reference through which the call is made, rather than from the dynamic type of the object supplying the virtual function's body.
Some languages, such as Java, do not have default arguments. However, the same behaviour can be simulated by using method overloading to create overloaded methods of the same name, which take different numbers of arguments; and the versions with fewer arguments simply call the versions with more arguments, with the default arguments as the missing arguments:

However, in addition to several other disadvantages, since the default arguments are not modeled in the type system, the type of a callback (aka higher-order function) can’t express that it accepts either of the overloads nor simulate the default arguments with overloaded functions. Whereas, in JavaScript the non-overloaded function definition can substitute the default when the input value is codice_3 (regardless if it was implicitly codice_3 via the argument’s absence at the call site or an explicitly passed codice_3 value); which is modeled as an optional argument parameter type codice_6 in TypeScript. JavaScript’s solution is not resolved statically (i.e. not at compile-time, which is why TypeScript models only the optionality and not the default values in the function’s type signature) thus incurs additional runtime overhead, although it does provide more flexibility in that callbacks can independently control their defaults instead of centrally dictated by the (callback’s type signature in the) type signature of the function which inputs the callback. The TypeScript solution can be simulated in Java with the codice_7 type except the analogous of an implicit codice_3 for each absent argument is an explicit codice_9 at the call site.

For every function call default argument values must be passed to the called function.

If a default argument value contains side-effects, it is significant when those side effects are evaluated – once for the entire program (at parse time, compile time, or load time), or once per function call, at call time.

Python is a notable language that evaluates expressions in default arguments once, at the time the function declaration is evaluated. If evaluation per function call is desired, it can be replicated by having the default argument be a sentinel value, such as codice_10, and then having the body of the function evaluate the default value's side effects only if the sentinel value was passed in.

For example:
Generally a default argument will behave identically to an argument passed by parameter or a local variable declared at the start of the function, and have the same scope and extent (lifetime) as a parameter or other local variable, namely an automatic variable which is deallocated on function termination.

In other cases a default argument may instead be statically allocated. If the variable is mutable, it will then retain its value across function calls, as with a static variable.

This behavior is found in Python for mutable types, such as lists. As with evaluation, in order to ensure the same extent as a local variable, one can use a sentinel value:


</doc>
<doc id="57666526" url="https://en.wikipedia.org/wiki?curid=57666526" title="C++/WinRT">
C++/WinRT

C++/WinRT is a C++ library for Microsoft's Windows Runtime platform, designed to provide access to modern Windows APIs. C++/WinRT is provided as a standard C++17 header file library, unlike C++/CX, which is an extension to C++ and requires a recent version of Microsoft Visual C++.

C++/WinRT was introduced as part of the Microsoft Windows SDK in version 10.0.17134.0 (Windows 10, version 1803). Microsoft Visual Studio support for C++/WinRT is provided by an officially-supported extension.

C++/WinRT was originally released in 2015 by Kenny Kerr, who shortly afterward joined Microsoft. C++/WinRT is now Microsoft's recommended replacement for both the Windows Runtime C++ Template Library, and for C++/CX.

Microsoft's Windows Runtime is based on Component Object Model (COM) APIs, and is designed to be accessed through "language projections". A language projection hides the COM details, and provides a more natural programming experience for a given language. For C++ developers, C++/WinRT is the officially supported, modern C++ language projection.

As of version 10.0.17134.0 (Windows 10, version 1803), the Microsoft Windows SDK contains a header-file-based standard C++ library for consuming first-party Windows APIs (that is, Windows Runtime APIs in Windows namespaces). C++/WinRT also ships with the codice_1 tool, which can be pointed at a Windows Runtime metadata (.winmd) file to generate a header-file-based standard C++ library that "projects" the APIs described in the metadata for consumption from C++/WinRT code. Windows Runtime metadata (.winmd) files provide a canonical way of describing a Windows Runtime API surface. By pointing the codice_1 tool at metadata, users can generate a library for use with any runtime class implemented in a second- or third-party Windows Runtime component, or implemented in their own application.

With C++/WinRT, users can also implement their own runtime classes using standard C++, without resorting to COM-style programming. For a runtime class, types can be described in a MIDL file (.idl), and from that file the codice_3 and codice_1 tools generate the implementation boilerplate source code files, ready for users to add their own implementation. Alternatively, users can just implement interfaces by deriving from a base class that's part of the C++/WinRT header library. These techniques employ the curiously recurring template pattern for function-calling via static dispatch. C++/WinRT makes use of a host of modern ISO C++11 (and later) language features to increase productivity and run-time performance. Features that were not available when C++/WinRT's predecessors (WRL and C++/CX) were designed.

Standard C++ data types, algorithms, and keywords are used with C++/WinRT; however, the projection also has its own custom data types.

C++/WinRT produces smaller binaries than other language options for the Windows Runtime.

Design and development of C++/WinRT was begun in 2014 by the then-independent software developer Kenny Kerr. At the time, the prevailing way for developers to call Windows Runtime APIs using C++ was with the C++/CX language projection. C++/CX adds non-standard extensions to the C++ language, such as the codice_5 and codice_6 (hat) notation inherited from C++/CLI. It hadn't been fully appreciated then that advances in ISO C++ language features meant that it had become possible to design a Windows Runtime language projection for standard C++, without extensions. "There are a lot of very experienced C++ developers at Microsoft who have spent decades-long careers working with C++ and COM," Kerr says. "I think it took someone who didn't realize that it was impossible to just try it anyway and show that it works."

"I had had some previous experience projecting COM APIs into modern C++, so I decided to see whether I could apply those same techniques to the Windows Runtime." One early challenge in developing C++/WinRT was managing the trade-offs that the Windows Runtime makes to support projections for JavaScript and managed .NET languages out of the box. The complexity in the way that generic collections work across language projections is another example of these design challenges, as was coming up with an efficient way for standard C++ to handle the Windows Runtime's interface-versioning model. "It really pushed my understanding of C++ at that time, and it's since pushed the Microsoft Visual C++ compiler to more efficiently handle such techniques at this scale."



</doc>
<doc id="1616966" url="https://en.wikipedia.org/wiki?curid=1616966" title="Class implementation file">
Class implementation file

In object-oriented programming, a class implementation file is often used to contain the implementation code for the method(s) of a class. This file is also referred to as a source file. Programming languages like C and C++ make use of these implementation files so as to separate the interface and implementation of these methods. 

Using this structure, a class definition file containing the declaration of the class and its members is also created. If the class definition has been included and the implementation file for its methods is available, the user can instantiate an object of the class. The purpose of this structure is to keep the implementation code hidden, but allow the user to view the design. 

Users make use of the public interface of an object so as to make creating objects as simple as possible, ensuring that client code does not distract the user with unnecessary details of the class's implementation.
This allows the user the information needed to use the class effectively, but prevents him or her from damaging the compiled code.

An implementation file is used in C++ programming when creating a class definition to split the interface from the implementation. The header file would declare all the member functions (methods) and data methods (fields) that the class has. 

The implementation file will contain the actual definition or source code of the methods declared in the header file. This file can start with a header block, which provides comments that describe the purpose of the defined class and any details about the creation of the actual file, such as the author of the file and date the file was created.
It can also include any libraries from the C++ Standard Library that will be used by any of the declared methods in the file. The class implementation file will usually have a line to include the associated header file (see examples below).

An example would be having a class called codice_1. The header file of this C++ file would be named "example_class.h" and the implementation file would be "example_class.cc".

An example of the structure of example_class.cc would look like this:
In this example, the implementation for the functions has been omitted, but the functions must be declared in example_class.h like this:
Another example of how a class implementation file would be structured can be seen with Objective-C, which is used in iOS programming.
This example will use "ExampleClass". A notable difference between C++ and Objective-C when making use of these implementation files is the extensions used at the end of the files. In C++ it will be .cpp
and in Objective-C it will be .m,
but both will use the same .h extension for their header file(s)
as shown in the example below.

This is an example of ExampleClass.h in Objective-C:
This is an example of the class's implementation file Exampleclass.m in Objective-C:



</doc>
<doc id="1907963" url="https://en.wikipedia.org/wiki?curid=1907963" title="Virtual inheritance">
Virtual inheritance

Virtual inheritance is a C++ technique that ensures only one copy of a base classs member variables are inherited by grandchild derived classes. Without virtual inheritance, if two classes codice_1 and codice_2 inherit from a class codice_3, and a class codice_4 inherits from both codice_1 and codice_2, then codice_4 will contain two copies of codice_3s member variables: one via codice_1, and one via codice_2. These will be accessible independently, using scope resolution.

Instead, if classes codice_1 and codice_2 inherit virtually from class codice_3, then objects of class codice_4 will contain only one set of the member variables from class codice_3.

This feature is most useful for multiple inheritance, as it makes the virtual base a common subobject for the deriving class and all classes that are derived from it. This can be used to avoid the diamond problem by clarifying ambiguity over which ancestor class to use, as from the perspective of the deriving class (codice_4 in the example above) the virtual base (codice_3) acts as though it were the direct base class of codice_4, not a class derived indirectly through a base (codice_1 or codice_2).

It is used when inheritance represents restriction of a set rather than composition of parts. In C++, a base class intended to be common throughout the hierarchy is denoted as virtual with the codice_21 keyword.

Consider the following class hierarchy.

struct Animal {

struct Mammal: Animal {

struct WingedAnimal: Animal {

// A bat is a winged mammal
struct Bat: Mammal, WingedAnimal {};

Bat bat;

As declared above, a call to codice_22 is ambiguous because there are two codice_23 (indirect) base classes in codice_24, so any codice_24 object has two different codice_23 base class subobjects. So an attempt to directly bind a reference to the codice_23 subobject of a codice_24 object would fail, since the binding is inherently ambiguous:

Bat b;
Animal& a = b; // error: which Animal subobject should a Bat cast into, 
To disambiguate, one would have to explicitly convert codice_29 to either base class subobject: 

Bat b;
Animal& mammal = static_cast<Mammal&>(b); 
Animal& winged = static_cast<WingedAnimal&>(b); 
In order to call codice_30, the same disambiguation, or explicit qualification is needed: codice_31 or codice_32 or alternatively codice_33 and codice_34. Explicit qualification not only uses an easier, uniform syntax for both pointers and objects but also allows for static dispatch, so it would arguably be the preferable method.

In this case, the double inheritance of codice_23 is probably unwanted, as we want to model that the relation (codice_24 is an codice_23) exists only once; that a codice_24 is a codice_39 and is a codice_40 does not imply that it is an codice_23 twice: an codice_23 base class corresponds to a contract that codice_24 implements (the "is a" relationship above really means ""implements the requirements of"), and a codice_24 only implements the codice_23 contract once. The real world meaning of "is a" only once" is that codice_24 should have only one way of implementing codice_30, not two different ways, depending on whether the codice_39 view of the codice_24 is eating, or the codice_40 view of the codice_24. (In the first code example we see that codice_30 is not overridden in either codice_39 or codice_40, so the two codice_23 subobjects will actually behave the same, but this is just a degenerate case, and that does not make a difference from the C++ point of view.)

This situation is sometimes referred to as diamond inheritance (see Diamond problem) because the inheritance diagram is in the shape of a diamond. Virtual inheritance can help to solve this problem.

We can re-declare our classes as follows:
struct Animal {

// Two classes virtually inheriting Animal:
struct Mammal: virtual Animal {

struct WingedAnimal: virtual Animal {

// A bat is still a winged mammal
struct Bat: Mammal, WingedAnimal {};

The codice_23 portion of codice_57 is now the "same" codice_23 instance as the one used by codice_59, which is to say that a codice_24 has only one, shared, codice_23 instance in its representation and so a call to codice_62 is unambiguous. Additionally, a direct cast from codice_24 to codice_23 is also unambiguous, now that there exists only one codice_23 instance which codice_24 could be converted to.

The ability to share a single instance of the codice_23 parent between codice_39 and codice_40 is enabled by recording the memory offset between the codice_39 or codice_40 members and those of the base codice_23 within the derived class. However this offset can in the general case only be known at runtime, thus codice_24 must become (codice_74, codice_39, codice_74, codice_40, codice_24, codice_23). There are two vtable pointers, one per inheritance hierarchy that virtually inherits codice_23. In this example, one for codice_39 and one for codice_40. The object size has therefore increased by two pointers, but now there is only one codice_23 and no ambiguity. All objects of type codice_24 will use the same vpointers, but each codice_24 object will contain its own unique codice_23 object. If another class inherits from codice_39, such as codice_88, then the vpointer in the codice_39 part of codice_88 will generally be different to the vpointer in the codice_39 part of codice_24 though they may happen to be the same should the codice_88 class be the same size as codice_24.


</doc>
<doc id="72038" url="https://en.wikipedia.org/wiki?curid=72038" title="C++">
C++

C++ () is a general-purpose programming language created by Bjarne Stroustrup as an extension of the C programming language, or "C with Classes". The language has expanded significantly over time, and modern C++ has object-oriented, generic, and functional features in addition to facilities for low-level memory manipulation. It is almost always implemented as a compiled language, and many vendors provide C++ compilers, including the Free Software Foundation, LLVM, Microsoft, Intel, Oracle, and IBM, so it is available on many platforms.

C++ was designed with a bias toward system programming and embedded, resource-constrained software and large systems, with performance, efficiency¸ and flexibility of use as its design highlights. C++ has also been found useful in many other contexts, with key strengths being software infrastructure and resource-constrained applications, including desktop applications, servers (e.g. e-commerce, Web search, or SQL servers), and performance-critical applications (e.g. telephone switches or space probes).

C++ is standardized by the International Organization for Standardization (ISO), with the latest standard version ratified and published by ISO in December 2017 as "ISO/IEC 14882:2017" (informally known as C++17). The C++ programming language was initially standardized in 1998 as "ISO/IEC 14882:1998", which was then amended by the C++03, C++11 and C++14 standards. The current C++17 standard supersedes these with new features and an enlarged standard library. Before the initial standardization in 1998, C++ was developed by Danish computer scientist Bjarne Stroustrup at Bell Labs since 1979 as an extension of the C language; he wanted an efficient and flexible language similar to C that also provided high-level features for program organization. C++20 is the next planned standard, keeping with the current trend of a new version every three years.

In 1979, Bjarne Stroustrup, a Danish computer scientist, began work on "", the predecessor to C++. The motivation for creating a new language originated from Stroustrup's experience in programming for his PhD thesis. Stroustrup found that Simula had features that were very helpful for large software development, but the language was too slow for practical use, while BCPL was fast but too low-level to be suitable for large software development. When Stroustrup started working in AT&T Bell Labs, he had the problem of analyzing the UNIX kernel with respect to distributed computing. Remembering his Ph.D. experience, Stroustrup set out to enhance the C language with Simula-like features. C was chosen because it was general-purpose, fast, portable and widely used. As well as C and Simula's influences, other languages also influenced this new language, including ALGOL 68, Ada, CLU and ML.

Initially, Stroustrup's "C with Classes" added features to the C compiler, Cpre, including classes, derived classes, strong typing, inlining and default arguments.

In 1982, Stroustrup started to develop a successor to C with Classes, which he named "C++" (++ being the increment operator in C) after going through several other names. New features were added, including virtual functions, function name and operator overloading, references, constants, type-safe free-store memory allocation (new/delete), improved type checking, and BCPL style single-line comments with two forward slashes (//). Furthermore, Stroustrup developed a new, standalone compiler for C++, Cfront.

In 1985, the first edition of "The C++ Programming Language" was released, which became the definitive reference for the language, as there was not yet an official standard. The first commercial implementation of C++ was released in October of the same year.

In 1989, C++ 2.0 was released, followed by the updated second edition of "The C++ Programming Language" in 1991. New features in 2.0 included multiple inheritance, abstract classes, static member functions, const member functions, and protected members. In 1990, "The Annotated C++ Reference Manual" was published. This work became the basis for the future standard. Later feature additions included templates, exceptions, namespaces, new casts, and a boolean type.

In 1998, C++98 was released, standardizing the language, and a minor update (C++03) was released in 2003.

After C++98, C++ evolved relatively slowly until, in 2011, the C++11 standard was released, adding numerous new features, enlarging the standard library further, and providing more facilities to C++ programmers. After a minor C++14 update released in December 2014, various new additions were introduced in C++17, and further changes planned for 2020.

As of 2019, C++ is now the fourth most popular programming language, behind Java, C, and Python.

On January 3, 2018, Stroustrup was announced as the 2018 winner of the Charles Stark Draper Prize for Engineering, "for conceptualizing and developing the C++ programming language".

According to Stroustrup, "the name signifies the evolutionary nature of the changes from C". This name is credited to Rick Mascitti (mid-1983) and was first used in December 1983. When Mascitti was questioned informally in 1992 about the naming, he indicated that it was given in a tongue-in-cheek spirit. The name comes from C's ++ operator (which increments the value of a variable) and a common naming convention of using "+" to indicate an enhanced computer program.

During C++'s development period, the language had been referred to as "new C" and "C with Classes" before acquiring its final name.

Throughout C++'s life, its development and evolution has been guided by a set of principles:


C++ is standardized by an ISO working group known as JTC1/SC22/WG21. So far, it has published five revisions of the C++ standard and is currently working on the next revision, C++20.

In 1998, the ISO working group standardized C++ for the first time as "ISO/IEC 14882:1998", which is informally known as "C++98". In 2003, it published a new version of the C++ standard called "ISO/IEC 14882:2003", which fixed problems identified in C++98.

The next major revision of the standard was informally referred to as "C++0x", but it was not released until 2011. C++11 (14882:2011) included many additions to both the core language and the standard library.

In 2014, C++14 (also known as C++1y) was released as a small extension to C++11, featuring mainly bug fixes and small improvements. The Draft International Standard ballot procedures completed in mid-August 2014.

After C++14, a major revision C++17, informally known as C++1z, was completed by the ISO C++ Committee in mid July 2017 and was approved and published in December 2017.

As part of the standardization process, ISO also publishes technical reports and specifications:
More technical specifications are in development and pending approval, including static reflection.

The C++ language has two main components: a direct mapping of hardware features provided primarily by the C subset, and zero-overhead abstractions based on those mappings. Stroustrup describes C++ as "a light-weight abstraction programming language [designed] for building and using efficient and elegant abstractions"; and "offering both hardware access and abstraction is the basis of C++. Doing it efficiently is what distinguishes it from other languages."

C++ inherits most of C's syntax. The following is Bjarne Stroustrup's version of the Hello world program that uses the C++ Standard Library stream facility to write a message to standard output:

As in C, C++ supports four types of memory management: static storage duration objects, thread storage duration objects, automatic storage duration objects, and dynamic storage duration objects.

Static storage duration objects are created before codice_1 is entered (see exceptions below) and destroyed in reverse order of creation after codice_1 exits. The exact order of creation is not specified by the standard (though there are some rules defined below) to allow implementations some freedom in how to organize their implementation. More formally, objects of this type have a lifespan that "shall last for the duration of the program".

Static storage duration objects are initialized in two phases. First, "static initialization" is performed, and only "after" all static initialization is performed, "dynamic initialization" is performed. In static initialization, all objects are first initialized with zeros; after that, all objects that have a constant initialization phase are initialized with the constant expression (i.e. variables initialized with a literal or codice_3). Though it is not specified in the standard, the static initialization phase can be completed at compile time and saved in the data partition of the executable. Dynamic initialization involves all object initialization done via a constructor or function call (unless the function is marked with codice_3, in C++11). The dynamic initialization order is defined as the order of declaration within the compilation unit (i.e. the same file). No guarantees are provided about the order of initialization between compilation units.

Variables of this type are very similar to static storage duration objects. The main difference is the creation time is just prior to thread creation and destruction is done after the thread has been joined.

The most common variable types in C++ are local variables inside a function or block, and temporary variables. The common feature about automatic variables is that they have a lifetime that is limited to the scope of the variable. They are created and potentially initialized at the point of declaration (see below for details) and destroyed in the "reverse" order of creation when the scope is left. This is implemented by allocation on the stack.

Local variables are created as the point of execution passes the declaration point. If the variable has a constructor or initializer this is used to define the initial state of the object. Local variables are destroyed when the local block or function that they are declared in is closed. C++ destructors for local variables are called at the end of the object lifetime, allowing a discipline for automatic resource management termed RAII, which is widely used in C++.

Member variables are created when the parent object is created. Array members are initialized from 0 to the last member of the array in order. Member variables are destroyed when the parent object is destroyed in the reverse order of creation. i.e. If the parent is an "automatic object" then it will be destroyed when it goes out of scope which triggers the destruction of all its members.

Temporary variables are created as the result of expression evaluation and are destroyed when the statement containing the expression has been fully evaluated (usually at the codice_5 at the end of a statement).

These objects have a dynamic lifespan and are created with a call to and destroyed explicitly with a call to . C++ also supports codice_6 and codice_7, from C, but these are not compatible with and .

C++ templates enable generic programming. C++ supports function, class, alias, and variable templates. Templates may be parameterized by types, compile-time constants, and other templates. Templates are implemented by "instantiation" at compile-time. To instantiate a template, compilers substitute specific arguments for a template's parameters to generate a concrete function or class instance. Some substitutions are not possible; these are eliminated by an overload resolution policy described by the phrase "Substitution failure is not an error" (SFINAE). Templates are a powerful tool that can be used for generic programming, template metaprogramming, and code optimization, but this power implies a cost. Template use may increase code size, because each template instantiation produces a copy of the template code: one for each set of template arguments, however, this is the same or smaller amount of code that would be generated if the code was written by hand. This is in contrast to run-time generics seen in other languages (e.g., Java) where at compile-time the type is erased and a single template body is preserved.

Templates are different from macros: while both of these compile-time language features enable conditional compilation, templates are not restricted to lexical substitution. Templates are aware of the semantics and type system of their companion language, as well as all compile-time type definitions, and can perform high-level operations including programmatic flow control based on evaluation of strictly type-checked parameters. Macros are capable of conditional control over compilation based on predetermined criteria, but cannot instantiate new types, recurse, or perform type evaluation and in effect are limited to pre-compilation text-substitution and text-inclusion/exclusion. In other words, macros can control compilation flow based on pre-defined symbols but cannot, unlike templates, independently instantiate new symbols. Templates are a tool for static polymorphism (see below) and generic programming.

In addition, templates are a compile time mechanism in C++ that is Turing-complete, meaning that any computation expressible by a computer program can be computed, in some form, by a template metaprogram prior to runtime.

In summary, a template is a compile-time parameterized function or class written without knowledge of the specific arguments used to instantiate it. After instantiation, the resulting code is equivalent to code written specifically for the passed arguments. In this manner, templates provide a way to decouple generic, broadly applicable aspects of functions and classes (encoded in templates) from specific aspects (encoded in template parameters) without sacrificing performance due to abstraction.

C++ introduces object-oriented programming (OOP) features to C. It offers classes, which provide the four features commonly present in OOP (and some non-OOP) languages: abstraction, encapsulation, inheritance, and polymorphism. One distinguishing feature of C++ classes compared to classes in other programming languages is support for deterministic destructors, which in turn provide support for the Resource Acquisition is Initialization (RAII) concept.

Encapsulation is the hiding of information to ensure that data structures and operators are used as intended and to make the usage model more obvious to the developer. C++ provides the ability to define classes and functions as its primary encapsulation mechanisms. Within a class, members can be declared as either public, protected, or private to explicitly enforce encapsulation. A public member of the class is accessible to any function. A private member is accessible only to functions that are members of that class and to functions and classes explicitly granted access permission by the class ("friends"). A protected member is accessible to members of classes that inherit from the class in addition to the class itself and any friends.

The object-oriented principle ensures the encapsulation of all and only the functions that access the internal representation of a type. C++ supports this principle via member functions and friend functions, but it does not enforce it. Programmers can declare parts or all of the representation of a type to be public, and they are allowed to make public entities not part of the representation of a type. Therefore, C++ supports not just object-oriented programming, but other decomposition paradigms such as modular programming.

It is generally considered good practice to make all data private or protected, and to make public only those functions that are part of a minimal interface for users of the class. This can hide the details of data implementation, allowing the designer to later fundamentally change the implementation without changing the interface in any way.

Inheritance allows one data type to acquire properties of other data types. Inheritance from a base class may be declared as public, protected, or private. This access specifier determines whether unrelated and derived classes can access the inherited public and protected members of the base class. Only public inheritance corresponds to what is usually meant by "inheritance". The other two forms are much less frequently used. If the access specifier is omitted, a "class" inherits privately, while a "struct" inherits publicly. Base classes may be declared as virtual; this is called virtual inheritance. Virtual inheritance ensures that only one instance of a base class exists in the inheritance graph, avoiding some of the ambiguity problems of multiple inheritance.

Multiple inheritance is a C++ feature not found in most other languages, allowing a class to be derived from more than one base class; this allows for more elaborate inheritance relationships. For example, a "Flying Cat" class can inherit from both "Cat" and "Flying Mammal". Some other languages, such as C# or Java, accomplish something similar (although more limited) by allowing inheritance of multiple interfaces while restricting the number of base classes to one (interfaces, unlike classes, provide only declarations of member functions, no implementation or member data). An interface as in C# and Java can be defined in C++ as a class containing only pure virtual functions, often known as an abstract base class or "ABC". The member functions of such an abstract base class are normally explicitly defined in the derived class, not inherited implicitly. C++ virtual inheritance exhibits an ambiguity resolution feature called dominance.

C++ provides more than 35 operators, covering basic arithmetic, bit manipulation, indirection, comparisons, logical operations and others. Almost all operators can be overloaded for user-defined types, with a few notable exceptions such as member access (codice_8 and codice_9) as well as the conditional operator. The rich set of overloadable operators is central to making user-defined types in C++ seem like built-in types.

Overloadable operators are also an essential part of many advanced C++ programming techniques, such as smart pointers. Overloading an operator does not change the precedence of calculations involving the operator, nor does it change the number of operands that the operator uses (any operand may however be ignored by the operator, though it will be evaluated prior to execution). Overloaded "codice_10" and "codice_11" operators lose their short-circuit evaluation property.

Polymorphism enables one common interface for many implementations, and for objects to act differently under different circumstances.

C++ supports several kinds of "static" (resolved at compile-time) and "dynamic" (resolved at run-time) polymorphisms, supported by the language features described above. Compile-time polymorphism does not allow for certain run-time decisions, while runtime polymorphism typically incurs a performance penalty.

Function overloading allows programs to declare multiple functions having the same name but with different arguments (i.e. "ad hoc" polymorphism). The functions are distinguished by the number or types of their formal parameters. Thus, the same function name can refer to different functions depending on the context in which it is used. The type returned by the function is not used to distinguish overloaded functions and would result in a compile-time error message.

When declaring a function, a programmer can specify for one or more parameters a default value. Doing so allows the parameters with defaults to optionally be omitted when the function is called, in which case the default arguments will be used. When a function is called with fewer arguments than there are declared parameters, explicit arguments are matched to parameters in left-to-right order, with any unmatched parameters at the end of the parameter list being assigned their default arguments. In many cases, specifying default arguments in a single function declaration is preferable to providing overloaded function definitions with different numbers of parameters.

Templates in C++ provide a sophisticated mechanism for writing generic, polymorphic code (i.e. parametric polymorphism). In particular, through the curiously recurring template pattern, it's possible to implement a form of static polymorphism that closely mimics the syntax for overriding virtual functions. Because C++ templates are type-aware and Turing-complete, they can also be used to let the compiler resolve recursive conditionals and generate substantial programs through template metaprogramming. Contrary to some opinion, template code will not generate a bulk code after compilation with the proper compiler settings.

Variable pointers and references to a base class type in C++ can also refer to objects of any derived classes of that type. This allows arrays and other kinds of containers to hold pointers to objects of differing types (references cannot be directly held in containers). This enables dynamic (run-time) polymorphism, where the referred objects can behave differently, depending on their (actual, derived) types.

C++ also provides the dynamic_cast operator, which allows code to safely attempt conversion of an object, via a base reference/pointer, to a more derived type: "downcasting". The "attempt" is necessary as often one does not know which derived type is referenced. ("Upcasting", conversion to a more general type, can always be checked/performed at compile-time via static_cast, as ancestral classes are specified in the derived class's interface, visible to all callers.) dynamic_cast relies on run-time type information (RTTI), metadata in the program that enables differentiating types and their relationships. If a dynamic_cast to a pointer fails, the result is the nullptr constant, whereas if the destination is a reference (which cannot be null), the cast throws an exception. Objects "known" to be of a certain derived type can be cast to that with static_cast, bypassing RTTI and the safe runtime type-checking of dynamic_cast, so this should be used only if the programmer is very confident the cast is, and will always be, valid.

Ordinarily, when a function in a derived class overrides a function in a base class, the function to call is determined by the type of the object. A given function is overridden when there exists no difference in the number or type of parameters between two or more definitions of that function. Hence, at compile time, it may not be possible to determine the type of the object and therefore the correct function to call, given only a base class pointer; the decision is therefore put off until runtime. This is called dynamic dispatch. Virtual member functions or "methods" allow the most specific implementation of the function to be called, according to the actual run-time type of the object. In C++ implementations, this is commonly done using virtual function tables. If the object type is known, this may be bypassed by prepending a fully qualified class name before the function call, but in general calls to virtual functions are resolved at run time.

In addition to standard member functions, operator overloads and destructors can be virtual. As a rule of thumb, if any function in the class is virtual, the destructor should be as well. As the type of an object at its creation is known at compile time, constructors, and by extension copy constructors, cannot be virtual. Nonetheless a situation may arise where a copy of an object needs to be created when a pointer to a derived object is passed as a pointer to a base object. In such a case, a common solution is to create a clone() (or similar) virtual function that creates and returns a copy of the derived class when called.

A member function can also be made "pure virtual" by appending it with = 0 after the closing parenthesis and before the semicolon. A class containing a pure virtual function is called an "abstract class". Objects cannot be created from an abstract class; they can only be derived from. Any derived class inherits the virtual function as pure and must provide a non-pure definition of it (and all other pure virtual functions) before objects of the derived class can be created. A program that attempts to create an object of a class with a pure virtual member function or inherited pure virtual member function is ill-formed.

C++ provides support for anonymous functions, also known as lambda expressions, with the following form:

The [capture] list supports the definition of closures. Such lambda expressions are defined in the standard as syntactic sugar for an unnamed function object. An example lambda function may be defined as follows:

Exception handling is used to communicate the existence of a runtime problem or error from where it was detected to where the issue can be handled. It permits this to be done in a uniform manner and separately from the main code, while detecting all errors. Should an error occur, an exception is thrown (raised), which is then caught by the nearest suitable exception handler. The exception causes the current scope to be exited, and also each outer scope (propagation) until a suitable handler is found, calling in turn the destructors of any objects in these exited scopes. At the same time, an exception is presented as an object carrying the data about the detected problem.

Note that many C++ style guides, such as Google's, LLVM's, Qt's, Apple's and Microsoft's, forbid the usage of exceptions.

The exception-causing code is placed inside a try block. The exceptions are handled in separate catch blocks (the handlers); each try block can have multiple exception handlers, as it is visible in the example below.

It is also possible to raise exceptions purposefully, using the throw keyword; these exceptions are handled in the usual way. In some cases, exceptions cannot be used due to technical reasons. One such example is a critical component of an embedded system, where every operation must be guaranteed to complete within a specified amount of time. This cannot be determined with exceptions as no tools exist to determine the maximum time required for an exception to be handled.

Unlike signal handling, in which the handling function is called from the point of failure, exception handling exits the current scope before the catch block is entered, which may be located in the current function or any of the previous function calls currently on the stack.

The C++ standard consists of two parts: the core language and the standard library. C++ programmers expect the latter on every major implementation of C++; it includes aggregate types (vectors, lists, maps, sets, queues, stacks, arrays, tuples), algorithms (find, for_each, binary_search, random_shuffle, etc.), input/output facilities (iostream, for reading from and writing to the console and files), filesystem library, localisation support, smart pointers for automatic memory management, regular expression support, multi-threading library, atomics support (allowing a variable to be read or written to by at most one thread at a time without any external synchronisation), time utilities (measurement, getting current time, etc.), a system for converting error reporting that doesn't use C++ exceptions into C++ exceptions, a random number generator and a slightly modified version of the C standard library (to make it comply with the C++ type system).

A large part of the C++ library is based on the Standard Template Library (STL). Useful tools provided by the STL include containers as the collections of objects (such as vectors and lists), iterators that provide array-like access to containers, and algorithms that perform operations such as searching and sorting.

Furthermore, (multi)maps (associative arrays) and (multi)sets are provided, all of which export compatible interfaces. Therefore, using templates it is possible to write generic algorithms that work with any container or on any sequence defined by iterators. As in C, the features of the library are accessed by using the #include directive to include a standard header. The C++ Standard Library provides 105 standard headers, of which 27 are deprecated.

The standard incorporates the STL that was originally designed by Alexander Stepanov, who experimented with generic algorithms and containers for many years. When he started with C++, he finally found a language where it was possible to create generic algorithms (e.g., STL sort) that perform even better than, for example, the C standard library qsort, thanks to C++ features like using inlining and compile-time binding instead of function pointers. The standard does not refer to it as "STL", as it is merely a part of the standard library, but the term is still widely used to distinguish it from the rest of the standard library (input/output streams, internationalization, diagnostics, the C library subset, etc.).

Most C++ compilers, and all major ones, provide a standards-conforming implementation of the C++ standard library.

To give compiler vendors greater freedom, the C++ standards committee decided not to dictate the implementation of name mangling, exception handling, and other implementation-specific features. The downside of this decision is that object code produced by different compilers is expected to be incompatible. There were, however, attempts to standardize compilers for particular machines or operating systems (for example C++ ABI), though they seem to be largely abandoned now.

C++ is often considered to be a superset of C but this is not strictly true. Most C code can easily be made to compile correctly in C++ but there are a few differences that cause some valid C code to be invalid or behave differently in C++. For example, C allows implicit conversion from void* to other pointer types but C++ does not (for type safety reasons). Also, C++ defines many new keywords, such as new and class, which may be used as identifiers (for example, variable names) in a C program.

Some incompatibilities have been removed by the 1999 revision of the C standard (C99), which now supports C++ features such as line comments (//) and declarations mixed with code. On the other hand, C99 introduced a number of new features that C++ did not support that were incompatible or redundant in C++, such as variable-length arrays, native complex-number types (however, the std::complex class in the C++ standard library provides similar functionality, although not code-compatible), designated initializers, compound literals, and the restrict keyword. Some of the C99-introduced features were included in the subsequent version of the C++ standard, C++11 (out of those which were not redundant). However, the C++11 standard introduces new incompatibilities, such as disallowing assignment of a string literal to a character pointer, which remains valid C.

To intermix C and C++ code, any function declaration or definition that is to be called from/used both in C and C++ must be declared with C linkage by placing it within an extern "C" {/*...*/} block. Such a function may not rely on features depending on name mangling (i.e., function overloading).

Despite its widespread adoption, some notable programmers have criticized the C++ language, including Linus Torvalds, Richard Stallman, Joshua Bloch, Ken Thompson, and Donald Knuth.

One of the most often criticised points of C++ is its perceived complexity as a language, with the criticism that a large number of non-orthogonal features in practice necessitates restricting code to subset of C++, thus eschewing the readability benefits of common style and idioms. As expressed by Joshua Bloch: I think C++ was pushed well beyond its complexity threshold, and yet there are a lot of people programming it. But what you do is you force people to subset it. So almost every shop that I know of that uses C++ says, “Yes, we’re using C++ but we’re not doing multiple-implementation inheritance and we’re not using operator overloading.” There are just a bunch of features that you’re not going to use because the complexity of the resulting code is too high. And I don’t think it’s good when you have to start doing that. You lose this programmer portability where everyone can read everyone else’s code, which I think is such a good thing. 

Donald Knuth (1993, commenting on pre-standardized C++), who said of Edsger Dijkstra that "to think of programming in C++" "would make him physically ill": The problem that I have with them today is that... C++ is too complicated. At the moment, it's impossible for me to write portable code that I believe would work on lots of different systems, unless I avoid all exotic features. Whenever the C++ language designers had two competing ideas as to how they should solve some problem, they said "OK, we'll do them both". So the language is too baroque for my taste. 

Ken Thompson, who was a colleague of Stroustrup at Bell Labs, gives his assessment: It certainly has its good points. But by and large I think it’s a bad language. It does a lot of things half well and it’s just a garbage heap of ideas that are mutually exclusive. Everybody I know, whether it’s personal or corporate, selects a subset and these subsets are different. So it’s not a good language to transport an algorithm—to say, “I wrote it; here, take it.” It’s way too big, way too complex. And it’s obviously built by a committee. 
Stroustrup campaigned for years and years and years, way beyond any sort of technical contributions he made to the language, to get it adopted and used. And he sort of ran all the standards committees with a whip and a chair. And he said “no” to no one. He put every feature in that language that ever existed. It wasn’t cleanly designed—it was just the union of everything that came along. And I think it suffered drastically from that. 

However Brian Kernighan, also a colleague at Bell Labs, disputes this assessment: C++ has been enormously influential. ... Lots of people say C++ is too big and too complicated etc. etc. but in fact it is a very powerful language and pretty much everything that is in there is there for a really sound reason: it is not somebody doing random invention, it is actually people trying to solve real world problems. Now a lot of the programs that we take for granted today, that we just use, are C++ programs. 

Stroustrup himself comments that C++ semantics are much cleaner than its syntax: "within C++, there is a much smaller and cleaner language struggling to get out".

Other complaints may include a lack of reflection or garbage collection, long compilation times, perceived feature creep, and verbose error messages, particularly from template metaprogramming.





</doc>
<doc id="3172" url="https://en.wikipedia.org/wiki?curid=3172" title="ANSI C">
ANSI C

ANSI C, ISO C and Standard C are successive standards for the C programming language published by the American National Standards Institute (ANSI) and the International Organization for Standardization (ISO). Historically, the names referred specifically to the original and best-supported version of the standard (known as C89 or C90). Software developers writing in C are encouraged to conform to the standards, as doing so helps portability between compilers.

The first standard for C was published by ANSI. Although this document was subsequently adopted by International Organization for Standardization (ISO) and subsequent revisions published by ISO have been adopted by ANSI, "ANSI C" is still used to refer to the standard. While some software developers use the term ISO C, others are standards-body neutral and use Standard C.

In 1983, the American National Standards Institute formed a committee, X3J11, to establish a standard specification of C. The standard was completed in 1989 and ratified as ANSI X3.159-1989 "Programming Language C." This version of the language is often referred to as "ANSI C". Later on sometimes the label "C89" is used to distinguish it from C99 but using the same labelling method.

The same standard as C89 was ratified by the International Organization for Standardization as ISO/IEC 9899:1990, with only formatting changes, which is sometimes referred to as C90. Therefore, the terms "C89" and "C90" refer to essentially the same language.

This standard has been withdrawn by both ANSI/INCITS and ISO/IEC.

In 1995, the ISO published an extension, called Amendment 1, for the ANSI-C standard. Its full name finally was "ISO/IEC 9899:1990/AMD1:1995" or nicknamed "C95". Aside from error correction there were further changes to the language capabilities, such as:


In addition to the amendment, two technical corrigenda were published by ISO for C90:


In March 2000, ANSI adopted the ISO/IEC 9899:1999 standard. This standard is commonly referred to as C99. Some notable additions to the previous standard include:


Three technical corrigenda were published by ISO for C99:


This standard has been withdrawn by both ANSI/INCITS and ISO/IEC in favour of C11.

, "C11" is the previous standard for the C programming language. Notable features introduced over the previous revision include improved Unicode support, type-generic expressions using the new codice_17 keyword, a cross-platform multi-threading API (codice_18) and atomic types support in both core language and the library (codice_19).

One technical corrigendum has been published by ISO for C11:


, "C18" is the current standard for the C programming language.

As part of the standardization process, ISO also publishes technical reports and specifications related to the C language:

More technical specifications are in development and pending approval, including the fifth and final part of TS 18661, a software transactional memory specification, and parallel library extensions.

ANSI C is now supported by almost all the widely used compilers. GCC and Clang are two major C compilers popular today, both are based on the C11 with updates including changes from later specifications such as C17 and C18. Any program written "only" in standard C and without any hardware dependent assumptions is virtually guaranteed to compile correctly on any platform with a conforming C implementation. Without such precautions, most programs may compile only on a certain platform or with a particular compiler, due, for example, to the use of non-standard libraries, such as GUI libraries, or to the reliance on compiler- or platform-specific attributes such as the exact size of certain data types and byte endianness.

To mitigate the differences between K&R C and the ANSI C standard, the codice_20 ("standard c") macro can be used to split code into ANSI and K&R sections.
In the above example, a prototype is used in a function declaration for ANSI compliant implementations, while an obsolescent non-prototype declaration is used otherwise. Those are still ANSI-compliant as of C99. Note how this code checks both definition and evaluation: this is because some implementations may set codice_20 to zero to indicate non-ANSI compliance.





</doc>
<doc id="22652294" url="https://en.wikipedia.org/wiki?curid=22652294" title="ANSI/ISO C Specification Language">
ANSI/ISO C Specification Language

The ANSI/ISO C Specification Language (ACSL) is a specification language for C programs, using Hoare style pre- and postconditions and invariants, that follows the design by contract paradigm. Specifications are written as C annotation comments to the C program, which hence can be compiled with any C compiler.

The current verification tool for ACSL is Frama-C.

In 1983, the American National Standards Institute (ANSI) commissioned a committee, X3J11, to standardize the C language. The first standard for C was published by ANSI. Although this document was subsequently adopted by International Organization for Standardization (ISO) and subsequent revisions published by ISO have been adopted by ANSI, the name ANSI C continues to be used.

ACSL is a Behavioral Interface Specification Language (BISL). It aims at specifying behavioral properties of C source code. The main inspiration for this language comes from the specification language of the Caduceus tool for deductive verification of behavioral properties of C programs. The specification language of Caduceus is itself inspired from JML which aims at similar goals for Java source code.

One difference with JML, is that ACSL aims at static verification and deductive verification whereas JML aims both at runtime assertion checking and static verification using for instance the ESC/Java tool.

Consider the following example for the prototype of a function named codice_1:

The contract is given by the comment which starts with codice_2. Its meaning is as follows:

Most of the features of ACSL are supported by Frama-C.


The complete ACSL specification is available from the download page of Frama-C.


</doc>
<doc id="33011281" url="https://en.wikipedia.org/wiki?curid=33011281" title="Bitwise operations in C">
Bitwise operations in C

In the C programming language, operations can be performed on a bit level using bitwise operators.

Bitwise operations are contrasted by byte-level operations which characterize the bitwise operators' logical counterparts, the AND, OR and NOT operators. Instead of performing on individual bits, byte-level operators perform on strings of eight bits (known as bytes) at a time. The reason for this is that a byte is normally the smallest unit of addressable memory (i.e. data with a unique memory address).

This applies to bitwise operators as well, which means that even though they operate on only one bit at a time they cannot accept anything smaller than a byte as their input.

All of these operators are also available in C++.

C provides six operators for bit manipulation.

The bitwise AND operator is a single ampersand: codice_1. It is just a representation of AND which does its work on the bits of the operands rather than the truth value of the operands. Bitwise binary AND does the logical AND (as shown in the table above) of the bits in each position of a number in its binary form.

For instance, working with a byte (the char type):

The most significant bit of the first number is 1 and that of the second number is also 1 so the most significant bit of the result is 1; in the second most significant bit, the bit of second number is zero, so we have the result as 0. 

Similar to bitwise AND, bitwise OR only operates at the bit level. Its result is a 1 if one of the either bits is 1 and zero only when both bits are 0. Its symbol is codice_3 which can be called a pipe.

The bitwise XOR (exclusive or) performs a logical XOR function, which is equivalent to adding two bits and discarding the carry. The result is zero only when we have two zeroes or two ones. XOR can be used to toggle the bits between 1 and 0. Thus codice_6 when used in a loop toggles its values between 1 and 0.

The ones' complement (codice_7) or the bitwise complement gets us the complement of a given number. Thus we get the bits inverted, for every bit codice_9 the result is bit codice_10 and conversely for every bit codice_10 we have a bit codice_9. This operation should not be confused with logical negation codice_13.

There are two bitwise shift operators. They are

The symbol of right shift operator is codice_14. For its operation, it requires two operands. It shifts each bit in its left operand to the right.
The number following the operator decides the number of places the bits are shifted (i.e. the right operand).
Thus by doing codice_18 all the bits will be shifted to the right by three places and so on.

Example:

Here blank spaces are generated simultaneously on the left when the bits are shifted to the right. When performed on an unsigned type, the operation performed is a logical shift, causing the blanks to be filled by codice_10s (zeros). When performed on a signed type, the result is technically undefined and compiler dependent, however most compilers will perform an arithmetic shift, causing the blank to be filled with the sign bit of the left operand.

Right shift can be used to divide a bit pattern by 2 as shown:

i = 14; // Bit pattern 00001110
j = i » 1; // here we have the bit pattern shifted by 1 thus we get 00000111 = 7 which is 14/2 
Typical usage of a right shift operator in C can be seen from the following code.

Example:

void showbits( unsigned int x )

int main( void )

The output of the above program will be

5225 in binary 00000000000000000001010001101001
5225 right shift 0 gives 00000000000000000001010001101001
5225 right shift 1 gives 00000000000000000000101000110100
5225 right shift 2 gives 00000000000000000000010100011010
5225 right shift 3 gives 00000000000000000000001010001101
5225 right shift 4 gives 00000000000000000000000101000110
5225 right shift 5 gives 00000000000000000000000010100011
The symbol of left shift operator is codice_15. It shifts each bit in its left-hand operand to the left by the number of positions indicated by the right-hand operand. It works opposite to that of right shift operator. Thus by doing codice_28 in the above example we have codice_29.
Blank spaces generated are filled up by zeroes as above.

Left shift can be used to multiply an integer by powers of 2 as in

int i = 4; /* bit pattern equivalent is binary 100 */
int j = i « 2; /* makes it binary 10000, which multiplies the original number by 4 i.e. 16 */
The following program adds two operands using AND, XOR and left shift («).


int main( void )

C provides a compound assignment operator for each binary arithmetic and bitwise operation (i.e. each operation which accepts two operands). Each of the compound bitwise assignment operators perform the appropriate binary operation and store the result in the left operand.

The bitwise assignment operators are as follows:

Four of the bitwise operators have equivalent logical operators. They are equivalent in that they have the same truth tables. However, logical operators treat each operand as having only one value, either true or false, rather than treating each bit of an operand as an independent value. Logical operators consider zero false and any nonzero value true. Another difference is that logical operators perform short-circuit evaluation.

The table below matches equivalent operators and shows a and b as operands of the operators.

codice_30 has the same truth table as codice_5 but unlike the true logical operators, by itself codice_30 is not strictly speaking a logical operator. This is because a logical operator must treat any nonzero value the same. To be used as a logical operator codice_30 requires that operands be normalized first. A logical not applied to both operands won’t change the truth table that results but will ensure all nonzero values are converted to the same value before comparison. This works because codice_13 on a zero always results in a one and codice_13 on any nonzero value always results in a zero.

Example:

/* Equivalent bitwise and logical operator tests */

void testOperator(char* name, unsigned char was, unsigned char expected);

int main( void )

void testOperator( char* name, unsigned char was, unsigned char expected )

The output of the above program will be




</doc>
<doc id="24318293" url="https://en.wikipedia.org/wiki?curid=24318293" title="Blocks (C language extension)">
Blocks (C language extension)

Blocks are a non-standard extension added by Apple Inc. to Clang's implementations of the C, C++, and Objective-C programming languages that uses a lambda expression-like syntax to create closures within these languages. Blocks are supported for programs developed for Mac OS X 10.6+ and iOS 4.0+, although third-party runtimes allow use on Mac OS X 10.5 and iOS 2.2+ and non-Apple systems.

Apple designed blocks with the explicit goal of making it easier to write programs for the Grand Central Dispatch threading architecture, although it is independent of that architecture and can be used in much the same way as closures in other languages. Apple has implemented blocks both in their own branch of the GNU Compiler Collection and in the upstream Clang LLVM compiler front end. Language runtime library support for blocks is also available as part of the LLVM project. The Khronos group uses blocks syntax to enqueue kernels from within kernels as of version 2.0 of OpenCL.

Like function definitions, blocks can take arguments, and declare their own variables internally. Unlike ordinary C function definitions, their value can capture state from their surrounding context. A block definition produces an opaque value which contains both a reference to the code within the block and a snapshot of the current state of local stack variables at the time of its definition. The block may be later invoked in the same manner as a function pointer. The block may be assigned to variables, passed to functions, and otherwise treated like a normal function pointer, although the application programmer (or the API) must mark the block with a special operator (Block_copy) if it's to be used outside the scope in which it was defined.

Given a block value, the code within the block can be executed at any later time by calling it, using the same syntax that would be used for calling a function.

A simple example capturing mutable state in the surrounding scope is an integer range iterator:
Blocks bear a superficial resemblance to GCC's extension of C to support lexically scoped nested functions. However, GCC's nested functions, unlike blocks, must not be called after the containing scope has exited, as that would result in undefined behavior.

GCC-style nested functions currently use dynamic creation of executable thunks on most architectures when taking the address of the nested function. On most architectures (including X86), these thunks are created on the stack, which requires marking the stack executable. Executable stacks are generally considered to be a potential security hole. Blocks do not require the use of executable thunks, so they do not share this weakness. On the other hand, blocks introduces a completely new type for the pointer, while pointers to nested functions in GCC are regular function pointers and can be used directly with existing code.




</doc>
<doc id="14678319" url="https://en.wikipedia.org/wiki?curid=14678319" title="C alternative tokens">
C alternative tokens

C alternative tokens refer to a set of alternative spellings of common operators in the C programming language. They are implemented as a group of macro constants in the C standard library in the codice_1 header. The tokens were created by Bjarne Stroustrup for the pre-standard C++ language and were added to the C standard in a 1995 amendment to the C90 standard via library to avoid the breakage of existing code.

The alternative tokens allow programmers to use C language bitwise and logical operators which could otherwise be hard to type on some international and non-QWERTY keyboards. The name of the header file they are implemented in refers to the ISO/IEC 646 standard, a 7-bit character set with a number of regional variations, some of which have accented characters in place of the punctuation marks used by C operators.

The codice_1 header defines the following 11 macros as stated below:

The above-mentioned identifiers are operator keywords in the ISO C++ programming language and do not require the inclusion of a header file. For consistency, the C++98 standard provides the header codice_3. However the latter file has no effect, being empty. Some compilers, such as Microsoft Visual C++ have, at least in the past, required the header to be included in order to use these identifiers.



</doc>
<doc id="231835" url="https://en.wikipedia.org/wiki?curid=231835" title="C preprocessor">
C preprocessor

The C preprocessor or cpp is the macro preprocessor for the C and C++ computer programming languages. The preprocessor provides the ability for the inclusion of header files, macro expansions, conditional compilation, and line control.

In many C implementations, it is a separate program invoked by the compiler as the first part of translation.

The language of preprocessor directives is only weakly related to the grammar of C, and so is sometimes used to process other kinds of text files.

Preprocessing is defined by the first four (of eight) "phases of translation" specified in the C Standard.


One of the most common uses of the preprocessor is to include another file:

The preprocessor replaces the line codice_2 with the text of the file 'stdio.h', which declares the codice_3 function among other things.

This can also be written using double quotes, e.g. codice_4. If the filename is enclosed within angle brackets, the file is searched for in the standard compiler include paths. If the filename is enclosed within double quotes, the search path is expanded to include the current source directory. C compilers and programming environments all have a facility which allows the programmer to define where include files can be found. This can be introduced through a command line flag, which can be parameterized using a makefile, so that a different set of include files can be swapped in for different operating systems, for instance.

By convention, include files have a ".h" extension, and files not included by others have a ".c" extension. However, there is no requirement that this be observed. Files with a ".def" extension may denote files designed to be included multiple times, each time expanding the same repetitive content; codice_5 is likely to refer to an XBM image file (which is at the same time a C source file).

codice_6 often compels the use of codice_6 guards or codice_8 to prevent double inclusion.

The if-else directives codice_9, codice_10, codice_11, codice_12, codice_13 and codice_14 can be used for conditional compilation.

Most compilers targeting Microsoft Windows implicitly define codice_15. This allows code, including preprocessor commands, to compile only when targeting Windows systems. A few compilers define codice_16 instead. For such compilers that do not implicitly define the codice_15 macro, it can be specified on the compiler's command line, using codice_18.

The example code tests if a macro codice_19 is defined. If it is, the file codice_20 is then included. Otherwise, it tests if a macro codice_15 is defined instead. If it is, the file codice_22 is then included.

A more complex codice_9 example can use operators, for example something like:

Translation can also be caused to fail by using the codice_24 directive:

There are two types of macros, "object-like" and "function-like". Object-like macros do not take parameters; function-like macros do (although the list of parameters may be empty). The generic syntax for declaring an identifier as a macro of each type is, respectively:

The "function-like" macro declaration must not have any whitespace between the identifier and the first, opening, parenthesis. If whitespace is present, the macro will be interpreted as object-like with everything starting from the first parenthesis added to the token list.

A macro definition can be removed with codice_25:
Whenever the identifier appears in the source code it is replaced with the replacement token list, which can be empty. For an identifier declared to be a function-like macro, it is only replaced when the following token is also a left parenthesis that begins the argument list of the macro invocation. The exact procedure followed for expansion of function-like macros with arguments is subtle.

Object-like macros were conventionally used as part of good programming practice to create symbolic names for constants, e.g.,

instead of hard-coding numbers throughout the code. An alternative in both C and C++, especially in situations in which a pointer to the number is required, is to apply the codice_26 qualifier to a global variable. This causes the value to be stored in memory, instead of being substituted by the preprocessor.

An example of a function-like macro is:

This defines a radians-to-degrees conversion which can be inserted in the code where required, i.e., codice_27. This is expanded in-place, so that repeated multiplication by the constant is not shown throughout the code. The macro here is written as all uppercase to emphasize that it is a macro, not a compiled function.

The second is enclosed in its own pair of parentheses to avoid the possibility of incorrect order of operations when it is an expression instead of a single value. For example, the expression expands correctly as ; without parentheses, gives precedence to the multiplication.

Similarly, the outer pair of parentheses maintain correct order of operation. For example, expands to ; without parentheses, gives precedence to the division.

"function-like" macro expansion occurs in the following stages:


This may produce surprising results:

Certain symbols are required to be defined by an implementation during preprocessing. These include codice_28 and codice_29, predefined by the preprocessor itself, which expand into the current file and line number. For instance the following:

prints the value of codice_30, preceded by the file and line number to the error stream, allowing quick access to which line the message was produced on. Note that the codice_31 argument is concatenated with the string following it. The values of codice_28 and codice_29 can be manipulated with the codice_34 directive. The codice_34 directive determines the line number and the file name of the line below. E.g.:

generates the printf function:

Source code debuggers refer also to the source position defined with codice_28 and codice_29.
This allows source code debugging, when C is used as target language of a compiler, for a totally different language.
The first C Standard specified that the macro codice_38 be defined to 1 if the implementation conforms to the ISO Standard and 0 otherwise, and the macro codice_39 defined as a numeric literal specifying the version of the Standard supported by the implementation. Standard C++ compilers support the codice_40 macro. Compilers running in non-standard mode must not set these macros, or must define others to signal the differences.

Other Standard macros include codice_41, the current date, and codice_42, the current time.

The second edition of the C Standard, C99, added support for codice_43, which contains the name of the function definition within which it is contained, but because the preprocessor is agnostic to the grammar of C, this must be done in the compiler itself using a variable local to the function.

Macros that can take a varying number of arguments (variadic macros) are not allowed in C89, but were introduced by a number of compilers and standardised in C99. Variadic macros are particularly useful when writing wrappers to functions taking a variable number of parameters, such as codice_44, for example when logging warnings and errors.

One little-known usage pattern of the C preprocessor is known as X-Macros. An X-Macro is a header file. Commonly these use the extension ".def" instead of the traditional ".h". This file contains a list of similar macro calls, which can be referred to as "component macros". The include file is then referenced repeatedly.

Many compilers define additional, non-standard macros, although these are often poorly documented. A common reference for these macros is the Pre-defined C/C++ Compiler Macros project, which lists "various pre-defined compiler macros that can be used to identify standards, compilers, operating systems, hardware architectures, and even basic run-time libraries at compile-time".

The # operator (known as the "Stringification Operator") converts a token into a C string literal, escaping any quotes or backslashes appropriately.

Example:

If you want to stringify the expansion of a macro argument, you have to use two levels of macros:

You cannot combine a macro argument with additional text and stringify it all together. You can however write a series of adjacent string constants and stringified arguments: the C compiler will then combine all the adjacent string constants into one long string.

The ## operator (known as the "Token Pasting Operator") concatenates two tokens into one token.

Example:

The codice_24 directive outputs a message through the error stream.

All C, C++ and Objective-C implementations provide a preprocessor, as preprocessing is a required step for those languages, and its behavior is described by official standards for these languages, such as the ISO C standard.

Implementations may provide their own extensions and deviations, and vary in their degree of compliance with written standards. Their exact behavior may depend on command-line flags supplied on invocation. For instance, the GNU C preprocessor can be made more standards compliant by supplying certain flags.

The codice_46 directive is a compiler-specific directive, which compiler vendors may use for their own purposes. For instance, a codice_46 is often used to allow suppression of specific error messages, manage heap and stack debugging and so on. A compiler with support for the OpenMP parallelization library can automatically parallelize a codice_48 loop with codice_49.

C99 introduced a few standard codice_46 directives, taking the form codice_51, which are used to control the floating-point implementation.



As the C preprocessor can be invoked separately from the compiler with which it is supplied, it can be used separately, on different languages. Notable examples include its use in the now-deprecated imake system and for preprocessing Fortran. However, such use as a general purpose preprocessor is limited: the input language must be sufficiently C-like.
For preprocessing Fortran, a more flexible variant of the C preprocessor is preferred, "GPP".
The GNU Fortran compiler automatically calls cpp before compiling Fortran code if certain file extensions are used. Intel offers a Fortran preprocessor, fpp, for use with the ifort compiler, which has similar capabilities.

GPP also works acceptably with most assembly languages. GNU mentions assembly as one of the target languages among C, C++ and Objective-C in the documentation of its implementation of the preprocessor. This requires that the assembler syntax not conflict with GPP syntax, which means no lines starting with codice_55 and that double quotes, which gpp interprets as string literals and thus ignores, don't have syntactical meaning other than that.

The C preprocessor is not Turing-complete, but it comes very close: recursive computations can be specified, but with a fixed upper bound on the amount of recursion performed. However, the C preprocessor is not designed to be, nor does it perform well as, a general-purpose programming language. As the C preprocessor does not have features of some other preprocessors, such as recursive macros, selective expansion according to quoting, and string evaluation in conditionals, it is very limited in comparison to a more general macro processor such as m4.




</doc>
<doc id="379671" url="https://en.wikipedia.org/wiki?curid=379671" title="The C Programming Language">
The C Programming Language

The C Programming Language (sometimes termed K&R, after its authors' initials) is a computer programming book written by Brian Kernighan and Dennis Ritchie, the latter of whom originally designed and implemented the language, as well as co-designed the Unix operating system with which development of the language was closely intertwined. The book was central to the development and popularization of the C programming language and is still widely read and used today. Because the book was co-authored by the original language designer, and because the first edition of the book served for many years as the "de facto" standard for the language, the book was regarded by many to be the authoritative reference on C.

C was created by Dennis Ritchie at Bell Labs in the early 1970s as an augmented version of Ken Thompson's B.
Another Bell Labs employee, Brian Kernighan, had written the first C tutorial,
and he persuaded Ritchie to coauthor a book on the language.
Kernighan would write most of the book's "expository" material, and Ritchie's reference manual became its appendices.

The first edition, published February 22, 1978, was the first widely available book on the C programming language. Its version of C is sometimes termed "K&R C" (after the book's authors), often to distinguish this early version from the later version of C standardized as "ANSI C".

In April 1988, the second edition of the book was published, updated to cover the changes to the language resulting from the then-new ANSI C standard, particularly with the inclusion of reference material on standard libraries. The second edition of the book (and as of 2018, the most recent) has since been translated into over 20 languages. In 2012, an eBook version of the second edition was published in ePub, Mobi, and PDF formats.

ANSI C, first standardized in 1989 (as ANSI X3.159-1989), has since undergone several revisions, the most recent of which is ISO/IEC 9899:2018 (also termed "C18"), adopted as an ANSI standard in June 2018. However, no new edition of "The C Programming Language" has been issued to cover the more recent standards.

"Byte" magazine stated in August 1983, "["The C Programming Language"] is the definitive work on the C language. Don't read any further until you have this book!" Jerry Pournelle wrote in the magazine that year that the book "is still the standard ... a bit terse". He continued, "You can learn the C language without getting Kernighan and Ritchie, but that's doing it the hard way. You're also working too hard if you make it the "only" book on C that you buy."

"The C Programming Language" has often been cited as a model for technical writing, with reviewers describing it as having clear presentation and concise treatment. Examples generally consist of complete programs of the type one is likely to encounter in daily use of the language, with an emphasis on system programming. Its authors said:

The book introduced the "Hello, World!" program, which prints only the text "hello, world", as an illustration of a minimal working C program. Since then, many texts have followed that convention for introducing a programming language.

Before the advent of ANSI C, the first edition of the text served as the "de facto" standard of the language for writers of C compilers. With the standardization of ANSI C, the authors more consciously wrote the second edition for programmers rather than compiler writers, saying:

The influence of "The C Programming Language" on programmers, a generation of whom first worked with C in universities and industry, has led many to accept the authors' programming style and conventions as recommended practice, if not normative practice. For example, the coding and formatting style of the programs presented in both editions of the book is often referred to as "K&R style" or the "One True Brace Style" and became the coding style used by convention in the source code for the Unix and Linux kernels.




</doc>
<doc id="324378" url="https://en.wikipedia.org/wiki?curid=324378" title="C standard library">
C standard library

The C standard library or libc is the standard library for the C programming language, as specified in the ANSI C standard. It was developed at the same time as the C library POSIX specification, which is a superset of it. Since ANSI C was adopted by the International Organization for Standardization, the C standard library is also called the ISO C library.

The C standard library provides macros, type definitions and functions for tasks such as string handling, mathematical computations, input/output processing, memory management, and several other operating system services.

The application programming interface (API) of the C standard library is declared in a number of header files. Each header file contains one or more function declarations, data type definitions, and macros.

After a long period of stability, three new header files (codice_1, codice_2, and codice_3) were added with "Normative Addendum 1" (NA1), an addition to the C Standard ratified in 1995. Six more header files (codice_4, codice_5, codice_6, codice_7, codice_8, and codice_9) were added with C99, a revision to the C Standard published in 1999, and five more files (codice_10, codice_11, codice_12, codice_13, and codice_14) with C11 in 2011. In total, there are now 29 header files:

Three of the header files (codice_4, codice_11, and codice_13) are conditional features that implementations are not required to support.

The POSIX standard added several nonstandard C headers for Unix-specific functionality. Many have found their way to other architectures. Examples include codice_18 and codice_19. A number of other groups are using other nonstandard headers – the GNU C Library has codice_20, and HP OpenVMS has the codice_21 function.

On Unix-like systems, the authoritative documentation of the actually implemented API is provided in the form of man pages. On most systems, man pages on standard library functions are in section 3; section 7 may contain some more generic pages on underlying concepts (e.g. codice_22 in Linux).

Unix-like systems typically have a C library in shared library form, but the header files (and compiler toolchain) may be absent from an installation so C development may not be possible. The C library is considered part of the operating system on Unix-like systems. The C functions, including the ISO C standard ones, are widely used by programs, and are regarded as if they were not only an implementation of something in the C language, but also de facto part of the operating system interface. Unix-like operating systems generally cannot function if the C library is erased. This is true for applications which are dynamically as opposed to statically linked. Further, the kernel itself (at least in the case of Linux) operates independently of any libraries. 

On Microsoft Windows, the core system dynamic libraries (DLLs) provide an implementation of the C standard library for the Microsoft Visual C++ compiler v6.0; the C standard library for newer versions of the Microsoft Visual C++ compiler is provided by each compiler individually, as well as "redistributable" packages. Compiled applications written in C are either statically linked with a C library, or linked to a dynamic version of the library that is shipped with these applications, rather than relied upon to be present on the targeted systems. Functions in a compiler's C library are not regarded as interfaces to Microsoft Windows.

Many other implementations exist, provided with both various operating systems and C compilers. Some of the popular implementations are the following:


Some compilers (for example, GCC) provide built-in versions of many of the functions in the C standard library; that is, the implementations of the functions are written into the compiled object file, and the program calls the built-in versions instead of the functions in the C library shared object file. This reduces function-call overhead, especially if function calls are replaced with inline variants, and allows other forms of optimization (as the compiler knows the control-flow characteristics of the built-in variants), but may cause confusion when debugging (for example, the built-in versions cannot be replaced with instrumented variants).

However, the built-in functions must behave like ordinary functions in accordance with ISO C. The main implication is that the program must be able to create a pointer to these functions by taking their address, and invoke the function by means of that pointer. If two pointers to the same function are derived in two different translation units in the program, these two pointers must compare equal; that is, the address comes by resolving the name of the function, which has external (program-wide) linkage.

Under FreeBSD and Linux, the mathematical functions (as declared in codice_23) are bundled separately in the mathematical library libm. If any of them are used, the linker must be given the directive codice_24.

According to the C standard the macro codice_25 shall be defined to 1 if the implementation is hosted. A hosted implementation has all the headers specified by the C standard. An implementation can also be "freestanding" which means that these headers will not be present. If an implementation is "freestanding", it shall define codice_25 to 0.

Some functions in the C standard library have been notorious for having buffer overflow vulnerabilities and generally encouraging buggy programming ever since their adoption. The most criticized items are:

Except the extreme case with codice_30, all the security vulnerabilities can be avoided by introducing auxiliary code to perform memory management, bounds checking, input checking, etc. This is often done in the form of wrappers that make standard library functions safer and easier to use. This dates back to as early as "The Practice of Programming" book by B. Kernighan and R. Pike where the authors commonly use wrappers that print error messages and quit the program if an error occurs.

The ISO C committee published Technical reports TR 24731-1 and is working on TR 24731-2 to propose adoption of some functions with bounds checking and automatic buffer allocation, correspondingly. The former has met severe criticism with some praise, the latter received mixed responses. Despite this, TR 24731-1 has been implemented into Microsoft's C standard library and its compiler issues warnings when using old "insecure" functions.

The codice_33 routine is criticized for being thread unsafe and otherwise vulnerable to race conditions.

The error handling of the functions in the C standard library is not consistent and sometimes confusing. According to the Linux manual page codice_34, "The current (version 2.8) situation under glibc is messy. Most (but not all) functions raise exceptions on errors. Some also set "errno". A few functions set "errno", but don't raise an exception. A very few functions do neither."

The original C language provided no built-in functions such as I/O operations, unlike traditional languages such as COBOL and Fortran. Over time, user communities of C shared ideas and implementations of what is now called C standard libraries. Many of these ideas were incorporated eventually into the definition of the standardized C language.

Both Unix and C were created at AT&T's Bell Laboratories in the late 1960s and early 1970s. During the 1970s the C language became increasingly popular. Many universities and organizations began creating their own variants of the language for their own projects. By the beginning of the 1980s compatibility problems between the various C implementations became apparent. In 1983 the American National Standards Institute (ANSI) formed a committee to establish a standard specification of C known as "ANSI C". This work culminated in the creation of the so-called C89 standard in 1989. Part of the resulting standard was a set of software libraries called the ANSI C standard library.

POSIX, as well as SUS, specify a number of routines that should be available over and above those in the basic C standard library. The POSIX specification includes header files for, among other uses, multi-threading, networking, and regular expressions. These are often implemented alongside the C standard library functionality, with varying degrees of closeness. For example, glibc implements functions such as codice_35 within codice_36, but before NPTL was merged into glibc it constituted a separate library with its own linker flag argument. Often, this POSIX-specified functionality will be regarded as part of the library; the basic C library may be identified as the ANSI or ISO C library.

BSD libc is a superset of the POSIX standard library used by BSD operating systems such as FreeBSD, NetBSD, OpenBSD and macOS. It first appeared in 4.4BSD, which was released in 1994. BSD libc has some extensions that are not defined in the original standard. Some of the extensions of BSD libc are:


Some languages include the functionality of the standard C library in their own libraries. The library may be adapted to better suit the language's structure, but the operational semantics are kept similar. The C++ language, for example, includes the functionality of the C standard library in the namespace codice_50 (e.g., codice_51, codice_52, codice_53), in header files with similar names to the C ones (codice_54, codice_55, codice_56, etc.). Other languages that take similar approaches are D, Perl, Ruby and the main implementation of Python known as CPython. In Python 2, for example, the built-in file objects are defined as "implemented using C's codice_57 package", so that the available operations (open, read, write, etc.) are expected to have the same behavior as the corresponding C functions. Rust has a crate called which allows several C functions, structs, and other type definitions to be used.

The C standard library is small compared to the standard libraries of some other languages. The C library provides a basic set of mathematical functions, string manipulation, type conversions, and file and console-based I/O. It does not include a standard set of "container types" like the C++ Standard Template Library, let alone the complete graphical user interface (GUI) toolkits, networking tools, and profusion of other functionality that Java and the .NET Framework provide as standard. The main advantage of the small standard library is that providing a working ISO C environment is much easier than it is with other languages, and consequently porting C to a new platform is comparatively easy.




</doc>
<doc id="456820" url="https://en.wikipedia.org/wiki?curid=456820" title="C syntax">
C syntax

The syntax of the C programming language, the rules governing writing of software in the language, is designed to allow for programs that are extremely terse, have a close relationship with the resulting object code, and yet provide relatively high-level data abstraction. C was the first widely successful high-level language for portable operating-system development.

C syntax makes use of the maximal munch principle.

The C language represents numbers in three forms: "integral", "real" and "complex". This distinction reflects similar distinctions in the instruction set architecture of most central processing units. "Integral" data types store numbers in the set of integers, while "real" and "complex" numbers represent numbers (or pair of numbers) in the set of real numbers in floating point form.

All C integer types have signed and unsigned variants. If signed or unsigned is not specified explicitly, in most circumstances signed is assumed. However, for historic reasons plain char is a type distinct from both signed char and unsigned char. It may be a signed type or an unsigned type, depending on the compiler and the character set (C guarantees that members of the C basic character set have positive values). Also, bit field types specified as plain int may be signed or unsigned, depending on the compiler.

C's integer types come in different fixed sizes, capable of representing various ranges of numbers. The type occupies exactly one byte (the smallest addressable storage unit), which is typically 8 bits wide. (Although can represent any of C's "basic" characters, a wider type may be required for international character sets.) Most integer types have both signed and unsigned varieties, designated by the and keywords. Signed integer types may use a two's complement, ones' complement, or sign-and-magnitude representation. In many cases, there are multiple equivalent ways to designate the type; for example, and are synonymous.

The representation of some types may include unused "padding" bits, which occupy storage but are not included in the width. The following table provides a complete list of the standard integer types and their "minimum" allowed widths (including any sign bit).
The type is distinct from both and , but is guaranteed to have the same representation as one of them. The and types are standardized since 1999, and may not be supported by older C compilers. Type is usually accessed via the name defined by the standard header stdbool.h.

In general, the widths and representation scheme implemented for any given platform are chosen based on the machine architecture, with some consideration given to the ease of importing source code developed for other platforms. The width of the type varies especially widely among C implementations; it often corresponds to the most "natural" word size for the specific platform. The standard header limits.h defines macros for the minimum and maximum representable values of the standard integer types as implemented on any specific platform.

In addition to the standard integer types, there may be other "extended" integer types, which can be used for s in standard headers. For more precise specification of width, programmers can and should use s from the standard header stdint.h.

Integer constants may be specified in source code in several ways. Numeric values can be specified as decimal (example: ), octal with zero (0) as a prefix (), or hexadecimal with 0x (zero x) as a prefix (). A character in single quotes (example: ), called a "character constant," represents the value of that character in the execution character set, with type . Except for character constants, the type of an integer constant is determined by the width required to represent the specified value, but is always at least as wide as . This can be overridden by appending an explicit length and/or signedness modifier; for example, has type . There are no negative integer constants, but the same effect can often be obtained by using a unary negation operator "-".

The enumerated type in C, specified with the enum keyword, and often just called an "enum" (usually pronounced "ee'-num" /ˌi.nʌm/ or "ee'-noom" /ˌi.nuːm/), is a type designed to represent values across a series of named constants. Each of the enumerated constants has type int. Each enum type itself is compatible with char or a signed or unsigned integer type, but each implementation defines its own rules for choosing a type.

Some compilers warn if an object with enumerated type is assigned a value that is not one of its constants. However, such an object can be assigned any values in the range of their compatible type, and enum constants can be used anywhere an integer is expected. For this reason, enum values are often used in place of preprocessor #define directives to create named constants. Such constants are generally safer to use than macros, since they reside within a specific identifier namespace.

An enumerated type is declared with the enum specifier and an optional name (or "tag") for the enum, followed by a list of one or more constants contained within curly braces and separated by commas, and an optional list of variable names. Subsequent references to a specific enumerated type use the enum keyword and the name of the enum. By default, the first constant in an enumeration is assigned the value zero, and each subsequent value is incremented by one over the previous constant. Specific values may also be assigned to constants in the declaration, and any subsequent constants without specific values will be given incremented values from that point onward.
For example, consider the following declaration:

This declares the enum colors type; the int constants RED (whose value is 0), GREEN (whose value is one greater than RED, 1), BLUE (whose value is the given value, 5), and YELLOW (whose value is one greater than BLUE, 6); and the enum colors variable paint_color. The constants may be used outside of the context of the enum (where any integer value is allowed), and values other than the constants may be assigned to paint_color, or any other variable of type enum colors.

The floating-point form is used to represent numbers with a fractional component. They do not, however, represent most rational numbers exactly; they are instead a close approximation. There are three types of real values, denoted by their specifiers: single precision (float), double precision (double), and double extended precision (long double). Each of these may represent values in a different form, often one of the IEEE floating-point formats.

Floating-point constants may be written in decimal notation, e.g. 1.23. Decimal scientific notation may be used by adding e or E followed by a decimal exponent, also known as E notation, e.g. 1.23e2 (which has the value 1.23 × 10 = 123.0). Either a decimal point or an exponent is required (otherwise, the number is parsed as an integer constant). Hexadecimal floating-point constants follow similar rules, except that they must be prefixed by 0x and use p or P to specify a binary exponent, e.g. 0xAp-2 (which has the value 2.5, since A × 2 = 10 × 2 = 10 ÷ 4). Both decimal and hexadecimal floating-point constants may be suffixed by f or F to indicate a constant of type float, by l (letter l) or L to indicate type long double, or left unsuffixed for a double constant.

The standard header file float.h defines the minimum and maximum values of the implementation's floating-point types float, double, and long double. It also defines other limits that are relevant to the processing of floating-point numbers.

Every object has a storage class. This specifies most basically the storage "duration," which may be static (default for global), automatic (default for local), or dynamic (allocated), together with other features (linkage and register hint).

Variables declared within a block by default have automatic storage, as do those explicitly declared with the auto or register storage class specifiers. The auto and register specifiers may only be used within functions and function argument declarations; as such, the auto specifier is always redundant. Objects declared outside of all blocks and those explicitly declared with the static storage class specifier have static storage duration. Static variables are initialized to zero by default by the compiler.

Objects with automatic storage are local to the block in which they were declared and are discarded when the block is exited. Additionally, objects declared with the register storage class may be given higher priority by the compiler for access to registers; although they may not actually be stored in registers, objects with this storage class may not be used with the address-of (&) unary operator. Objects with static storage persist for the program's entire duration. In this way, the same object can be accessed by a function across multiple calls. Objects with allocated storage duration are created and destroyed explicitly with malloc, free, and related functions.

The extern storage class specifier indicates that the storage for an object has been defined elsewhere. When used inside a block, it indicates that the storage has been defined by a declaration outside of that block. When used outside of all blocks, it indicates that the storage has been defined outside of the compilation unit. The extern storage class specifier is redundant when used on a function declaration. It indicates that the declared function has been defined outside of the compilation unit.

Note that storage specifiers apply only to functions and objects; other things such as type and enum declarations are private to the compilation unit in which they appear. Types, on the other hand, have qualifiers (see below).

Types can be qualified to indicate special properties of their data. The type qualifier codice_1 indicates that a value does not change once it has been initialized. Attempting to modify a codice_1 qualified value yields undefined behavior, so some C compilers store them in rodata or (for embedded systems) in read-only memory (ROM). The type qualifier codice_3 indicates to an optimizing compiler that it may not remove apparently redundant reads or writes, as the value may change even if it was not modified by any expression or statement, or multiple writes may be necessary, such as for memory-mapped I/O.

An incomplete type is a structure or union type whose members have not yet been specified, an array type whose dimension has not yet been specified, or the void type (the void type cannot be completed). Such a type may not be instantiated (its size is not known), nor may its members be accessed (they, too, are unknown); however, the derived pointer type may be used (but not dereferenced).

They are often used with pointers, either as forward or external declarations. For instance, code could declare an incomplete type like this:

This declares pt as a pointer to struct thing "and" the incomplete type struct thing. Pointers to data always have the same byte-width regardless of what they point to, so this statement is valid by itself (as long as pt is not dereferenced). The incomplete type can be completed later in the same scope by redeclaring it:
Incomplete types are used to implement recursive structures; the body of the type declaration may be deferred to later in the translation unit:
Incomplete types are also used for data hiding; the incomplete type is defined in a header file, and the body only within the relevant source file.

In declarations the asterisk modifier (*) specifies a pointer type. For example, where the specifier int would refer to the integer type, the specifier int* refers to the type "pointer to integer". Pointer values associate two pieces of information: a memory address and a data type. The following line of code declares a pointer-to-integer variable called "ptr":

When a non-static pointer is declared, it has an unspecified value associated with it. The address associated with such a pointer must be changed by assignment prior to using it. In the following example, "ptr" is set so that it points to the data associated with the variable "a":

In order to accomplish this, the "address-of" operator (unary &) is used. It produces the memory location of the data object that follows.

The pointed-to data can be accessed through a pointer value. In the following example, the integer variable "b" is set to the value of integer variable "a", which is 10:

In order to accomplish that task, the unary dereference operator, denoted by an asterisk (*), is used. It returns the data to which its operand—which must be of pointer type—points. Thus, the expression *"p" denotes the same value as "a". Dereferencing a null pointer is illegal.

Arrays are used in C to represent structures of consecutive elements of the same type. The definition of a (fixed-size) array has the following syntax:

which defines an array named "array" to hold 100 values of the primitive type int. If declared within a function, the array dimension may also be a non-constant expression, in which case memory for the specified number of elements will be allocated. In most contexts in later use, a mention of the variable "array" is converted to a pointer to the first item in the array. The sizeof operator is an exception: sizeof array yields the size of the entire array (that is, 100 times the size of an int, and codice_4 will return 100). Another exception is the & (address-of) operator, which yields a pointer to the entire array, for example

The primary facility for accessing the values of the elements of an array is the array subscript operator. To access the "i"-indexed element of "array", the syntax would be , which refers to the value stored in that array element.

Array subscript numbering begins at 0 (see Zero-based indexing). The largest allowed array subscript is therefore equal to the number of elements in the array minus 1. To illustrate this, consider an array "a" declared as having 10 elements; the first element would be and the last element would be .

C provides no facility for automatic bounds checking for array usage. Though logically the last subscript in an array of 10 elements would be 9, subscripts 10, 11, and so forth could accidentally be specified, with undefined results.

Due to arrays and pointers being interchangeable, the addresses of each of the array elements can be expressed in equivalent pointer arithmetic. The following table illustrates both methods for the existing array:

Since the expression is semantically equivalent to , which in turn is equivalent to ; the expression can also be written as , although this form is rarely used.

C99 standardised variable-length arrays (VLAs) within block scope. Such array variables are allocated based on the value of an integer value at runtime upon entry to a block, and are deallocated at the end of the block. As of C11 this feature is no longer required to be implemented by the compiler.

This syntax produces an array whose size is fixed until the end of the block.

Arrays that can be resized dynamically can be produced with the help of the C standard library. The malloc function provides a simple method for allocating memory. It takes one parameter: the amount of memory to allocate in bytes. Upon successful allocation, malloc returns a generic (void) pointer value, pointing to the beginning of the allocated space. The pointer value returned is converted to an appropriate type implicitly by assignment. If the allocation could not be completed, malloc returns a null pointer. The following segment is therefore similar in function to the above desired declaration:

The result is a "pointer to int" variable ("a") that points to the first of "n" contiguous int objects; due to array–pointer equivalence this can be used in place of an actual array name, as shown in the last line. The advantage in using this dynamic allocation is that the amount of memory that is allocated to it can be limited to what is actually needed at run time, and this can be changed as needed (using the standard library function realloc).

When the dynamically-allocated memory is no longer needed, it should be released back to the run-time system. This is done with a call to the free function. It takes a single parameter: a pointer to previously allocated memory. This is the value that was returned by a previous call to malloc.

As a security measure, some programmers then set the pointer variable to NULL:

This ensures that further attempts to dereference the pointer will crash the program. If this is not done, the variable becomes a dangling pointer which can lead to a use-after-free bug. However, if the pointer is a local variable, setting it to NULL does not prevent the program from using other copies of the pointer. Local use-after-free bugs are usually easy for static analyzers to recognize. Therefore, this approach is less useful for local pointers and it is more often used with pointers stored in long-living structs. In general though, setting pointers to NULL is good practice as it allows a programmer is NULL-check pointers prior to dereferencing, thus helping prevent crashes.

Recalling the array example, one could also create a fixed-size array through dynamic allocation:

...Which yields a pointer-to-array.

Accessing the pointer-to-array can be done in two ways:
Iterating can also be done in two ways:
The benefit to using the second example is that the numeric limit of the first example isn't required, which means that the pointer-to-array could be of any size and the second example can execute without any modifications.

In addition, C supports arrays of multiple dimensions, which are stored in row-major order. Technically, C multidimensional arrays are just one-dimensional arrays whose elements are arrays. The syntax for declaring multidimensional arrays is as follows:
where "ROWS" and "COLUMNS" are constants. This defines a two-dimensional array. Reading the subscripts from left to right, "array2d" is an array of length "ROWS", each element of which is an array of "COLUMNS" integers.

To access an integer element in this multidimensional array, one would use
Again, reading from left to right, this accesses the 5th row, and the 4th element in that row. The expression array2d[4] is an array, which we are then subscripting with [3] to access the fourth integer.

Higher-dimensional arrays can be declared in a similar manner.

A multidimensional array should not be confused with an array of references to arrays (also known as an Iliffe vectors or sometimes an "array of arrays"). The former is always rectangular (all subarrays must be the same size), and occupies a contiguous region of memory. The latter is a one-dimensional array of pointers, each of which may point to the first element of a subarray in a different place in memory, and the sub-arrays do not have to be the same size. The latter can be created by multiple uses of malloc.

In C, string literals are surrounded by double quotes ("), e.g. "Hello world!" and are compiled to an array of the specified char values with an additional null terminating character (0-valued) code to mark the end of the string.

String literals may not contain embedded newlines; this proscription somewhat simplifies parsing of the language. To include a newline in a string, the backslash escape \n may be used, as below.

There are several standard library functions for operating with string data (not necessarily constant) organized as array of char using this null-terminated format; see below.

C's string-literal syntax has been very influential, and has made its way into many other languages, such as C++, Objective-C, Perl, Python, PHP, Java, Javascript, C#, Ruby. Nowadays, almost all new languages adopt or build upon C-style string syntax. Languages that lack this syntax tend to precede C.

If you wish to include a double quote inside the string, that can be done by escaping it with a backslash (\), for example, "This string contains \"double quotes\".". To insert a literal backslash, one must double it, e.g. "A backslash looks like this: \\".

Backslashes may be used to enter control characters, etc., into a string:
The use of other backslash escapes is not defined by the C standard, although compiler vendors often provide additional escape codes as language extensions.

C has string literal concatenation, meaning that adjacent string literals are concatenated at compile time; this allows long strings to be split over multiple lines, and also allows string literals resulting from C preprocessor defines and macros to be appended to strings at compile time:

will expand to

which is syntactically equivalent to
Individual character constants are single-quoted, e.g. 'A', and have type int (in C++, char). The difference is that "A" represents a null-terminated array of two characters, 'A' and '\0', whereas 'A' directly represents the character value (65 if ASCII is used). The same backslash-escapes are supported as for strings, except that (of course) " can validly be used as a character without being escaped, whereas ' must now be escaped.

A character constant cannot be empty (i.e. <nowiki>"</nowiki> is invalid syntax), although a string may be (it still has the null terminating character). Multi-character constants (e.g. 'xy') are valid, although rarely useful — they let one store several characters in an integer (e.g. 4 ASCII characters can fit in a 32-bit integer, 8 in a 64-bit one). Since the order in which the characters are packed into an int is not specified (left to the implementation to define), portable use of multi-character constants is difficult.

Nevertheless, in situations limited to a specific platform and the compiler implementation, multicharacter constants do find their use in specificing signatures. One common use case is the OSType, where the combination of Classic Mac OS compilers and its inherent big-endianness means that bytes in the integer appear in the exact order of characters defined in the literal. The definition by popular "implementations" are in fact consistent: in GCC, Clang, and Visual C++, '1234' yields codice_5 under ASCII.

Since type char is 1 byte wide, a single char value typically can represent at most 255 distinct character codes, not nearly enough for all the characters in use worldwide. To provide better support for international characters, the first C standard (C89) introduced wide characters (encoded in type wchar_t) and wide character strings, which are written as L"Hello world!"

Wide characters are most commonly either 2 bytes (using a 2-byte encoding such as UTF-16) or 4 bytes (usually UTF-32), but Standard C does not specify the width for wchar_t, leaving the choice to the implementor. Microsoft Windows generally uses UTF-16, thus the above string would be 26 bytes long for a Microsoft compiler; the Unix world prefers UTF-32, thus compilers such as GCC would generate a 52-byte string. A 2-byte wide wchar_t suffers the same limitation as char, in that certain characters (those outside the BMP) cannot be represented in a single wchar_t; but must be represented using surrogate pairs.

The original C standard specified only minimal functions for operating with wide character strings; in 1995 the standard was modified to include much more extensive support, comparable to that for char strings. The relevant functions are mostly named after their char equivalents, with the addition of a "w" or the replacement of "str" with "wcs"; they are specified in <wchar.h>, with <wctype.h> containing wide-character classification and mapping functions.

The now generally recommended method of supporting international characters is through UTF-8, which is stored in char arrays, and can be written directly in the source code if using a UTF-8 editor, because UTF-8 is a direct ASCII extension.

A common alternative to wchar_t is to use a variable-width encoding, whereby a logical character may extend over multiple positions of the string. Variable-width strings may be encoded into literals verbatim, at the risk of confusing the compiler, or using numerical backslash escapes (e.g. "\xc3\xa9" for "é" in UTF-8). The UTF-8 encoding was specifically designed (under Plan 9) for compatibility with the standard library string functions; supporting features of the encoding include a lack of embedded nulls, no valid interpretations for subsequences, and trivial resynchronisation. Encodings lacking these features are likely to prove incompatible with the standard library functions; encoding-aware string functions are often used in such cases.

Strings, both constant and variable, can be manipulated without using the standard library. However, the library contains many useful functions for working with null-terminated strings.

Structures and unions in C are defined as data containers consisting of a sequence of named members of various types. They are similar to records in other programming languages. The members of a structure are stored in consecutive locations in memory, although the compiler is allowed to insert padding between or after members (but not before the first member) for efficiency or as padding required for proper alignment by the target architecture. The size of a structure is equal to the sum of the sizes of its members, plus the size of the padding.

Unions in C are related to structures and are defined as objects that may hold (at different times) objects of different types and sizes. They are analogous to variant records in other programming languages. Unlike structures, the components of a union all refer to the same location in memory. In this way, a union can be used at various times to hold different types of objects, without the need to create a separate object for each new type. The size of a union is equal to the size of its largest component type.

Structures are declared with the keyword and unions are declared with the keyword. The specifier keyword is followed by an optional identifier name, which is used to identify the form of the structure or union. The identifier is followed by the declaration of the structure or union's body: a list of member declarations, contained within curly braces, with each declaration terminated by a semicolon. Finally, the declaration concludes with an optional list of identifier names, which are declared as instances of the structure or union.

For example, the following statement declares a structure named "s" that contains three members; it will also declare an instance of the structure known as "tee":

And the following statement will declare a similar union named "u" and an instance of it named "n":

Members of structures and unions cannot have an incomplete or function type. Thus members cannot be an instance of the structure or union being declared (because it is incomplete at that point) but can be pointers to the type being declared.

Once a structure or union body has been declared and given a name, it can be considered a new data type using the specifier or , as appropriate, and the name. For example, the following statement, given the above structure declaration, declares a new instance of the structure "s" named "r":

It is also common to use the specifier to eliminate the need for the or keyword in later references to the structure. The first identifier after the body of the structure is taken as the new name for the structure type (structure instances may not be declared in this context). For example, the following statement will declare a new type known as "s_type" that will contain some structure:

Future statements can then use the specifier "s_type" (instead of the expanded ... specifier) to refer to the structure.

Members are accessed using the name of the instance of a structure or union, a period (.), and the name of the member. For example, given the declaration of "tee" from above, the member known as "y" (of type float) can be accessed using the following syntax:

Structures are commonly accessed through pointers. Consider the following example that defines a pointer to "tee", known as "ptr_to_tee":

Member "y" of "tee" can then be accessed by dereferencing "ptr_to_tee" and using the result as the left operand:

Which is identical to the simpler tee.y above as long as "ptr_to_tee" points to "tee". Due to operator precedence ("." being higher than "*"), the shorter codice_6 is incorrect for this purpose, instead being parsed as codice_7 and thus the parentheses are necessary. Because this operation is common, C provides an abbreviated syntax for accessing a member directly from a pointer. With this syntax, the name of the instance is replaced with the name of the pointer and the period is replaced with the character sequence ->. Thus, the following method of accessing "y" is identical to the previous two:

Members of unions are accessed in the same way.

This can be chained; for example, in a linked list, one may refer to codice_8 for the second following node (assuming that codice_9 is not null).

Assigning values to individual members of structures and unions is syntactically identical to assigning values to any other object. The only difference is that the "lvalue" of the assignment is the name of the member, as accessed by the syntax mentioned above.

A structure can also be assigned as a unit to another structure of the same type. Structures (and pointers to structures) may also be used as function parameter and return types.

For example, the following statement assigns the value of 74 (the ASCII code point for the letter 't') to the member named "x" in the structure "tee", from above:

And the same assignment, using "ptr_to_tee" in place of "tee", would look like:

Assignment with members of unions is identical.

According to the C standard, the only legal operations that can be performed on a structure are copying it, assigning to it as a unit (or initializing it), taking its address with the address-of (&) unary operator, and accessing its members. Unions have the same restrictions. One of the operations implicitly forbidden is comparison: structures and unions cannot be compared using C's standard comparison facilities (==, >, <, etc.).

C also provides a special type of structure member known as a bit field, which is an integer with an explicitly specified number of bits. A bit field is declared as a structure member of type int, signed int, unsigned int, or _Bool, following the member name by a colon (:) and the number of bits it should occupy. The total number of bits in a single bit field must not exceed the total number of bits in its declared type.

As a special exception to the usual C syntax rules, it is implementation-defined whether a bit field declared as type int, without specifying signed or unsigned, is signed or unsigned. Thus, it is recommended to explicitly specify signed or unsigned on all structure members for portability.

Unnamed fields consisting of just a colon followed by a number of bits are also allowed; these indicate padding. Specifying a width of zero for an unnamed field is used to force alignment to a new word.

The members of bit fields do not have addresses, and as such cannot be used with the address-of (&) unary operator. The sizeof operator may not be applied to bit fields.

The following declaration declares a new structure type known as f and an instance of it known as g. Comments provide a description of each of the members:

Default initialization depends on the storage class specifier, described above.

Because of the language's grammar, a scalar initializer may be enclosed in any number of curly brace pairs. Most compilers issue a warning if there is more than one such pair, though.
Structures, unions and arrays can be initialized in their declarations using an initializer list. Unless designators are used, the components of an initializer correspond with the elements in the order they are defined and stored, thus all preceding values must be provided before any particular element's value. Any unspecified elements are set to zero (except for unions). Mentioning too many initialization values yields an error.

The following statement will initialize a new instance of the structure "s" known as "pi":
Designated initializers allow members to be initialized by name, in any order, and without explicitly providing the preceding values. The following initialization is equivalent to the previous one:
Using a designator in an initializer moves the initialization "cursor". In the example below, if codice_10 is greater than 10, there will be some zero-valued elements in the middle of codice_11; if it is less than 10, some of the values provided by the first five initializers will be overridden by the second five (if codice_10 is less than 5, there will be a compilation error):
In C89, a union was initialized with a single value applied to its first member. That is, the union "u" defined above could only have its "int x" member initialized:
Using a designated initializer, the member to be initialized does not have to be the first member:
If an array has unknown size (i.e. the array was an incomplete type), the number of initializers determines the size of the array and its type becomes complete:
Compound designators can be used to provide explicit initialization when unadorned initializer lists
might be misunderstood. In the example below, codice_13 is declared as an array of structures, each structure consisting of a member codice_11 (an array of 3 codice_15) and a member codice_16 (an codice_15). The initializer sets the size of codice_13 to 2 and sets the values of the first element of each codice_11:

This is equivalent to:

There is no way to specify repetition of an initializer in standard C.

It is possible to borrow the initialization methodology to generate compound structure and array literals:

Compound literals are often combined with designated initializers to make the declaration more readable:

C is a free-form language.

Bracing style varies from programmer to programmer and can be the subject of debate. See Indent style for more details.

In the items in this section, any <statement> can be replaced with a compound statement. Compound statements have the form:

and are used as the body of a function or anywhere that a single statement is expected. The declaration-list declares variables to be used in that scope, and the statement-list are the actions to be performed. Brackets define their own scope, and variables defined inside those brackets will be automatically
deallocated at the closing bracket. Declarations and statements can be freely intermixed within a compound statement (as in C++).

C has two types of selection statements: the if statement and the switch statement.

The if statement is in the form:
In the if statement, if the <expression> in parentheses is nonzero (true), control passes to <statement1>. If the else clause is present and the <expression> is zero (false), control will pass to <statement2>. The else <statement2> part is optional and, if absent, a false <expression> will simply result in skipping over the <statement1>. An else always matches the nearest previous unmatched if; braces may be used to override this when necessary, or for clarity.

The switch statement causes control to be transferred to one of several statements depending on the value of an expression, which must have integral type. The substatement controlled by a switch is typically compound. Any statement within the substatement may be labeled with one or more case labels, which consist of the keyword case followed by a constant expression and then a colon (:). The syntax is as follows:
No two of the case constants associated with the same switch may have the same value. There may be at most one default label associated with a switch. If none of the case labels are equal to the expression in the parentheses following switch, control passes to the default label or, if there is no default label, execution resumes just beyond the entire construct.

Switches may be nested; a case or default label is associated with the innermost switch that contains it. Switch statements can "fall through", that is, when one case section has completed its execution, statements will continue to be executed downward until a break; statement is encountered. Fall-through is useful in some circumstances, but is usually not desired.
In the preceding example, if <label2> is reached, the statements <statements 2> are executed and nothing more inside the braces. However, if <label1> is reached, both <statements 1> and <statements 2> are executed since there is no break to separate the two case statements.

It is possible, although unusual, to insert the switch labels into the sub-blocks of other control structures. Examples of this include Duff's device and Simon Tatham's implementation of coroutines in Putty.

C has three forms of iteration statement:
In the while and do statements, the sub-statement is executed repeatedly so long as the value of the expression remains non-zero (equivalent to true). With while, the test, including all side effects from <expression>, occurs before each iteration (execution of <statement>); with do, the test occurs after each iteration. Thus, a do statement always executes its sub-statement at least once, whereas while may not execute the sub-statement at all.

The statement:

is equivalent to:

except for the behaviour of a continue; statement (which in the for loop jumps to e3 instead of e2). If e2 is blank, it would have to be replaced with a 1.

Any of the three expressions in the for loop may be omitted. A missing second expression makes the while test always non-zero, creating a potentially infinite loop.

Since C99, the first expression may take the form of a declaration, typically including an initializer, such as:
The declaration's scope is limited to the extent of the for loop.

Jump statements transfer control unconditionally. There are four types of jump statements in C: goto, continue, break, and return.

The goto statement looks like this:
The identifier must be a label (followed by a colon) located in the current function. Control transfers to the labeled statement.

A continue statement may appear only within an iteration statement and causes control to pass to the loop-continuation portion of the innermost enclosing iteration statement. That is, within each of the statements

a continue not contained within a nested iteration statement is the same as goto cont.

The break statement is used to end a for loop, while loop, do loop, or switch statement. Control passes to the statement following the terminated statement.

A function returns to its caller by the return statement. When return is followed by an expression, the value is returned to the caller as the value of the function. Encountering the end of the function is equivalent to a return with no expression. In that case, if the function is declared as returning a value and the caller tries to use the returned value, the result is undefined.

GCC extends the C language with a unary && operator that returns the address of a label. This address can be stored in a void* variable type and may be used later in a goto instruction. For example, the following prints "hi " in an infinite loop:

This feature can be used to implement a jump table.

A C function definition consists of a return type (void if no value is returned), a unique name, a list of parameters in parentheses, and various statements:
A function with non-void return type should include at least one return statement. The parameters are given by the <parameter-list>, a comma-separated list of parameter declarations, each item in the list being a data type followed by an identifier: <data-type> <variable-identifier>, <data-type> <variable-identifier>, ...

If there are no parameters, the <parameter-list> may be left empty or optionally be specified with the single word void.

It is possible to define a function as taking a variable number of parameters by providing the ... keyword as the last parameter instead of a data type and variable identifier. A commonly used function that does this is the standard library function printf, which has the declaration:
Manipulation of these parameters can be done by using the routines in the standard library header <stdarg.h>.

A pointer to a function can be declared as follows:
The following program shows use of a function pointer for selecting between addition and subtraction:
After preprocessing, at the highest level a C program consists of a sequence of declarations at file scope. These may be partitioned into several separate source files, which may be compiled separately; the resulting object modules are then linked along with implementation-provided run-time support modules to produce an executable image.

The declarations introduce functions, variables and types. C functions are akin to the subroutines of Fortran or the procedures of Pascal.

A "definition" is a special type of declaration. A variable definition sets aside storage and possibly initializes it, a function definition provides its body.

An implementation of C providing all of the standard library functions is called a "hosted implementation". Programs written for hosted implementations are required to define a special function called main, which is the first function called when a program begins executing.

Hosted implementations start program execution by invoking the main function, which must be defined following one of these prototypes:
The first two definitions are equivalent (and both are compatible with C++). It is probably up to individual preference which one is used (the current C standard contains two examples of main() and two of main(void), but the draft C++ standard uses main()). The return value of main (which should be int) serves as "termination status" returned to the host environment.

The C standard defines return values 0 and EXIT_SUCCESS as indicating success and EXIT_FAILURE as indicating failure. (EXIT_SUCCESS and EXIT_FAILURE are defined in <stdlib.h>). Other return values have implementation-defined meanings; for example, under Linux a program killed by a signal yields a return code of the numerical value of the signal plus 128.

A minimal correct C program consists of an empty main routine, taking no arguments and doing nothing:
Because no codice_20 statement is present, codice_21 returns 0 on exit. (This is a special-case feature introduced in C99 that applies only to codice_21.)

The main function will usually call other functions to help it perform its job.

Some implementations are not hosted, usually because they are not intended to be used with an operating system. Such implementations are called "free-standing" in the C standard. A free-standing implementation is free to specify how it handles program startup; in particular it need not require a program to define a main function.

Functions may be written by the programmer or provided by existing libraries. Interfaces for the latter are usually declared by including header files—with the #include preprocessing directive—and the library objects are linked into the final executable image. Certain library functions, such as printf, are defined by the C standard; these are referred to as the standard library functions.

A function may return a value to caller (usually another C function, or the hosting environment for the function main). The printf function mentioned above returns how many characters were printed, but this value is often ignored.

In C, arguments are passed to functions by value while other languages may pass variables by reference.
This means that the receiving function gets copies of the values and has no direct way of altering the original variables.
For a function to alter a variable passed from another function, the caller must pass its "address" (a "pointer" to it), which can then be dereferenced in the receiving function. See Pointers for more information.

The function scanf works the same way:
In order to pass an editable pointer to a function (such as for the purpose of returning an allocated array to the calling code) you have to pass a pointer to "that" pointer: its address.

The parameter int **a_p is a pointer to a pointer to an int, which is the address of the pointer p defined in the "main" function in this case.

Function parameters of array type may at first glance appear to be an exception to C's pass-by-value rule. The following program will print 2, not 1:
However, there is a different reason for this behavior. In fact, a function parameter declared with an array type is treated like one declared to be a pointer. That is, the preceding declaration of setArray is equivalent to the following:
At the same time, C rules for the use of arrays in expressions cause the value of a in the call to setArray to be converted to a pointer to the first element of array a. Thus, in fact this is still an example of pass-by-value, with the caveat that it is the address of the first element of the array being passed by value, not the contents of the array.

The following words are reserved, and may not be used as identifiers:

Implementations may reserve other keywords, such as asm, although implementations typically provide non-standard keywords that begin with one or two underscores.

C identifiers are case sensitive (e.g., foo, FOO, and Foo are the names of different objects). Some linkers may map external identifiers to a single case, although this is uncommon in most modern linkers.

Text starting with the token /* is treated as a comment and ignored. The comment ends at the next */; it can occur within expressions, and can span multiple lines. Accidental omission of the comment terminator is problematic in that the next comment's properly constructed comment terminator will be used to terminate the initial comment, and all code in between the comments will be considered as a comment. C-style comments do not nest; that is, accidentally placing a comment within a comment has unintended results:
C++ style line comments start with // and extend to the end of the line. This style of comment originated in BCPL and became valid C syntax in C99; it is not available in the original K&R C nor in ANSI C:
The parameters given on a command line are passed to a C program with two predefined variables - the count of the command-line arguments in argc and the individual arguments as character strings in the pointer array argv. So the command:

codice_23

results in something like:
While individual strings are arrays of contiguous characters, there is no guarantee that the strings are stored as a contiguous group.

The name of the program, argv[0], may be useful when printing diagnostic messages or for making one binary serve multiple purposes. The individual values of the parameters may be accessed with argv[1], argv[2], and argv[3], as shown in the following program:

In any reasonably complex expression, there arises a choice as to the order in which to evaluate the parts of the expression: may be evaluated in the order , , , , or in the order , , , . Formally, a conforming C compiler may evaluate expressions in "any" order between "sequence points" (this allows the compiler to do some optimization). Sequence points are defined by:

Expressions before a sequence point are always evaluated before those after a sequence point. In the case of short-circuit evaluation, the second expression may not be evaluated depending on the result of the first expression. For example, in the expression , if the first argument evaluates to nonzero (true), the result of the entire expression cannot be anything else than true, so b() is not evaluated. Similarly, in the expression , if the first argument evaluates to zero (false), the result of the entire expression cannot be anything else than false, so b() is not evaluated.

The arguments to a function call may be evaluated in any order, as long as they are all evaluated by the time the function is entered. The following expression, for example, has undefined behavior:
An aspect of the C standard (not unique to C) is that the behavior of certain code is said to be "undefined". In practice, this means that the program produced from this code can do anything, from working as the programmer intended, to crashing every time it is run.

For example, the following code produces undefined behavior, because the variable "b" is modified more than once with no intervening sequence point:

Because there is no sequence point between the modifications of "b" in ""b"++ + "b"++", it is possible to perform the evaluation steps in more than one order, resulting in an ambiguous statement. This can be fixed by rewriting the code to insert a sequence point in order to enforce an unambiguous behavior, for example:



</doc>
<doc id="2225997" url="https://en.wikipedia.org/wiki?curid=2225997" title="C Traps and Pitfalls">
C Traps and Pitfalls

C Traps and Pitfalls is a slim computer programming book by former AT&T Corporation researcher and programmer Andrew Koenig, its first edition still in print in 2017, which outlines the many ways in which beginners and even sometimes quite experienced C programmers can write poor, malfunctioning and dangerous source code.

It evolved from an earlier technical report, by the same name, published internally at Bell Labs. This, in turn was inspired by a prior paper given by Koenig on "PL/I Traps and Pitfalls" at a SHARE conference in 1977. Koenig wrote that this title was inspired by a 1968 science fiction anthology by Robert Sheckley, "The People Trap and other Pitfalls, Snares, Devices and Delusions, as Well as Two Sniggles and a Contrivance".


</doc>
<doc id="23590441" url="https://en.wikipedia.org/wiki?curid=23590441" title="C11 (C standard revision)">
C11 (C standard revision)

C11 (formerly C1X) is an informal name for ISO/IEC 9899:2011, a past standard for the C programming language. It replaced C99 (standard ISO/IEC 9899:1999) and has been superseded by C18 (standard ISO/IEC 9899:2018). C11 mainly standardizes features already supported by common contemporary compilers, and includes a detailed memory model to better support multiple threads of execution. Due to delayed availability of conforming C99 implementations, C11 makes certain features optional, to make it easier to comply with the core language standard.

The final draft, N1570, was published in April 2011. The new standard passed its final draft review on October 10, 2011 and was officially ratified by ISO and published as ISO/IEC 9899:2011 on December 8, 2011, with no comments requiring resolution by participating national bodies.

A standard macro codice_1 is defined with value codice_2 to indicate that C11 support is available. Some features of C11 are supported by the GCC starting with version 4.6, Clang starting with version 3.1, and IBM XL C starting with version 12.1.

The standard includes several changes to the C99 language and library specifications, such as:


The new revision allows implementations to not support certain parts of the standard — including some that had been mandatory to support in the 1999 revision. Programs can use predefined macros to determine whether an implementation supports a certain feature or not.
The optional bounds-checking interfaces (Annex K) remain controversial and have not been widely implemented, and their deprecation or removal from the next standard revision has been proposed. (The open-source Open Watcom C/C++ does contain a "Safer C" library that is considered a nearly conforming implementation.)




</doc>
<doc id="403720" url="https://en.wikipedia.org/wiki?curid=403720" title="Digraphs and trigraphs">
Digraphs and trigraphs

In computer programming, digraphs and trigraphs are sequences of two and three characters, respectively, that appear in source code and, according to a programming language's specification, should be treated as if they were single characters.

Various reasons exist for using digraphs and trigraphs: keyboards may not have keys to cover the entire character set of the language, input of special characters may be difficult, text editors may reserve some characters for special use and so on. Trigraphs might also be used for some EBCDIC code pages that lack characters such as codice_1 and codice_2.

The basic character set of the C programming language is a subset of the ASCII character set that includes nine characters which lie outside the ISO 646 invariant character set. This can pose a problem for writing source code when the encoding (and possibly keyboard) being used does not support any of these nine characters. The ANSI C committee invented trigraphs as a way of entering source code using keyboards that support any version of the ISO 646 character set.

Trigraphs are not commonly encountered outside compiler test suites. Some compilers support an option to turn recognition of trigraphs off, or disable trigraphs by default and require an option to turn them on. Some can issue warnings when they encounter trigraphs in source files. Borland supplied a separate program, the trigraph preprocessor (codice_3), to be used only when trigraph processing is desired (the rationale was to maximise speed of compilation).

Different systems define different sets of digraphs and trigraphs, as described below.

Early versions of ALGOL predated the standardized ASCII and EBCDIC character sets, and were typically implemented using a manufacturer-specific six-bit character code. A number of ALGOL operations either lacked codepoints in the available character set or were not supported by peripherals, leading to a number of substitutions including codice_4 for codice_5 (assignment) and codice_6 for codice_7 (greater than or equal).

The Pascal programming language supports digraphs codice_8, codice_9, codice_10 and codice_11 for codice_12, codice_13, codice_1 and codice_2 respectively. Unlike all other cases mentioned here, codice_10 and codice_11 were and still are in wide use. However, many compilers treat them as a different type of commenting block rather than as actual digraphs, that is, a comment started with codice_10 cannot be closed with codice_2 and vice versa.

The J programming language is a descendant of APL but uses the ASCII character set rather than APL symbols. Because the printable range of ASCII is smaller than APL's specialized set of symbols, codice_20 (dot) and codice_21 (colon) characters are used to inflect ASCII symbols, effectively interpreting unigraphs, digraphs or rarely trigraphs as standalone "symbols".

Unlike the use of digraphs and trigraphs in C and C++, there are no single-character equivalents to these in J.

The C preprocessor replaces all occurrences of the following nine trigraph sequences by their single-character equivalents before any other processing.

A programmer may want to place two question marks together yet not have the compiler treat them as introducing a trigraph. The C grammar does not permit two consecutive codice_22 tokens, so the only places in a C file where two question marks in a row may be used are in multi-character constants, string literals, and comments. This is particularly a problem for the classic Mac OS, where the constant codice_23 may be used as a file type or creator. To safely place two consecutive question marks within a string literal, the programmer can use string concatenation codice_24 or an escape sequence codice_25.

codice_26 is not itself a trigraph sequence, but when followed by a character such as codice_27 it will be interpreted as codice_22 + codice_29, as in the example below which has 16 codice_22s before the codice_31.

The codice_32 trigraph can be used to introduce an escaped newline for line splicing; this must be taken into account for correct and efficient handling of trigraphs within the preprocessor. It can also cause surprises, particularly within comments. For example:

which is a single logical comment line (used in C++ and C99), and

which is a correctly formed block comment.

In 1994, a normative amendment to the C standard, included in C99, supplied digraphs as more readable alternatives to five of the trigraphs. They are listed in the table on the right.

Unlike trigraphs, digraphs are handled during tokenization, and any digraph must always represent a full token by itself, or compose the token codice_33 replacing the preprocessor concatenation token codice_34. If a digraph sequence occurs inside another token, for example a quoted string, or a character constant, it will not be replaced.

C++ (through C++14, see below) behaves like C, including the C99 additions, but with additional tokens listed in the table.

As a note, codice_33 is treated as a single token, rather than two occurrences of codice_36.

The C++ Standard makes this comment with regards to the term "digraph":

Trigraphs were proposed for deprecation in C++0x, which was released as C++11. This was opposed by IBM, speaking on behalf of itself and other users of C++, and as a result trigraphs were retained in C++0x. Trigraphs were then proposed again for removal (not only deprecation) in C++17. This passed a committee vote, and trigraphs (but not the additional tokens) are removed from C++17 despite the opposition from IBM. Existing code that uses trigraphs can be supported by translating from the source files (parsing trigraphs) to the basic source character set that does not include trigraphs.

Hewlett-Packard calculators supporting the RPL language and input method provide support for a large number of trigraphs (also called "TIO codes") to reliably transcribe non-seven-bit ASCII characters of the calculators' extended character set on foreign platforms, and to ease keyboard input without using the application. The first character of all TIO codes is a codice_37, followed by two other ASCII characters vaguely resembling the glyph to be substituted. All other characters can be entered using the special codice_38 TIO code syntax with nnn being a three-digit decimal number (with leading zeros if necessary) of the corresponding code point (thereby formally representing a "tetragraph").

The Vim text editor supports digraphs for actual entry of text characters, following . The entry of digraphs is bound to by default. The list of all possible digraphs in Vim can be displayed by typing .

GNU Screen has a digraph command, bound to by default.

Lotus 1-2-3 for DOS uses as compose key to allow easier input of many special characters of the Lotus International Character Set (LICS) and Lotus Multi-Byte Character Set (LMBCS).



</doc>
<doc id="456753" url="https://en.wikipedia.org/wiki?curid=456753" title="Duff's device">
Duff's device

In the C programming language, Duff's device is a way of manually implementing loop unrolling by interleaving two syntactic constructs of C: the - loop and a switch statement. Its discovery is credited to Tom Duff in November 1983, when Duff was working for Lucasfilm and used it to speed up a real-time animation program.

Loop unrolling attempts to reduce the overhead of conditional branching needed to check whether a loop is done, by executing a batch of loop bodies per iteration. To handle cases where the number of iterations is not divisible by the unrolled-loop increments, a common technique among assembly language programmers is to jump directly into the middle of the unrolled loop body to handle the remainder.
Duff implemented this technique in C by using C's case label fall-through feature to jump into the unrolled body.

Duff's problem was to copy 16-bit units ("shorts" in most C implementations) from an array into a memory-mapped output register, denoted in C by a pointer. His original code, in K&R C, looked as follows:

This code assumes that initial . The pointer is not incremented as would be required for a memory-to-memory copy. If were always divisible by eight, unrolling this loop eight-fold would produce the following:

Duff realized that to handle cases where is not divisible by eight, the assembly programmer's technique of jumping into the loop body could be implemented by interlacing the structures of a switch statement and a loop, putting the switch's labels at the points of the loop body that correspond to the remainder of :

Duff's device can similarly be applied with any other size for the unrolled loop, not just eight as in the example above.

Based on an algorithm used widely by programmers coding in assembly for minimizing the number of tests and branches during a copy, Duff's device appears out of place when implemented in C. The device is valid C by virtue of two attributes in C:

This leads to what the "Jargon File" calls "the most dramatic use yet seen of fall through in C". C's default fall-through in case statements has long been one of its most controversial features; Duff himself said that "This code forms some sort of argument in that debate, but I'm not sure whether it's for or against."

The basic idea of loop unrolling is that the number of instructions executed in a loop can be reduced by reducing the number of loop tests, sometimes reducing the amount of time spent in the loop. For example, in the case of a loop with only a single instruction in the block code, the loop test will typically be performed for every iteration of the loop, that is every time the instruction is executed. If, instead, eight copies of the same instruction are placed in the loop, then the test will be performed only every eight iterations, and this may gain time by avoiding seven tests. However, this only handles a multiple of eight iterations, requiring something else to handle any remainder of iterations.

Duff's device provides a solution by first performing the remainder of iterations, followed by iterating as many times as necessary the multiple of eight similar instructions. To determine the number of remainder iterations, the code first calculates the total number of iterations modulo eight. According to this remainder, the program execution will then "jump" to a codice_1 statement followed by "exactly the number of iterations needed". Once this is done, everything is straightforward the code continues by doing iterations of groups of eight instructions, this has become possible since the remaining number of iterations is a multiple of eight.

Duff's device provides a compact loop unrolling by using the case keyword "both inside and outside the loop". This is unusual because the contents of a case statement are traditionally thought of as a block of code nested inside the case statement, and a reader would typically expect it to end before the next case statement. According to the specifications of C language, this is not necessary; indeed, case statements can appear anywhere inside the switch code block, and at any depth; the program execution will simply jump to the next statement, wherever it may be.

Many compilers will optimize the switch into a jump table just as would be done in an assembly implementation.

The primary increase in speed versus a simple, straightforward loop, comes from loop unwinding that reduces the number of performed branches, which are computationally expensive due to the need to flushand hence stallthe instruction pipeline. The codice_2 statement is used to handle the remainder of the data not evenly divisible by the number of operations unrolled (in this example, eight byte moves are unrolled, so the codice_2 handles an extra 1–7 bytes automatically).

This automatic handling of the remainder may not be the best solution on all systems and compilers in some cases two loops may actually be faster (one loop, unrolled, to do the main copy, and a second loop to handle the remainder). The problem appears to come down to the ability of the compiler to correctly optimize the device; it may also interfere with pipelining and branch prediction on some architectures. When numerous instances of Duff's device were removed from the XFree86 Server in version 4.0, there was an improvement in performance and a noticeable reduction in size of the executable.<ref name="lkml-0008.2/0171"></ref> Therefore, when considering this code as a program optimization, it may be worth running a few benchmarks to verify that it actually is the fastest code on the target architecture, at the target optimization level, with the target compiler, as well as weighing the risk that the optimized code will later be used on different platforms where it is not the fastest code.

For the purpose of memory-to-memory copies (which, as mentioned above, was not the original use of Duff's device), the standard C library provides function codice_4; it will not perform worse than a memory-to-memory copy version of this code, and may contain architecture-specific optimizations that will make it significantly faster.




</doc>
<doc id="32546164" url="https://en.wikipedia.org/wiki?curid=32546164" title="Embedded C">
Embedded C

Embedded C is a set of language extensions for the C programming language by the C Standards Committee to address commonality issues that exist between C extensions for different embedded systems. 

Embedded C programming typically requires nonstandard extensions to the C language in order to support enhanced microprocessor features such as fixed-point arithmetic, multiple distinct memory banks, and basic I/O operations. In 2008, the C Standards Committee extended the C language to address such capabilities by providing a common standard for all implementations to adhere to. It includes a number of features not available in normal C, such as fixed-point arithmetic, named address spaces and basic I/O hardware addressing. Embedded C uses most of the syntax and semantics of standard C, e.g., main() function, variable definition, datatype declaration, conditional statements (if, switch case), loops (while, for), functions, arrays and strings, structures and union, bit operations, macros, etc. 

A Technical Report was published in 2004 and a second revision in 2006.


</doc>
<doc id="32561813" url="https://en.wikipedia.org/wiki?curid=32561813" title="Escape sequences in C">
Escape sequences in C

Escape sequences are used in the programming languages C and C++, and their design was copied in many other languages such as Java and C#. An escape sequence is a sequence of characters that does not represent itself when used inside a character or string literal, but is translated into another character or a sequence of characters that may be difficult or impossible to represent directly.

In C, all escape sequences consist of two or more characters, the first of which is the backslash, (called the "Escape character"); the remaining characters determine the interpretation of the escape sequence. For example, is an escape sequence that denotes a newline character.

Suppose we want to print out on one line, followed by on the next line. One could attempt to represent the string to be printed as a single literal as follows:
int main() {
world!");

This is not valid in C, since a string literal may not span multiple logical source lines. This can be worked around by printing the newline character using its numerical value ( in ASCII),
int main() {

This instructs the program to print , followed by the byte whose numerical value is , followed by . While this will indeed work when the machine uses the ASCII encoding, it will not work on systems that use other encodings, that have a different numerical value for the newline character. It is also not a good solution because it still does not allow to represent a newline character inside a literal, and instead takes advantage of the semantics of printf. In order to solve these problems and ensure maximum portability between systems, C interprets inside a literal as a newline character, whatever that may be on the target system:
int main() {

In this code, the escape sequence does not stand for a backslash followed by the letter , because the backslash causes an "escape" from the normal way characters are interpreted by the compiler. After seeing the backslash, the compiler expects another character to complete the escape sequence, and then translates the escape sequence into the bytes it is intended to represent. Thus, represents a string with an embedded newline, regardless of whether it is used inside or anywhere else.

This raises the issue of how to represent an actual backslash inside a literal. This is done by using the escape sequence , as seen in the next section.

Some languages don't have escape sequences, for example Pascal. Instead a command including a newline would be used (writeln includes a newline, write excludes it).

writeln('Hello');
write('world!');
The following escape sequences are defined in standard C. This table also shows the values they map to in ASCII. However, these escape sequences can be used on any system with a C compiler, and may map to different values if the system does not use a character encoding based on ASCII.

 produces one byte, despite the fact that the platform may use more than one byte to denote a newline, such as the DOS/Windows CR-LF sequence, . The translation from to on DOS and Windows occurs when the byte is written out to a file or to the console, and the inverse translation is done when text files are read.

A hex escape sequence must have at least one hex digit following , with no upper bound; it continues for as many hex digits as there are. Thus, for example, denotes the byte with the numerical value ABCDEF, followed by the letter , which is not a hex digit. However, if the resulting integer value is too large to fit in a single byte, the actual numerical value assigned is implementation-defined. Most platforms have 8-bit types, which limits a useful hex escape sequence to two hex digits. However, hex escape sequences longer than two hex digits might be useful inside a wide character or wide string literal(prefixed with L):

char s1[] = "\x12"; // single char with value 0x12 (18 in decimal)
char s1[] = "\x1234"; // single char with implementation-defined value, unless char is long enough
wchar_t s2[] = L"\x1234"; // single wchar_t with value 0x1234, provided wchar_t is long enough (16 bits suffices)
An octal escape sequence consists of followed by one, two, or three octal digits. The octal escape sequence ends when it either contains three octal digits already, or the next character is not an octal digit. For example, is a single octal escape sequence denoting a byte with numerical value 9 (11 in octal), rather than the escape sequence followed by the digit . However, is the octal escape sequence followed by the digit . In order to denote the byte with numerical value 1, followed by the digit , one could use , since C automatically concatenates adjacent string literals. Note that some three-digit octal escape sequences may be too large to fit in a single byte; this results in an implementation-defined value for the byte actually produced. The escape sequence is a commonly used octal escape sequence, which denotes the null character, with value zero.

A sequence such as is not a valid escape sequence according to the C standard as it is not found in the table above. The C standard requires such "invalid" escape sequences to be diagnosed (i.e., the compiler must print an error message). Notwithstanding this fact, some compilers may define additional escape sequences, with implementation-defined semantics. An example is the escape sequence, which has 1B as the hexadecimal value in ASCII, represents the escape character, and is supported in GCC, clang and tcc. It wasn't however added to the C standard repertoire, because it has no meaningful equivalent in some character sets (such as EBCDIC).

From the C99 standard, C has also supported escape sequences that denote Unicode code points in string literals. Such escape sequences are called "universal character names", and have the form or , where stands for a hex digit. Unlike the other escape sequences considered, a universal character name may expand into more than one code unit.

The sequence denotes the code point , interpreted as a hexadecimal number. The sequence denotes the code point , interpreted as a hexadecimal number. (Therefore, code points located at U+10000 or higher must be denoted with the syntax, whereas lower code points may use or .) The code point is converted into a sequence of code units in the encoding of the destination type on the target system. For example, consider

char s1[] = "\xC0";
char s2[] = "\u00C1";
wchar_t s3[] = L"\xC0";
wchar_t s4[] = L"\u00C0";

The string will contain a single byte (not counting the terminating null) whose numerical value, the actual value stored in memory, is in fact . The string will contain the character "Á", U+00C1 . On a system that uses the UTF-8 encoding, the string will contain "two" bytes, . The string contains a single , again with numerical value . The string contains the character "À" encoded into , if the UTF-16 encoding is used, then will also contain only a single , 16 bits long, with numerical value . A universal character name such as may be represented by a single if the UTF-32 encoding is used, or two if UTF-16 is used.

Importantly, the universal character name always denotes the character "À", regardless of what kind of string literal it is used in, or the encoding in use. Again, always denotes the character at code point 1F603, regardless of context. On the other hand, octal and hex escape sequences always denote certain sequences of numerical values, regardless of encoding. Therefore, universal character names are complementary to octal and hex escape sequences; while octal and hex escape sequences represent "physical" code units, universal character names represent code points, which may be thought of as "logical" characters.




</doc>
<doc id="7729061" url="https://en.wikipedia.org/wiki?curid=7729061" title="F2c">
F2c

f2c is a program to convert Fortran 77 to C code, developed at Bell Laboratories. The standalone f2c program was based on the core of the first complete Fortran 77 compiler to be implemented, the "f77" program by Feldman and Weinberger. Because the f77 compiler was itself written in C and relied on a C compiler back end to complete its final compilation step, it and its derivatives like f2c were much more portable than compilers generating machine code directly.

The f2c program was released as free software and subsequently became one of the most common means to compile Fortran code on many systems where native Fortran compilers were unavailable or expensive. Several large Fortran libraries, such as LAPACK, were made available as C libraries via conversion with f2c. The f2c program also influenced the development of the GNU g77 compiler, which uses a modified version of the f2c runtime libraries.




</doc>
<doc id="8715879" url="https://en.wikipedia.org/wiki?curid=8715879" title="Impulse C">
Impulse C

Impulse C is a subset of the C programming language combined with a C-compatible function library supporting parallel programming, in particular for programming of applications targeting FPGA devices. It is developed by Impulse Accelerated Technologies of Kirkland, Washington.

The High-level synthesis tool CoDeveloper includes an Impulse C compiler and related function library intended for development of FPGA-based applications. Impulse C is compatible with standard ANSI C, allowing standard C tools to be used for designing and debugging applications targeting FPGAs. The Impulse C compiler accepts a subset of C and generates FPGA hardware in the form of Hardware Description Language (HDL) files. Impulse C allows embedded systems designers and software programmers to target FPGA devices for C-language application acceleration.

Impulse C is distinct from standard C in that it provides a parallel programming model for mixed processor and FPGA platforms. For this purpose, Impulse C includes extensions to C, in the form of functions and datatypes, allowing applications written in standard C to be mapped onto coarse-grained parallel architectures that may include standard processors along with programmable FPGA hardware.

The Impulse C tools include hardware/software co-simulation tools as well as C-to-RTL scheduling/optimizing technology used to map application elements to hardware via FPGA logic synthesis tools.

Impulse C supports a variant of the communicating sequential processes (CSP) programming model, while remaining compatible with standard C tools such as debuggers and profilers. Impulse C is designed for dataflow-oriented, streaming applications, but is also designed to support alternate programming models including the use of shared memory as a communication mechanism.

In an Impulse C streaming application, hardware and software processes communicate primarily through buffered data streams that are implemented directly in hardware. This buffering of data, which is implemented using dual-clock FIFOs generated by the compiler, makes it possible to write parallel applications at a relatively high level of abstraction, without the cycle-by-cycle synchronization that would otherwise be required. 

Using Impulse C, an application can be partitioned to create a multiple-process implementation that is partitioned into hardware and software components, or implemented entirely within an FPGA device. For example, an image filtering application could be described using Impulse C as a collection of parallel, pipelined processes, each of which has been described using one or more C subroutines.

On the software side of the application, for example in an embedded FPGA processor, Impulse C library functions are used to open and close data streams, read or write data on the streams and, if desired, send status messages or poll for results. For processor-to-FPGA communications, stream reads and writes can be specified as operations that take advantage of FPGA-specific, internal or external bus interfaces.

On the hardware side of the application, Impulse C library functions and other C statements are compiled to generate equivalent, parallel hardware implementations in the form of synthesizable HDL files. These files are processed by FPGA tools to create FPGA hardware bitmaps.

At the heart of the Impulse C streaming programming model are processes and streams. Processes are independently synchronized, concurrently executing segments of an application. Hardware processes are written using a subset of standard C and perform the work of an application by accepting data, performing computations and generating outputs. 
In a typical application, data flows from process to process by means of buffered streams, or in some cases by means of messages and/or shared memories. The characteristics of each stream, including the width and depth of the generated FIFOs, may be specified in the C application.

Impulse C is used for applications including image processing and digital signal processing on embedded systems, as well as for acceleration of high-performance computing applications including financial analytics, bioinformatics and scientific computing.

Impulse C supports FPGAs from Xilinx and Altera, including their available soft- and hard-core processors the Altera Nios II and Xilinx's MicroBlaze and PowerPC.



</doc>
<doc id="4622578" url="https://en.wikipedia.org/wiki?curid=4622578" title="Interactive C">
Interactive C

Interactive C is a program which uses a modified version of ANSI C with several libraries and features that allow hobbyists to program small robotics platforms.

Newton Research Labs developed Interactive C as a compiling environment for robots using the Motorola 6811 processor. The MIT LEGO Robot Design Contest (6.270) was the original purpose for the software. It became popular, however, due to its ability to compile on the fly rather than taking time to compile beforehand as other languages had done. The programming environment's newest version is IC Version 8.0.2, which supports these operating systems:

The screenshot to the right shows Interactive C running on a Windows operating system. The program features an "Interaction Window" where one-line C commands can be sent to the connected controller as well as an editing window, here titled "main.c", where a program file is being edited and can be sent to the attached controller.

Here is the basic "Hello World" example for IC programming:

Here is another example using motor ports 1 and 3:

A basic infinite loop that will beep for ever:
Interactive C is used by The Ohio State University to program MIT Handy Boards in its Fundamentals of Engineering for Honors Program. 

KISS Institute for Practical Robotics developed a third-party alternative to the Newton Labs version of Interactive C for their Botball Educational Robotics Program.

The latest version of Interactive C by KISS Institute for Practical Robotics is IC 8.0.2, which supports these operating systems:

IC8 supports the following robotics controllers:



</doc>
<doc id="4051" url="https://en.wikipedia.org/wiki?curid=4051" title="Brian Kernighan">
Brian Kernighan

Brian Wilson Kernighan (; born January 1, 1942) is a Canadian computer scientist.

He worked at Bell Labs and contributed to the development of Unix alongside Unix creators Ken Thompson and Dennis Ritchie.

Kernighan's name became widely known through co-authorship of the first book on the C programming language with Dennis Ritchie. Kernighan affirmed that he had no part in the design of the C language ("it's entirely Dennis Ritchie's work"). He authored many Unix programs, including ditroff.

Kernighan is coauthor of the AWK and AMPL programming languages. The "K" of K&R C and the "K" in AWK both stand for "Kernighan". 

In collaboration with Shen Lin he devised well-known heuristics for two NP-complete optimization problems: graph partitioning and the travelling salesman problem. In a display of authorial equity, the former is usually called the Kernighan–Lin algorithm, while the latter is known as the Lin–Kernighan heuristic.

Kernighan has been a Professor in the Computer Science Department of Princeton University since 2000. He is also the Undergraduate Department Representative.

Kernighan was born in Toronto. He attended the University of Toronto between 1960 and 1964, earning his Bachelor's degree in engineering physics. He received his PhD in electrical engineering from Princeton University in 1969 for research supervised by Peter Weiner.

Kernighan has held a professorship in the Department of Computer Science at Princeton since 2000. Each fall he teaches a course called "Computers in Our World", which introduces the fundamentals of computing to non-majors. 

Kernighan was the software editor for Prentice Hall International. His "Software Tools" series spread the essence of "C/Unix thinking" with makeovers for BASIC, FORTRAN, and Pascal, and most notably his "Ratfor" (rational FORTRAN) was put in the public domain.

He has said that if stranded on an island with only one programming language it would have to be C.

Kernighan coined the term Unix and helped popularize Thompson's Unix philosophy. Kernighan is also known as a coiner of the expression "What You See Is All You Get" (WYSIAYG), which is a sarcastic variant of the original "What You See Is What You Get" (WYSIWYG). Kernighan's term is used to indicate that WYSIWYG systems might throw away information in a document that could be useful in other contexts.

Kernighan's original 1978 implementation of Hello, World! was sold at The Algorithm Auction, the world's first auction of computer algorithms.

In 1996, Kernighan taught CS50 which is the Harvard University introductory course in Computer Science.

Other achievements during his career include:



</doc>
<doc id="9256277" url="https://en.wikipedia.org/wiki?curid=9256277" title="Linkage (software)">
Linkage (software)

In programming languages, particularly the compiled ones like C, C++, and D, linkage describes how names can or can not refer to the same entity throughout the whole program or one single translation unit.

The codice_1 keyword is used in C to restrict the visibility of a function or variable to its translation unit. This is also valid in C++. (C++ 98/03 deprecated this usage in favor of anonymous namespaces, but is no longer deprecated in C++ 11.) Also, C++ implicitly treats any codice_2 namespace-scope variable as having internal linkage unless it is explicitly declared codice_3, unlike C.

A name's linkage is related to, but distinct from, its scope. The scope of a name is the part of a translation unit where it is visible. For instance, a name with global scope (which is the same as file-scope in C and the same as the global namespace-scope in C++) is visible in any part of the file. Its scope will end at the end of the translation unit, whether or not that name has been given external or internal linkage. 

If the name has external linkage, the entity that name denotes may be referred to from another translation unit using a distinct declaration for that same name, and from other scopes within the same translation unit using distinct declarations. Were the name given internal linkage, such a declaration would denote a distinct entity, although using the same name, but its entity could be referred to by distinct declarations within the same translation unit. A name that has no linkage at all cannot be referred to from declarations in different scopes, not even from within the same translation unit. Examples of such names are parameters of functions and local variables. The details differ between C (where only objects and functions - but not types - have linkage) and C++ and between this simplified overview.

Linkage between languages must be done with some care, as different languages adorn their external symbols differently.
A common idiom uses codice_4 to link C++ and C code.

Definition of 'linkage' quoted from ISO/IEC 9899:TC3 (C99 Standard). C uses the term "identifier" where this article uses "name" (the latter of which is what C++ uses to formalize linkage):

An identifier declared in different scopes or in the same scope more than once can be made to refer to the same object or function by a process called linkage.

The following is a common example of linkage:

Function codice_5 is declared in two files, with its function body defined in demo2.c. Via linkage, codice_5 called in codice_7 inside demo1.c refers to codice_5 in demo2.c. This is an example of external linkage for a function.



</doc>
<doc id="3686118" url="https://en.wikipedia.org/wiki?curid=3686118" title="Long double">
Long double

In C and related programming languages, codice_1 refers to a floating-point data type that is often more precise than double-precision though the language standard only requires it to be at least as precise as codice_2. As with C's other floating-point types, it may not necessarily map to an IEEE format.

The codice_1 type was present in the original 1989 C standard, but support was improved by the 1999 revision of the C standard, or C99, which extended the standard library to include functions operating on codice_1 such as codice_6 and codice_7.

Long double constants are floating-point constants suffixed with "L" or "l" (lower-case L), e.g., 0.333333333333333333L. Without a suffix, the evaluation depends on FLT_EVAL_METHOD.

On the x86 architecture, most C compilers implement codice_1 as the 80-bit extended precision type supported by x86 hardware (sometimes stored as 12 or 16 bytes to maintain data structure alignment), as specified in the C99 / C11 standards (IEC 60559 floating-point arithmetic (Annex F)). An exception is Microsoft Visual C++ for x86, which makes codice_1 a synonym for codice_2. The Intel C++ compiler on Microsoft Windows supports extended precision, but requires the codice_11 switch for codice_1 to correspond to the hardware's extended precision format.

Compilers may also use codice_1 for the (binary128). This is the case on HP-UX, Solaris/SPARC, and 64-bit ARM (AArch64) machines. Most implementations are in software, but some processors have hardware support.

On some PowerPC and SPARCv9 machines, codice_1 is implemented as a double-double arithmetic, where a codice_1 value is regarded as the exact sum of two double-precision values, giving at least a 106-bit precision; with such a format, the codice_1 type does not conform to the IEEE floating-point standard. Otherwise, codice_1 is simply a synonym for codice_2 (double precision), e.g. on 32-bit ARM.

With the GNU C Compiler, codice_1 is 80-bit extended precision on x86 processors regardless of the physical storage used for the type (which can be either 96 or 128 bits), On some other architectures, codice_1 can be double-double (e.g. on PowerPC) or 128-bit quadruple precision (e.g. on SPARC). As of gcc 4.3, a quadruple precision is also supported on x86, but as the nonstandard type codice_21 rather than codice_1.

Although the x86 architecture, and specifically the x87 floating-point instructions on x86, supports 80-bit extended-precision operations, it is possible to configure the processor to automatically round operations to double (or even single) precision. Conversely, in extended-precision mode, extended precision may be used for intermediate compiler-generated calculations even when the final results are stored at a lower precision (i.e. FLT_EVAL_METHOD == 2). With gcc on Linux, 80-bit extended precision is the default; on several BSD operating systems (FreeBSD and OpenBSD), double-precision mode is the default, and codice_1 operations are effectively reduced to double precision. (NetBSD 7.0 and later, however, defaults to 80-bit extended precision ). However, it is possible to override this within an individual program via the FLDCW "floating-point load control-word" instruction. On x86_64 the BSDs default to 80-bit extended precision. Microsoft Windows with Visual C++ also sets the processor in double-precision mode by default, but this can again be overridden within an individual program (e.g. by the codice_24 function in Visual C++). The Intel C++ Compiler for x86, on the other hand, enables extended-precision mode by default. On IA-32 OS X, codice_1 is 80-bit extended precision.

In CORBA (from specification of 3.0, which uses "ANSI/IEEE Standard 754-1985" as its reference), "the long double data type represents an IEEE double-extended floating-point number, which has an exponent of at least 15 bits in length and a signed fraction of at least 64 bits", with GIOP/IIOP CDR, whose floating-point types "exactly follow the IEEE standard formats for floating point numbers", marshalling this as what seems to be IEEE 754-2008 binary128 a.k.a. quadruple precision without using that name.



</doc>
<doc id="6782013" url="https://en.wikipedia.org/wiki?curid=6782013" title="MISRA C">
MISRA C

MISRA C is a set of software development guidelines for the C programming language developed by MISRA (Motor Industry Software Reliability Association). Its aims are to facilitate code safety, security, portability and reliability in the context of embedded systems, specifically those systems programmed in ISO C / C90 / C99.

There is also a set of guidelines for MISRA C++ not covered by this article.


For the first two editions of MISRA-C (1998 and 2004) all Guidelines were considered as Rules. With the publication of MISRA C:2012 a new category of Guideline was introduced - the "Directive" whose compliance is more open to interpretation, or relates to process or procedural matters.

Although originally specifically targeted at the automotive industry, MISRA C has evolved as a widely accepted model for best practices by leading developers in sectors including automotive, aerospace, telecom, medical devices, defense, railway, and others.
For example:


When a new software project is started, the latest MISRA standard should be used. Previous standards are still available for use with legacy software projects that need to refer to it.

Each Guideline is classified as "Mandatory" (new for MISRA C:2012), "Required" or "Advisory". Furthermore, the MISRA Compliance document permits "Advisory" guidelines to be "Disapplied".


The rules can be divided logically into a number of categories:


MISRA C:2012 separately classifies each guideline as either "Single Translation Unit" or "System".

MISRA C:2012 classifies the "rules" (but not the "directives") as "Decidable" or "Undecidable".

In April 2016, MISRA published "MISRA Compliance:2016", which provides enhanced guidance on achieving compliance to MISRA C and MISRA C++.

In order for a piece of software to claim to be compliant to the MISRA C Guidelines, all "mandatory" rules shall be met and all "required" rules and directives shall either be met or subject to a formal deviation. "Advisory" rules may be disapplied without a formal deviation, but this should still be recorded in the project documentation.

Note: For compliance purposes, there is no distinction between "rules" and "directives".

Many MISRA C "rules" can be characterized as "guidelines" because under certain condition software engineers may deviate from rules and still be considered compliant with the standard. Deviations must be documented either in the code or in a file. In addition; proof must be provided that the software engineer has considered the safety of the system and that deviating from the rule will not have a negative impact, requirements for deviations also include:


The first edition of MISRA C, "Guidelines for the use of the C language in vehicle based software", which was published in 1998 and is officially known as "MISRA-C:1998".

MISRA-C:1998 has 127 rules, of which 93 are required and 34 are advisory; the rules are numbered in sequence from 1 to 127.

In 2004, a second edition "Guidelines for the use of the C language in critical systems", or "MISRA-C:2004" was produced, with many substantial changes to the guidelines, including a complete renumbering of the rules.

MISRA-C:2004 contains 142 rules, of which 122 are "required" and 20 are "advisory"; they are divided into 21 topical categories, from "Environment" to "Run-time failures".

In 2013, the third edition, MISRA C:2012, was published. MISRA C:2012 extends support to the C99 version of the C language (while maintaining guidelines for C90), in addition to including a number of improvements that can reduce the cost and complexity of compliance, whilst aiding consistent, safe use of C in critical systems.

MISRA-C:2012 contains 143 rules and 16 "directives" (that is, rules whose compliance is more open to interpretation, or relates to process or procedural matters); each of which is classified as "mandatory", "required", or "advisory". They are separately classified as either "Single Translation Unit" or "System". Additionally, the rules are classified as "Decidable" or "Undecidable".

In April 2016, MISRA published (as a free download) "MISRA C:2012 - Amendment 1: Additional Security Guidelines" which added fourteen new security guidelines.

MISRA have published the following addenda to support MISRA C:2012:


An exemplar suite (for MISRA-C:2004 and MISRA C:2012) is available from the MISRA GitLab repository. This allows tool-users to evaluate and compare the checking support provided by the various MISRA tools; additionally, it gives tool-implementers some guidance as to the intent of the MISRA Guidelines.

While there exist many software tools that claim to check code for "MISRA conformance", there is no MISRA certification process.

Most of the guidelines can be checked using tools that perform static code analysis. The remaining guidelines require the use of dynamic code analysis.

Tools that check code for MISRA conformance include:

C/C++ compilers that support MISRA conformance include:

Some research results question the effectiveness of MISRA.

In a paper that compares earlier work on MISRA C:1998 with MISRA C:2004, Les Hatton comes to the conclusion that:

He goes on to state:

A study at the TU Delft, by Cathal Boogerd and Leon Moonen, empirically assesses the value of MISRA C:2004. It comes to similar results:




</doc>
<doc id="22482961" url="https://en.wikipedia.org/wiki?curid=22482961" title="Painted blue">
Painted blue

Blue paint refers to the mark given to preprocessing tokens by the C preprocessor that temporarily disables expansion of those tokens. A token is said to be painted blue when it has been disabled in this way. While the original author of the term is disputed, Derek Jones states that it came about as a reference to blue ink used by the C committee.


</doc>
<doc id="37005981" url="https://en.wikipedia.org/wiki?curid=37005981" title="The Power of 10: Rules for Developing Safety-Critical Code">
The Power of 10: Rules for Developing Safety-Critical Code

The Power of 10 Rules were created in 2006 by Gerard J. Holzmann of the NASA/JPL Laboratory for Reliable Software. The rules are intended to eliminate certain C coding practices which make code difficult to review or statically analyze. These rules are a complement to the MISRA C guidelines and have been incorporated into the greater set of JPL coding standards.

The ten rules are:

The NASA study of the Toyota Electronic throttle control firmware found at least 243 violations of these rules.



</doc>
<doc id="8869115" url="https://en.wikipedia.org/wiki?curid=8869115" title="Restrict">
Restrict

In the C programming language, codice_1 is a keyword that can be used in pointer declarations. By adding this type qualifier, a programmer hints to the compiler that for the lifetime of the pointer, only the pointer itself or a value directly derived from it (such as ) will be used to access the object to which it points.

codice_1 limits the effects of pointer aliasing, aiding optimizations. If the declaration of intent is not followed and the object is accessed by an independent pointer, this will result in undefined behavior. The use of this type qualifier in C, in principle, allows non-obtuse C to achieve the same performance as the same program written in Fortran. It was introduced in C99 standard.

C++ does not have standard support for codice_1, but many compilers have equivalents that usually work in both C++ and C, such as the GCC's and Clang's codice_4, and Visual C++'s codice_5. In addition, codice_6 is supported by those three compilers. The exact interpretation of these alternative keywords vary by the compiler:


If the compiler knows that there is only one pointer to a memory block, it can produce better optimized code. For instance:

In the above code, the pointers codice_7, codice_8, and codice_9 "might" refer to the same memory location, so the compiler may generate less optimal code:
However, if the codice_1 keyword is used and the above function is declared as

then the compiler is allowed to "assume" that codice_7, codice_8, and codice_9 point to different locations and updating one pointer will not affect the other pointers. The programmer, not the compiler, is responsible for ensuring that the pointers do not point to identical locations. The compiler can e.g. rearrange the code, first loading all memory locations, then performing the operations before committing the results back to memory.

The above assembly code is shorter because codice_9 is loaded only once. Also, since the compiler can rearrange the code more freely, the compiler can generate code that executes faster. In the second version of the above example, the codice_15 operations are all taking place after the codice_16 operations, ensuring that the processor won't have to block in the middle of the code to wait until the codice_15 operations are complete.

Note that the real generated code may have different behaviors. Benefit with the above mini-example tends to be small, and in real-life cases large loops doing heavy memory access tends to be what is really helped by restrict.

As mentioned above, how incorrect code behaves is undefined, the compiler only ensures the generated code works properly if the code follows the declaration of intent.

To help prevent incorrect code, some compilers and other tools try to detect when overlapping arguments have been passed to functions with parameters marked . The CERT C Coding Standard considers misuse of and library functions marked with it (EXP43-C) a probable source of software bugs, although as of November 2019 no vulnerabilities are known to have been caused by this.



</doc>
<doc id="33691376" url="https://en.wikipedia.org/wiki?curid=33691376" title="C string handling">
C string handling

The C programming language has a set of functions implementing operations on strings (character strings and byte strings) in its standard library. Various operations, such as copying, concatenation, tokenization and searching are supported. For character strings, the standard library uses the convention that strings are null-terminated: a string of characters is represented as an array of elements, the last of which is a "NUL" character.

The only support for strings in the programming language proper is that the compiler translates quoted string constants into null-terminated strings.

A string is defined as a contiguous sequence of code units terminated by the first zero code unit (often called the "NUL" code unit). This means a string cannot contain the zero code unit, as the first one seen marks the end of the string. The "length" of a string is the number of code units before the zero code unit. The memory occupied by a string is always one more code unit than the length, as space is needed to store the zero terminator.

Generally, the term "string" means a string where the code unit is of type codice_1, which is exactly 8 bits on all modern machines. C90 defines "wide strings" which use a code unit of type codice_2, which is 16 or 32 bits on modern machines. This was intended for Unicode but it is increasingly common to use UTF-8 in normal strings for Unicode instead.

Strings are passed to functions by passing a pointer to the first code unit. Since codice_3 and codice_4 are different types, the functions that process wide strings are different than the ones processing normal strings and have different names.

String literals (codice_5 in the C source code) are converted to arrays during compilation. The result is an array of code units containing all the characters plus a trailing zero code unit. In C90 codice_6 produces a wide string. A string literal can contain the zero code unit (one way is to put codice_7 into the source), but this will cause the string to end at that point. The rest of the literal will be placed in memory (with another zero code unit added to the end) but it is impossible to know those code units were translated from the string literal, therefore such source code is "not" a string literal.

Each string ends at the first occurrence of the zero code unit of the appropriate kind (codice_1 or codice_2). Consequently, a byte string can contain non-NUL characters in ASCII or any ASCII extension, but not characters in encodings such as UTF-16 (even though a 16-bit code unit might be nonzero, its high or low byte might be zero). The encodings that can be stored in wide strings are defined by the width of codice_2. In most implementations, codice_2 is at least 16 bits, and so all 16-bit encodings, such as UCS-2, can be stored. If codice_2 is 32-bits, then 32-bit encodings, such as UTF-32, can be stored.

Variable-width encodings can be used in both byte strings and wide strings. String length and offsets are measured in bytes or codice_2, not in "characters", which can be confusing to beginning programmers. UTF-8 and Shift JIS are often used in C byte strings, while UTF-16 is often used in C wide strings when codice_2 is 16 bits. Truncating strings with variable length characters using functions like codice_15 can produce invalid sequences at the end of the string. This can be unsafe if the truncated parts are interpreted by code that assumes the input is valid.

Support for Unicode literals such as codice_16(UTF-8) or codice_17 (UTF-16 or UTF-32) is implementation defined, and may require that the source code be in the same encoding. Some compilers or editors will require entering all non-ASCII characters as codice_18 sequences for each byte of UTF-8, and/or codice_19 for each word of UTF-16.

Most of the functions that operate on C strings are declared in the codice_20 header (codice_21 in C++), while functions that operate on C wide strings are declared in the codice_22 header (codice_23 in C++). These headers also contain declarations of functions used for handling memory buffers; the name is thus something of a misnomer.

Functions declared in codice_20 are extremely popular since, as a part of the C standard library, they are guaranteed to work on any platform which supports C. However, some security issues exist with these functions, such as potential buffer overflows when not used carefully and properly, causing the programmers to prefer safer and possibly less portable variants, out of which some popular ones are listed below. Some of these functions also violate const-correctness by accepting a codice_25 string pointer and returning a non-codice_25 pointer within the string. To correct this, some have been separated into two overloaded functions in the C++ version of the standard library.

In historical documentation the term "character" was often used instead of "byte" for C strings, which leads many to believe that these functions somehow do not work for UTF-8. In fact all lengths are defined as being in bytes and this is true in all implementations, and these functions work as well with UTF-8 as with single-byte encodings. The BSD documentation has been fixed to make this clear, but POSIX, Linux, and Windows documentation still uses "character" in many places where "byte" or "wchar_t" is the correct term.

Functions for handling memory buffers can process sequences of bytes that include null-byte as part of the data. Names of these functions typically start with codice_27, as opposite to the codice_28 prefix.

These functions all take a pointer to a <samp>mbstate_t</samp> object that the caller must maintain. This was originally intended to track shift states in the <samp>mb</samp> encodings, but modern ones such as UTF-8 do not need this. However these functions were designed on the assumption that the <samp>wc</samp> encoding is not a variable-width encoding and thus are designed to deal with exactly one <samp>wchar_t</samp> at a time, passing it by value rather than using a string pointer. As UTF-16 is a variable-width encoding, the <samp>mbstate_t</samp> has been reused to keep track of surrogate pairs in the wide encoding, though the caller must still detect and call <samp>mbtowc</samp> twice for a single character.

The C standard library contains several functions for numeric conversions. The functions that deal with byte strings are defined in the codice_29 header (codice_30 header in C++). The functions that deal with wide strings are defined in the codice_22 header (codice_23 header in C++).

The codice_33 functions are not const-correct, since they accept a codice_25 string pointer and return a non-codice_25 pointer within the string.

Also, since the Normative Amendment 1 (C95), codice_36 functions are considered subsumed by codice_33 functions, for which reason neither C95 nor any later standard provides wide-character versions of these functions. The argument against codice_36 is that they do not differentiate between an error and a codice_39.

Despite the well-established need to replace codice_40 and codice_41 with functions that do not allow buffer overflows, no accepted standard has arisen. This is partly due to the mistaken belief by many C programmers that codice_42 and codice_15 have the desired behavior; however, neither function was designed for this (they were intended to manipulate null-padded fixed-size string buffers, a data format less commonly used in modern software), and the behavior and arguments are non-intuitive and often written incorrectly even by expert programmers.

The most popular replacement are the codice_44 and codice_45 functions, which appeared in OpenBSD 2.4 in December, 1998. These functions always write one NUL to the destination buffer, truncating the result if necessary, and return the size of buffer that would be needed, which allows detection of the truncation and provides a size for creating a new buffer that will not truncate. They have been criticized on the basis of allegedly being inefficient, encouraging the use of C strings (instead of some superior alternative form of string), and hiding other potential errors. Consequently, they have not been included in the GNU C library (used by software on Linux), although they are implemented in the C libraries for OpenBSD, FreeBSD, NetBSD, Solaris, OS X, and QNX, as well as in alternative C libraries for Linux, such as musl introduced in 2011. The lack of GNU C library support has not stopped various software authors from using it and bundling a replacement, among other SDL, GLib, ffmpeg, rsync, and even internally in the Linux kernel. Open source implementations for these functions are available.

As part of its 2004 Security Development Lifecycle, Microsoft introduced a family of "secure" functions including codice_46 and codice_47 (along with many others). These functions were standardized with some minor changes as part of the optional C11 (Annex K) proposed by ISO/IEC WDTR 24731. Experience with these functions has shown significant problems with their adoption and errors in usage, so the removal of Annex K is proposed for the next revision of the C standard. These functions perform various checks including whether the string is too long to fit in the buffer. If the checks fail, a user-specified "runtime-constraint handler" function is called, which usually aborts the program. Some functions perform destructive operations before calling the runtime-constraint handler; for example, codice_47 sets the destination to the empty string, which can make it difficult to recover from error conditions or debug them. These functions attracted considerable criticism because initially they were implemented only on Windows and at the same time warning messages started to be produced by Microsoft Visual C++ suggesting the programmers to use these functions instead of standard ones. This has been speculated by some to be an attempt by Microsoft to lock developers into its platform. Although open-source implementations of these functions are available, these functions are not present in common Unix C libraries.

If the string length is known, then codice_49 or codice_50 are more efficient than codice_41 as they do not repeatedly check for the NUL terminator. They need a buffer length as a parameter, so they can't lead to buffer overflows in a manner similar to the aforementioned functions as long the supplied buffer length is right.




</doc>
<doc id="26009779" url="https://en.wikipedia.org/wiki?curid=26009779" title="Translation unit (programming)">
Translation unit (programming)

In C and C++ programming language terminology, a translation unit is the ultimate input to a C or C++ compiler from which an object file is generated. In casual usage it is sometimes referred to as a compilation unit. A translation unit roughly consists of a source file after it has been processed by the C preprocessor, meaning that header files listed in codice_1 directives are literally included, sections of code within codice_2 may be included, and macros have been expanded.

A C program consists of "units" called "source files" (or "preprocessing files"), which, in addition to source code, includes directives for the C preprocessor. A translation unit is the output of the C preprocessor – a source file after it has been preprocessed.

Preprocessing notably consists of expanding a source file to recursively replace all codice_1 directives with the literal file declared in the directive (usually header files, but possibly other source files); the result of this step is a "preprocessing translation unit". Further steps include macro expansion of codice_4 directives, and conditional compilation of codice_5 directives, among others; this translates the preprocessing translation unit into a "translation unit". From a translation unit, the compiler generates an object file, which can be further processed and linked (possibly with other object files) to form an "executable program". 

Note that the preprocessor is in principle language agnostic, and is a lexical preprocessor, working at the lexical analysis level – it does not do parsing, and thus is unable to do any processing specific to C syntax. The input to the compiler is the translation unit, and thus it does not see any preprocessor directives, which have all been processed before compiling starts. While a given translation unit is fundamentally based on a file, the actual source code fed into the compiler may appear substantially different than the source file that the programmer views, particularly due to the recursive inclusion of headers.

Translation units define a scope, roughly file scope, and functioning similarly to module scope; in C terminology this is referred to as internal linkage, which is one of the two forms of linkage in C. Names (functions and variables) declared outside of a function block may be visible either only within a given translation unit, in which case they are said to have internal linkage – they are not visible to the linker – or may be visible to other object files, in which case they are said to have external linkage, and are visible to the linker.

C does not have a notion of modules. However, separate object files (and hence also the translation units used to produce object files) function similarly to separate modules, and if a source file does not include other source files, internal linkage (translation unit scope) may be thought of as "file scope, including all header files".

The bulk of a project's code is typically held in files with a codice_6 suffix (or codice_7, codice_8 or codice_9 for C++, of which codice_7 is used most conventionally). Files intended to be included typically have a codice_11 suffix ( codice_12 or codice_13 are also used for C++, but codice_11 is the most common even for C++), and generally do not contain function or variable definitions to avoid name conflicts when headers are included in multiple source files, as is often the case. Header files can be, and often are, included in other header files. It is standard practice for all codice_6 files in a project to include at least one codice_11 file.



</doc>
<doc id="492281" url="https://en.wikipedia.org/wiki?curid=492281" title="Union type">
Union type

In computer science, a union is a value that may have any of several representations or formats within the same position in memory; that consists of a variable that may hold such a data structure. Some programming languages support special data types, called union types, to describe such values and variables. In other words, a union type definition will specify which of a number of permitted primitive types may be stored in its instances, e.g., "float or long integer". In contrast with a record (or structure), which could be defined to contain a float "and" an integer; in a union, there is only one value at any given time.

A union can be pictured as a chunk of memory that is used to store variables of different data types. Once a new value is assigned to a field, the existing data is overwritten with the new data. The memory area storing the value has no intrinsic type (other than just bytes or words of memory), but the value can be treated as one of several abstract data types, having the type of the value that was last written to the memory area.

In type theory, a union has a sum type; this corresponds to disjoint union in mathematics.

Depending on the language and type, a union value may be used in some operations, such as assignment and comparison for equality, without knowing its specific type. Other operations may require that knowledge, either by some external information, or by the use of a tagged union.

Because of the limitations of their use, untagged unions are generally only provided in untyped languages or in a type-unsafe way (as in C). They have the advantage over simple tagged unions of not requiring space to store a data type tag.

The name "union" stems from the type's formal definition. If a type is considered as the set of all values that that type can take on, a union type is simply the mathematical union of its constituting types, since it can take on any value any of its fields can. Also, because a mathematical union discards duplicates, if more than one field of the union can take on a single common value, it is impossible to tell from the value alone which field was last written.

However, one useful programming function of unions is to map smaller data elements to larger ones for easier manipulation. A data structure consisting, for example, of 4 bytes and a 32-bit integer, can form a union with an unsigned 64-bit integer, and thus be more readily accessed for purposes of comparison etc.

ALGOL 68 has tagged unions, and uses a case clause to distinguish and extract the constituent type at runtime. A union containing another union is treated as the set of all its constituent possibilities.

The syntax of the C/C++ union type and the notion of casts was derived from ALGOL 68, though in an untagged form.

In C and C++, untagged unions are expressed nearly exactly like structures (structs), except that each data member begins at the same location in memory. The data members, as in structures, need not be primitive values, and in fact may be structures or even other unions. C++ (since C++11) also allows for a data member to be any type that has a full-fledged constructor/destructor and/or copy constructor, or a non-trivial copy assignment operator. For example, it is possible to have the standard C++ string as a member of a union.

Like a structure, all of the members of a union are by default public. The keywords codice_1, codice_2, and codice_3 may be used inside a structure or a union in exactly the same way they are used inside a class for defining private, public, and protected member access.

The primary use of a union is allowing access to a common location by different data types, for example hardware input/output access, bitfield and word sharing, or type punning. Unions can also provide low-level polymorphism. However, there is no checking of types, so it is up to the programmer to be sure that the proper fields are accessed in different contexts. The relevant field of a union variable is typically determined by the state of other variables, possibly in an enclosing struct.

One common C programming idiom uses unions to perform what C++ calls a reinterpret_cast, by assigning to one field of a union and reading from another, as is done in code which depends on the raw representation of the values. A practical example is the method of computing square roots using the IEEE representation. This is not, however, a safe use of unions in general.

In C++, C11, and as a non-standard extension in many compilers, unions can also be anonymous. Their data members do not need to be referenced, are instead accessed directly. They have some restrictions as opposed to traditional unions: in C11, they must be a member of another structure or union, and in C++, they can not have methods or access specifiers.

Simply omitting the class-name portion of the syntax does not make a union an anonymous union. For a union to qualify as an anonymous union, the declaration must not declare an object.
Example:
In Unix-like compilers such as GCC, Clang, and IBM XL C for AIX, a attribute is available for union types. Types contained in the union can be converted transparently to the union type itself in a function call, provided that all types have the same size. It is mainly intended for function with multiple parameter interfaces, a use necessaciated by early Unix extensions and later re-standarisation.

In COBOL, union data items are defined in two ways. The first uses the RENAMES (66 level) keyword, which effectively maps a second alphanumeric data item on top of the same memory location as a preceding data item. In the example code below, data item PERSON-REC is defined as a group containing another group and a numeric data item. PERSON-DATA is defined as an alphanumeric data item that renames PERSON-REC, treating the data bytes continued within it as character data.
The second way to define a union type is by using the REDEFINES keyword. In the example code below, data item VERS-NUM is defined as a 2-byte binary integer containing a version number. A second data item VERS-BYTES is defined as a two-character alphanumeric variable. Since the second item is "redefined" over the first item, the two items share the same address in memory, and therefore share the same underlying data bytes. The first item interprets the two data bytes as a binary value, while the second item interprets the bytes as character values.

In PL/I then original term for a union was "cell", which is still accepted as a synonym for union by several compilers. The union declaration is similar to the structure definition, where elements at the same level within the union declaration occupy the same storage. Elements of the union can be any data type, including structures and array. Here 
vers_num and vers_bytes occupy the same storage locations.

An alternative to a union declaration is the DEFINED attribute, which allows alternative declarations of storage, however the data types of the base and defined variables must match.

In C and C++, the syntax is:
A structure can also be a member of a union, as the following example shows:

This example defines a variable codice_4 as a union (tagged as codice_5), which contains two members, a structure (tagged as codice_6) named codice_7 (which in turn contains three members), and an integer variable named codice_8.

Unions may occur within structures and arrays, and vice versa:

The number ival is referred to as symtab[i].u.ival and the first character of string sval by either of *symtab[i].u.sval or symtab[i].u.sval[0].

A union is a class all of whose data members are mapped to the same address within its object. The size of an object of a union is, therefore, the size of its largest data member.

In a structure, all of its data members are stored in contiguous memory locations. The size of an object of a struct is, therefore, the size of the sum of all its data members.

This gain in space efficiency, while valuable in certain circumstances, comes at a great cost of safety: the program logic must ensure that it only reads the field most recently written along all possible execution paths. The exception is when unions are used for type conversion: in this case, a certain field is written and the subsequently read field is deliberately different.

As an example illustrating this point, the declaration

defines a data object with two members occupying consecutive memory locations:

In contrast, the declaration

defines a data object with two members occupying the same memory location:

Structures are used where an "object" is composed of other objects, like a point object consisting of two integers, those being the x and y coordinates:

Unions are typically used in situation where an object can be one of many things but only one at a time, such as a type-less storage system:




</doc>
<doc id="944846" url="https://en.wikipedia.org/wiki?curid=944846" title="Volatile (computer programming)">
Volatile (computer programming)

In computer programming, particularly in the C, C++, C#, and Java programming languages, the volatile keyword indicates that a value may change between different accesses, even if it does not appear to be modified. This keyword prevents an optimizing compiler from optimizing away subsequent reads or writes and thus incorrectly reusing a stale value or omitting writes. Volatile values primarily arise in hardware access (memory-mapped I/O), where reading from or writing to memory is used to communicate with peripheral devices, and in threading, where a different thread may have modified a value.

Despite being a common keyword, the behavior of codice_1 differs significantly between programming languages, and is easily misunderstood. In C and C++, it is a type qualifier, like codice_2, and is a property of the "type". Furthermore, in C and C++ it does "not" work in most threading scenarios, and that use is discouraged. In Java and C#, it is a property of a variable and indicates that the object to which the variable is bound may mutate, and is specifically intended for threading. In the D programming language, there is a separate keyword codice_3 for the threading usage, but no codice_1 keyword exists.

In C, and consequently C++, the codice_1 keyword was intended to

Operations on codice_1 variables are not atomic, nor do they establish a proper happens-before relationship for threading. This is specified in the relevant standards (C, C++, POSIX, WIN32), and volatile variables are not threadsafe in the vast majority of current implementations. Thus, the usage of codice_1 keyword as a portable synchronization mechanism is discouraged by many C/C++ groups.

In this example, the code sets the value stored in codice_11 to codice_12. It then starts to poll that value repeatedly until it changes to codice_13:
static int foo;

void bar(void) {

An optimizing compiler will notice that no other code can possibly change the value stored in codice_11, and will assume that it will remain equal to codice_12 at all times. The compiler will therefore replace the function body with an infinite loop similar to this:
void bar_optimized(void) {

However, codice_11 might represent a location that can be changed by other elements of the computer system at any time, such as a hardware register of a device connected to the CPU. The above code would never detect such a change; without the codice_1 keyword, the compiler assumes that the current program is the only part of the system that could change the value (which is by far the most common situation).

To prevent the compiler from optimizing code as above, the codice_1 keyword is used:
static volatile int foo;

void bar (void) {

With this modification the loop condition will not be optimized away, and the system will detect the change when it occurs.

Generally, there are memory barrier operations available on platforms (which are exposed in C++11) that should be preferred instead of volatile as they allow the compiler to perform better optimization and more importantly they guarantee correct behaviour in multi-threaded scenarios; neither the C specification (before C11) nor the C++ specification (before C++11) specifies a multi-threaded memory model, so volatile may not behave deterministically across OSes/compilers/CPUs).

The following C programs, and accompanying assemblies, demonstrate how the codice_1 keyword affects the compiler's output. The compiler in this case was GCC.

While observing the assembly code, it is clearly visible that the code generated with codice_1 objects is more verbose, making it longer so the nature of codice_1 objects can be fulfilled. The codice_1 keyword prevents the compiler from performing optimization on code involving volatile objects, thus ensuring that each volatile variable assignment and read has a corresponding memory access. Without the codice_1 keyword, the compiler knows a variable does not need to be reread from memory at each use, because there should not be any writes to its memory location from any other thread or process.

According to the C++11 ISO Standard, the volatile keyword is only meant for use for hardware access; do not use it for inter-thread communication. For inter-thread communication, the standard library provides codice_24 templates.

The Java programming language also has the codice_1 keyword, but it is used for a somewhat different purpose. When applied to a field, the Java qualifier codice_1 provides the following guarantees:

Using codice_1 may be faster than a lock, but it will not work in some situations before Java 5. The range of situations in which volatile is effective was expanded in Java 5; in particular, double-checked locking now works correctly.

In C#, codice_1 ensures that code accessing the field is not subject to some thread-unsafe optimizations that may be performed by the compiler, the CLR, or by hardware. Only the following types can be marked volatile: all reference types, Single, Boolean, Byte, SByte, Int16, UInt16, Int32, UInt32, Char, and all enumerated types with an underlying type of Byte, SByte, Int16, UInt16, Int32, or UInt32. (This excludes value structs, as well as the primitive types Double, Int64, UInt64 and Decimal.)

Basically codice_1 is a shorthand for calling codice_30 and codice_31. These methods are special. In effect, these methods disable some optimizations usually performed by the C# compiler, the JIT compiler, and the CPU itself. The methods work as follows:

codice_35 is part of the Fortran 2003 standard, although earlier version supported it as an extension. Making all variables codice_1 in a function is also useful finding aliasing related bugs.

integer, volatile :: i ! When not defined volatile the following two lines of code are identical
write(*,*) i**2 ! Loads the variable i once from memory and multiplies that value times itself
write(*,*) i*i ! Loads the variable i twice from memory and multiplies those values
By always "drilling down" to memory of a VOLATILE, the Fortran compiler is precluded from reordering reads or writes to volatiles. This makes visible to other threads actions done in this thread, and vice versa. 

Use of VOLATILE reduces and can even prevent optimization.



</doc>
<doc id="37690170" url="https://en.wikipedia.org/wiki?curid=37690170" title="X Macro">
X Macro

X Macros are a technique for reliable maintenance of parallel lists, of code or data, whose corresponding items must appear in the same order. They are most useful where at least some of the lists cannot be composed by indexing, such as compile time.

Examples of such lists particularly include initialization of arrays, in concert with declarations of enumeration constants and function prototypes, generation of statement sequences and switch arms, etc.

Usage of X Macros dates back to the 1960s. It remains useful also in modern-day C and C++ programming languages, but remains relatively unknown.
An X macro application consists of two parts: 


The list is defined by a macro or header file (named, codice_1) which generates no code by itself, but merely consists of a sequence of invocations of a macro (classically named "codice_2") with the elements' data. Each expansion of codice_1 is preceded by a definition of codice_2 with the syntax for a list element. The invocation of codice_1 expands codice_2 for each element in the list.

This example defines a list of variables, and automatically generates their declarations and a function to print them out.

First the list definition. The list entries could contain multiple arguments, but here only the name of the variable is used.

Then we execute this list to generate the variable declarations:

In a similar way, we can generate a function that prints the variables and their names:

When run through the C preprocessor, the following code is generated. Line breaks and indentation have been added for ease of reading, even though they are not actually generated by the preprocessor:



</doc>
<doc id="44866380" url="https://en.wikipedia.org/wiki?curid=44866380" title="Flexible array member">
Flexible array member

Flexible array members were introduced in the C99 standard of the C programming language (in particular, in section §6.7.2.1, item 16, page 103). It is a member of a codice_1, which is an array without a given dimension. It must be the last member of such a codice_1 and it must be accompanied by at least one other member, as in the following example:

Typically, such structures serve as the header in a larger, variable memory allocation: 

The codice_3 operator on such a codice_1 gives the size of the structure as if the flexible array member was empty. This may include padding added to accommodate the flexible member; the compiler is also free to re-use such padding as part of the array itself . 

It is common to allocate codice_5 bytes. 

This is not wrong, however it may allocate a few more bytes than necessary: the compiler may be re-purposing some of the padding that is included in codice_6. Should this be a concern, macros are available to compute the minimum size while ensuring that the compiler's padding is not disrupted. 

As the array may start in the padding before the end of the structure, its content should always be accessed via indexing (codice_7) or codice_8, not codice_3. 

In previous standards of the C language, it was common to declare a zero-sized array member instead of a flexible array member. The GCC compiler explicitly accepts zero-sized arrays for such purposes.

C++ does not have flexible array members.


</doc>
<doc id="2214112" url="https://en.wikipedia.org/wiki?curid=2214112" title="C data types">
C data types

In the C programming language, data types constitute the semantics and characteristics of storage of data elements. They are expressed in the language syntax in form of declarations for memory locations or variables. Data types also determine the types of operations or methods of processing of data elements. 

The C language provides basic arithmetic types, such as integer and real number types, and syntax to build array and compound types. Include directives for specification files, commonly called "headers", for the C standard library syntax contain definitions of support types, that have additional properties, such as providing storage with an exact size, independent of the language implementation on specific hardware platforms.

The C language provides the four basic arithmetic type specifiers "char", "int", "float" and "double", and the modifiers "signed", "unsigned", "short", and "long". The following table lists the permissible combinations in specifying a large set of storage size-specific declarations.

The actual size of the integer types varies by implementation. The standard only requires size relations between the data types and minimum sizes for each data type:

The relation requirements are that the "long long" is not smaller than "long", which is not smaller than "int", which is not smaller than "short". As "char"'s size is always the minimum supported data type, no other data types (except bit-fields) can be smaller.

The minimum size for "char" is 8 bits, the minimum size for "short" and "int" is 16 bits, for "long" it is 32 bits and "long long" must contain at least 64 bits.

The type "int" should be the integer type that the target processor is most efficiently working with. This allows great flexibility: for example, all types can be 64-bit. However, several different integer width schemes (data models) are popular. Because the data model defines how different programs communicate, a uniform data model is used within a given operating system application interface.

In practice, "char" is usually eight bits in size and "short" is usually 16 bits in size (as are their unsigned counterparts). This holds true for platforms as diverse as 1990s SunOS 4 Unix, Microsoft MS-DOS, modern Linux, and Microchip MCC18 for embedded 8-bit PIC microcontrollers. POSIX requires "char" to be exactly eight bits in size.

Various rules in the C standard make "unsigned char" the basic type used for arrays suitable to store arbitrary non-bit-field objects: its lack of padding bits and trap representations, the definition of "object representation", and the possibility of aliasing.

The actual size and behavior of floating-point types also vary by implementation. The only guarantee is that "long double" is not smaller than "double", which is not smaller than "float". Usually, the 32-bit and 64-bit IEEE 754 binary floating-point formats are used, if supported by hardware.

The C99 standard includes new real floating-point types "float_t" and "double_t", defined in "<math.h>". They correspond to the types used for the intermediate results of floating-point expressions when FLT_EVAL_METHOD is 0, 1, or 2. These types may be wider than "long double".

C99 also added complex types: "float _Complex", "double _Complex", "long double _Complex".

C99 added a boolean (true/false) type "_Bool". Additionally, the file "<stdbool.h>" defines "bool" as a convenient alias for this type, and also provides macros for "true" and "false". "_Bool" functions similarly to a normal integral type, with one exception: any assignments to a "_Bool" that are not 0 (false) are stored as 1 (true). This behavior exists to avoid integer overflows in implicit narrowing conversions. For example, in the following code:

Variable "b" evaluates to false if "unsigned char" has a size of 8 bits. This is because the value 256 does not fit in the data type, which results in the lower 8 bits of it being used, resulting in a zero value. However, changing the type causes the previous code to behave normally:

The type "_Bool" also ensures true values always compare equal to each other:

The C language specification includes the typedefs "size_t" and "ptrdiff_t" to represent memory-related quantities. Their size is defined according to the target processor's arithmetic capabilities, not the memory capabilities, such as available address space. Both of these types are defined in file "stddef.h ("cstddef" header in C++).

codice_1 is an unsigned integer type used to represent the size of any object (including arrays) in the particular implementation. The operator sizeof yields a value of the type codice_1. The maximum size of codice_1 is provided via codice_4, a macro constant which is defined in the codice_5 header (codice_6 header in C++). codice_1 is guaranteed to be at least 16 bits wide. Additionally, POSIX includes codice_8, which is a signed integral type of the same width as codice_1.

codice_10 is a signed integral type used to represent the difference between pointers. It is only guaranteed to be valid against pointers of the same type; subtraction of pointers consisting of different types is implementation-defined.

Information about the actual properties, such as size, of the basic arithmetic types, is provided via macro constants in two headers: codice_11 header (codice_12 header in C++) defines macros for integer types and codice_13 header (codice_14 header in C++) defines macros for floating-point types. The actual values depend on the implementation.



The C99 standard includes definitions of several new integer types to enhance the portability of programs. The already available basic integer types were deemed insufficient, because their actual sizes are implementation defined and may vary across different systems. The new types are especially useful in embedded environments where hardware usually supports only several types and that support varies between different environments. All new types are defined in codice_73 header (codice_74 header in C++) and also are available at codice_5 header (codice_6 header in C++). The types can be grouped into the following categories:


The following table summarizes the types and the interface to acquire the implementation details ("n" refers to the number of bits):

The header file "inttypes.h" ("cinttypes" in C++) provides features that enhance the functionality of the types defined in <stdint.h> header. Included are macros that define printf format string and scanf format string specifiers corresponding to the <stdint.h> types and several functions for working with "intmax_t" and "uintmax_t" types. This header file was added in C99.


The macros are in the format codice_77. Here "{fmt}" defines the output formatting and is one of codice_78 (decimal), codice_79 (hexadecimal), codice_80 (octal), codice_81 (unsigned) and codice_82 (integer). "{type}" defines the type of the argument and is one of codice_83, codice_84, codice_85, codice_86, codice_87, where codice_83 corresponds to the number of bits in the argument.


The macros are in the format codice_89. Here "{fmt}" defines the output formatting and is one of codice_78 (decimal), codice_79 (hexadecimal), codice_80 (octal), codice_81 (unsigned) and codice_82 (integer). "{type}" defines the type of the argument and is one of codice_83, codice_84, codice_85, codice_86, codice_87, where codice_83 corresponds to the number of bits in the argument.


Similarly to the fixed-width integer types, ISO/IEC TS 18661 specifies floating-point types for IEEE 754 interchange and extended formats in binary and decimal:

Structures aggregate the storage of multiple data items, of potentially differing data types, into one memory block referenced by a single variable. The following example declares the data type "struct birthday" which contains the name and birthday of a person. The structure definition is followed by a declaration of the variable "John" that allocates the needed storage.

The memory layout of a structure is a language implementation issue for each platform, with a few restrictions. The memory address of the first member must be the same as the address of structure itself. Structures may be initialized or assigned to using compound literals. A function may directly return a structure, although this is often not efficient at run-time. Since C99, a structure may also end with a flexible array member.

A structure containing a pointer to a structure of its own type is commonly used to build linked data structures:
For every type "T", except void and function types, there exist the types "array of "N" elements of type "T"". An array is a collection of values, all of the same type, stored contiguously in memory. An array of size "N" is indexed by integers from "0" up to and including "N−1". Here is a brief example:

Arrays can be initialized with a compound initializer, but not assigned. Arrays are passed to functions by passing a pointer to the first element. Multidimensional arrays are defined as "array of array …", and all except the outermost dimension must have compile-time constant size:

Every data type "T" has a corresponding type "pointer to T". A pointer is a data type that contains the address of a storage location of a variable of a particular type. They are declared with the asterisk ("*") type declarator following the basic storage type and preceding the variable name. White space before or after the asterisk is optional.
Pointers may also be declared for pointer data types, thus creating multiple indirect pointers, such as and , including pointers to array types. The latter are less common than an array of pointers, and their syntax may be confusing:
The element "pc" requires ten blocks of memory of the size of "pointer to char" (usually 40 or 80 bytes on common platforms), but element "pa" is only one pointer (size 4 or 8 bytes), and the data it refers to is an array of ten bytes ().

A union type is a special construct that permits access to the same memory block by using a choice of differing type descriptions. For example, a union of data types may be declared to permit reading the same data either as an integer, a float, or any other user declared type:

The total size of "u" is the size of "u.s"—which happens to be the sum of the sizes of "u.s.u" and "u.s.d"—since "s" is larger than both "i" and "f". When assigning something to "u.i", some parts of "u.f" may be preserved if "u.i" is smaller than "u.f".

Reading from a union member is not the same as casting since the value of the member is not converted, but merely read.

Function pointers allow referencing functions with a particular signature. For example, to store the address of the standard function codice_105 in the variable codice_106:

Function pointers are invoked by name just like normal function calls. Function pointers are separate from pointers and void pointers.

The aforementioned types can be characterized further by type qualifiers, yielding a "qualified type". and C11, there are four type qualifiers in standard C: codice_107 (C89), codice_108 (C89), codice_109 (C99) and codice_110 (C11) the latter has a private name to avoid clashing with user names, but the more ordinary name codice_111 can be used if the codice_112 header is included. Of these, codice_107 is by far the best-known and most used, appearing in the standard library and encountered in any significant use of the C language, which must satisfy const-correctness. The other qualifiers are used for low-level programming, and while widely used there, are rarely used by typical programmers.



</doc>
<doc id="32170560" url="https://en.wikipedia.org/wiki?curid=32170560" title="Comparison of Object Pascal and C">
Comparison of Object Pascal and C

The computer programming languages C and Object Pascal have similar times of origin, influences, and purposes. Both were used to design (and compile) their own compilers early in their lifetimes.

Both C and Pascal are old programming languages: The original Pascal definition appeared in 1969 and a first compiler in 1970. The first version of C appeared in 1972. While C didn't change much in time, Pascal has evolved a lot and nowadays the vast majority of Pascal programming is done in modern Object Pascal, not in the old procedural Pascal. The old procedural Pascal today is essentially limited to microcontroller programming with tools such as mikroPascal, while Object Pascal is the main dialect and is used with tools such as Delphi, Lazarus (IDE) and Free Pascal.

What is documented here is the modern Object Pascal used in Free Pascal and Delphi. The C documented is C99, as standardized in 1999.

Syntactically, Object Pascal is much more Algol-like than C. English keywords are retained where C uses punctuation symbols — Pascal has codice_1, codice_2, and codice_3 where C uses codice_4, codice_5, and codice_6 for example. However, C is actually more Algol-like than Pascal regarding (simple) declarations, retaining the "type-name" "variable-name" syntax. For example, C can accept declarations at the start of any block, not just the outer block of a function.

Another, more subtle, difference is the role of the semicolon. In Pascal semicolons "separate" individual statements within a compound statement whereas they "terminate" the statement in C. They are also syntactically part of the statement itself in C (transforming an expression into a statement). This difference manifests itself primarily in two situations:


A superfluous semicolon can be put on the last line before end, thereby formally inserting an "empty statement".

In traditional C, there are only codice_9. Since C99, there are also codice_10.
In Object Pascal, there are codice_11, codice_12, and codice_13.

C and Pascal differ in their interpretation of upper and lower case. C is case sensitive while Pascal is not, thus codice_14 and codice_15 are distinct names in C but identical in Pascal. In both languages, identifiers consist of letters and digits, with the rule that the first character may not be a digit. In C, the underscore counts as a letter, so even _abc is a valid name. Names with a leading underscore are often used to differentiate special system identifiers in C. Pascal also accepts _ character as a part of identifiers, no difference with C.

Both C and Pascal use keywords (words reserved for use by the language itself). Examples are if, while, const, for and goto, which are keywords that happen to be common to both languages. In C, the basic built-in type names are also keywords (e.g. int, char) or combinations of keywords (e.g. unsigned char), while in Pascal the built-in type names are predefined normal identifiers.

Recent Object Pascal compilers however allow to escape keywords with &, this feature is mainly need when directly communication to foreign OOP systems like COM and COCOA that might use fields and methods based on Pascal keywords. C has no way to escape keywords.

In Pascal, procedure definitions start with keywords procedure or function and type definitions with type. In C, function definitions are determined by syntactical context while type definitions use the keyword codice_16. Both languages use a mix of keywords and punctuation for definitions of complex types; for instance, arrays are defined by the keyword array in Pascal and by punctuation in C, while enumerations are defined by the keyword codice_17 in C but by punctuation in Pascal.

In Pascal functions, begin and end delimit a block of statements (proper), while C functions use "{" and "}" to delimit a block of statements optionally preceded by declarations. C (prior to C99) strictly defines that any declarations must occur "before" the statements within a particular block but allows blocks to appear within blocks, which is a way to go around this. Pascal is strict that declarations must occur before statements, but allows "definitions" of types and functions - not only variable declarations - to be encapsulated by function definitions to any level of depth.

The grammars of both languages are of a similar size. From an implementation perspective the main difference between the two languages is that to parse C it is necessary to have access to a symbol table for types, while in Pascal there is only one such construct, assignment. For instance, the C fragment codice_18 could be a declaration of codice_19 to be an object whose type is pointer to codice_20, or a statement-expression that multiplies codice_20 and codice_19. The corresponding Pascal fragment codice_23 is unambiguous without a symbol table.

Pascal requires all variable and function declarations to specify their type explicitly. In traditional C, a type name may be omitted in most contexts and the default type codice_24 (which corresponds to codice_25 in Pascal) is then implicitly assumed (however, such defaults are considered bad practice in C and are often flagged by warnings).

C accommodates different sizes and signed and unsigned modes for integers by using modifiers such as codice_26, codice_27, codice_28, codice_29, etc. The exact meaning of the resulting integer type is machine-dependent, however, what "can" be guaranteed is that codice_30 is no shorter than codice_24 and codice_24 is no shorter than codice_33. However, in C standard, there are at least minimal sizes of types are specified which guarantees codice_34 to be a single byte and codice_24 to be at least two bytes.

In Pascal, a similar end is performed by declaring a "subrange" of integer (a compiler may then choose to allocate a smaller amount of storage for the declared variable):

This subrange feature is not supported by C.

A major, if subtle, difference between C and Pascal is how they promote integer operations. In Pascal, all operations on integers or integer subranges have the same effect, as if all of the operands were promoted to a full integer. In C, there are defined rules as to how to promote different types of integers, typically with the resultant type of an operation between two integers having a precision that is greater than or equal to the precisions of the operands. This can make machine code generated from C efficient on many processors. A highly optimizing Pascal compiler can reduce, but not eliminate, this effect under standard Pascal rules.

The (only) pre-Standard implementation of C as well as Small-C et al. allowed integer and pointer types to be relatively freely intermixed.

In C the character type is codice_34 which is a kind of integer that is no longer than codice_33, . Expressions such as codice_38 are therefore perfectly legal, as are declarations such as codice_39 and codice_40.

This integer nature of codice_34 (an eight-bit byte on most machines) is clearly illustrated by declarations such as
Whether the codice_34 type should be regarded as codice_28 or codice_29 by default is up to the implementation.

In Pascal, characters and integers are distinct types. The inbuilt compiler functions codice_45 and codice_46 can be used to typecast single characters to the corresponding integer value of the character set in use, and vice versa. e.g. on systems using the ASCII character set codice_47 and codice_48 is a TAB character.

In addition to codice_49 type, Object Pascal also has codice_50 to represent Unicode characters. In C, this is usually implemented as a macro or codice_16 with name codice_52, which is simply an alias for codice_24.

In Pascal, boolean is an enumerated type. The possible values of boolean are false and true, with ordinal value of false=0 and true=1, other values are undefined. For conversion to integer, ord is used:

There is no standard function for integer to boolean, however, the conversion is simple in practice:

C has binary valued relational operators (<, >, ==, !=, <=, >=) which may be regarded as "boolean" in the sense that they always give results which are either zero or one. As all tests (&&, ||, ?:, if, while, etc.) are performed by zero-checks, false is represented by zero, while true is represented by any other value.

To interface with COM, Object Pascal has added codice_54, codice_55 and codice_56 type whose size respects their prefix and that follow the C truth table.

Free Pascal has added proper Pascal boolean types with size suffix (codice_57) to interface with GLIB, that uses codice_58, a 32-bit boolean type with Pascal truth table.

The C programmer may sometimes use bitwise operators to perform boolean operations. Care needs to be taken because the semantics are different when operands make use of more than one bit to represent a value.

Pascal has another more abstract, high level method of dealing with bitwise data, sets. Sets allow the programmer to set, clear, intersect, and unite bitwise data values, rather than using direct bitwise operators. Example;

Pascal: 
C: 
Although bit operations on integers and operations on sets can be considered similar if the sets are implemented using bits, there is no direct parallel between their uses unless a non-standard conversion between integers and sets is possible.

Pascal could also do bitwise operations exactly the same way as C through the use of codice_1, codice_2, codice_61 and codice_62 operators. These operators normally work on booleans, but when the operands are integers, they behave as bitwise operators. This is made possible by boolean and integer being distinct incompatible types. Therefore, the C code above could be written in Pascal as:

In C, string remains as pointer to the first element of a null-terminated array of char, as it was in 1972. One still has to use library support from codice_63 to manipulate strings.

Object Pascal has many string types because when a new type is introduced, the old one is kept for backwards compatibility. This happened twice, once with Delphi 2 (introduction of ansistring) and Delphi 2009 (Unicodestring). Besides the main string types (short-, ansi-, wide-, unicodestring) and the corresponding character types (ansichar, widechar=unicodechar), all types derived from the character type have some string properties too (pointer to char, array of char, dynamic array of char, pointer to array of char etc.).

In Object Pascal, codice_64 is a compiler-managed type and is reference-counted (if it has to be), i.e., its storage management is handled by the compiler (or more accurately, by the runtime code inserted by the compiler in the executable). String concatenation is done with the codice_65 operator, and string comparison can be done with standard relational operators (case sensitive): codice_66.

Object Pascal also provides C-compatible strings under the type codice_67, with manipulation routines defined in the codice_68 unit. Moreover, Object Pascal provides a wide variety of string types:

For convenience, the plain codice_76 type is provided, which, depending on a compiler switch, could mean codice_69, codice_71 or codice_74. An additional convention used is that if a limit to the number of characters is given, it is a codice_69, otherwise it's the other.

codice_81 and codice_82 Strings can be freely intermixed when manipulating strings; the compiler will do silent conversion when required. Note that if the target string type is codice_69, silent truncation might happen due to the maximum length allowed.

Example:

In C, there is no real concept of an array; there is only a pseudo construct to declare storage for multiple variables of the same type. Arrays in C don't know their own length, and they're referenced through a pointer to the first element, which is why they're always 0 based. Example:

To get the array length, one has to calculate codice_84. Therefore, to count the length of an integer array, use: codice_85. It is a common mistake to calculate this in a function expecting an array as an argument. Despite its appearance, a function can only accept a pointer as an argument, not the real array. Therefore, inside the function, the array is treated as plain pointer. Example:

A common solution to the problem above is to always pass the array length as a function argument, and functions that expect an array argument should also provide a placeholder for its length.

Despite its treatment as a pointer, not all pointer style constructs could be used to array. For example, this code would compile fine but would cause access violation when executed:

Care should be taken when designing such code, and documentation should explicitly state this to prevent users from doing such a mistake.

Assignment between static arrays isn't allowed and one must use the codice_86 function and its variants to copy data between arrays.

In Pascal, an array is declared using the codice_87 keyword, specifying its lower and upper bound, and its base type. The latter is usually defined as a range type. For example:

Arrays know their upper and lower bounds (and implicitly their length), and the bounds are passed along when a function expects an array as argument. The functions codice_88, codice_89 and codice_90 retrieve the lower bound, upper bound and array length, respectively, in any context.

Without an explicit cast, arrays can't and won't be converted to pointers and it is a compile time error. This is a property of type-safe programming.

Assignment between static arrays is allowed. The assignment copies all items from the source array to the destination. It is mandatory that the upper and lower bounds are compatible between source and destination. If somehow they're different, then one can use codice_91 to partially copy data. However, since codice_91 is a low-level function, one must use it with care. It is the programmer's responsibility to ensure that data movement exceeds neither destination nor source boundary. Example:

C has no language support for declaring and using dynamic arrays. However, due to its pointer dereference syntax, a dynamic array could be implemented with memory management functions, usually those from codice_93. Example:

As can be seen, again the length isn't maintained automatically, and reallocation should use an additional variable to protect against not enough memory error.
Assignment between dynamic arrays follows pointer assignment rule.

Object Pascal provides language-level support for dynamic arrays. It's declared with lower and upper bound omitted. One then must call codice_94 function to allocate the storage. Dynamic arrays in Object Pascal are reference counted, so one doesn't have to worry about freeing the storage. Dynamic arrays are always zero-based. The three functions codice_88, codice_89 and codice_90 would still retrieve lower bound, upper bound and array length correctly. Example:
Assignment between dynamic arrays copies the reference of the source array to the destination. If a real copy is required, one can use the codice_98 function. Example:



</doc>
<doc id="1986891" url="https://en.wikipedia.org/wiki?curid=1986891" title="Comparison of Pascal and C">
Comparison of Pascal and C

The computer programming languages C and Pascal have similar times of origin, influences, and purposes. Both were used to design (and compile) their own compilers early in their lifetimes. The original Pascal definition appeared in 1969 and a first compiler in 1970. The first version of C appeared in 1972.

Both are descendants of the ALGOL language series. ALGOL introduced programming language support for structured programming, where programs are constructed of single entry and single exit constructs such as if, while, for and case. Pascal stems directly from ALGOL W, while it shared some new ideas with ALGOL 68. The C language is more indirectly related to ALGOL, originally through B, BCPL, and CPL, and later through ALGOL 68 (for example in case of codice_1 and codice_2) and also Pascal (for example in case of enumerations, codice_3, codice_4 and booleans). Some Pascal dialects also incorporated traits from C.

The languages documented here are the Pascal of Niklaus Wirth, as standardized as ISO 7185 in 1982, and the C of Brian Kernighan and Dennis Ritchie, as standardized in 1989. The reason is that these versions both represent the mature version of the language, and also because they are comparatively close in time. ANSI C and C99 (the later C standards) features, and features of later implementations of Pascal (Turbo Pascal, Free Pascal) are not included in the comparison, despite the improvements in robustness and functionality that they conferred.

Syntactically, Pascal is much more ALGOL-like than C. English keywords are retained where C uses punctuation symbols – Pascal has codice_5, codice_6, and codice_7 where C uses codice_8, codice_9, and codice_10 for example. However, C is more ALGOL-like than Pascal regarding (simple) declarations, retaining the "type-name" "variable-name" syntax. For example, C can accept declarations at the start of any block, not just the outer block of a function.

Another, more subtle, difference is the role of the semicolon. In Pascal, semicolons "separate" individual statements within a compound statement; instead in C, they "terminate" the statement. In C, they are also syntactically part of the statement (transforming an expression into a statement). This difference manifests mainly in two situations:


A superfluous semicolon can be put on the last line before end, thereby formally inserting an "empty statement".

In traditional C, there are only codice_14. This is only supported by certain Pascal dialects like MIDletPascal.

In traditional Pascal, there are codice_15 and codice_16.
Modern Pascal, like Object Pascal (Delphi, FPC), as well as modern C implementations allow C++ style comments codice_17

C and Pascal differ in their interpretation of upper and lower case. C is case sensitive while Pascal is not, thus codice_18 and codice_19 are distinct names in C but identical in Pascal. In both languages, identifiers consist of letters and digits, with the rule that the first character may not be a digit. In C, the underscore counts as a letter, so even _abc is a valid name. Names with a leading underscore are often used to differentiate special system identifiers in C.

Both C and Pascal use keywords (words reserved for use by the language). Examples are if, while, const, for and goto, which are keywords that happen to be common to both languages. In C, the basic built-in type names are also keywords (e.g., int, char) or combinations of keywords (e.g., unsigned char), while in Pascal the built-in type names are predefined normal identifiers.

In Pascal, procedure definitions start with keywords procedure or function and type definitions with type. In C, function definitions are determined by syntactical context while type definitions use the keyword codice_4. Both languages use a mix of keywords and punctuation for definitions of complex types; for instance, arrays are defined by the keyword array in Pascal and by punctuation in C, while enumerations are defined by the keyword codice_21 in C but by punctuation in Pascal.

In Pascal functions, begin and end delimit a block of statements (proper), while C functions use "{" and "}" to delimit a block of statements optionally preceded by declarations. C (before C99) strictly defines that any declarations must occur "before" the statements within a particular block but allows blocks to appear within blocks, which is a way to go around this. Pascal is strict that declarations must occur before statements, but allows "definitions" of types and functions - not only variable declarations - to be encapsulated by function definitions to any level of depth.

The grammars of both languages are of a similar size. From an implementation perspective the main difference between the two languages is that to parse C it is necessary to have access to a symbol table for types, while in Pascal there is only one such construct, assignment. For instance, the C fragment codice_22 could be a declaration of codice_23 to be an object whose type is pointer to codice_24, or a statement-expression that multiplies codice_24 and codice_23. In contrast, the corresponding Pascal fragment codice_27 is inherently unambiguous; correct parsing does not require a symbol table.

Pascal requires all variable and function declarations to specify their type explicitly. In traditional C, a type name may be omitted in most contexts and the default type codice_28 (which corresponds to codice_29 in Pascal) is then implicitly assumed (however, such defaults are considered bad practice in C and are often flagged by warnings).

C accommodates different sizes and signed and unsigned modes for integers by using modifiers such as codice_30, codice_31, codice_32, codice_33, etc. The exact meaning of the resulting integer type is machine-dependent, however, what "can" be guaranteed is that codice_34 is at least 16 bits, codice_35 is no shorter than codice_28 and codice_37 is no longer than codice_28.

In Pascal, a similar end is performed by declaring a "subrange" of integer (a compiler may then choose to allocate a smaller amount of storage for the declared variable):
type a = 1..100;
This subrange feature is not supported by C.

A major, if subtle, difference between C and Pascal is how they promote integer operations. In Pascal, the result of an operation is defined for all integer/subrange types, even if intermediate results do not fit into an integer. The result is undefined only if it does not fit into the integer/subrange on the left hand side of the assignment. This may imply an artificial restriction on the range of integer types, or may require slow execution to handle the intermediate results: However, the compiler may take advantage of restricted subranges to produce more efficient code.

In C, operands must first be promoted to the size of the required result: intermediate results are undefined if they do not fit into the range of the promoted operands. If range of the required result is greater than the range of operands, this normally produces slow inefficient code, even from a good optimising compiler. However, a C compiler is never required or expected to handle out of range intermediate results: it is the programmers responsibility to ensure that all intermediate results fit into the operand range.

The (only) pre-Standard implementation of C as well as Small-C et al. allowed integer and pointer types to be relatively freely intermixed.

In C the character type is codice_39 which is a kind of integer that is no longer than codice_37, . Expressions such as codice_41 are therefore perfectly legal, as are declarations such as codice_42 and codice_43.

This integer nature of codice_39 (one byte) is clearly illustrated by declarations such as

unsigned char uc = 255; /* common limit */
signed char sc = -128; /* common negative limit */
Whether the codice_39 type should be regarded as codice_32 or codice_33 by default is up to the implementation.

In Pascal, characters and integers are distinct types. The inbuilt compiler functions codice_48 and codice_49 can be used to typecast single characters to the corresponding integer value of the character set in use, and vice versa. e.g. on systems using the ASCII character set codice_50 and codice_51 is a TAB character.

In Pascal, boolean is an enumerated type. The possible values of boolean are false and true. For conversion to integer, ord is used:
i := ord(b);
There is no standard function for integer to boolean, however, the conversion is simple in practice:
b := i <> 0;
C has binary valued relational operators (<, >, ==, !=, <=, >=) which may be regarded as "boolean" in the sense that they always give results which are either zero or one. As all tests (&&, ||, ?:, if, while, etc.) are performed by zero-checks, false is represented by zero, while true is represented by any other value.

C allows using bitwise operators to perform boolean operations. Care must be taken because the semantics are different when operands make use of more than one bit to represent a value.

Pascal has another more abstract, high level method of dealing with bitwise data, sets. Sets allow the programmer to set, clear, intersect, and unite bitwise data values, rather than using direct bitwise operators (which are available in modern Pascal as well). Example;

Pascal: 

Status := Status + [StickyFlag];
Status := Status - [StickyFlag];
if (StickyFlag in Status) then ...
or

Pascal: 

Status := Status or StickyFlag;
Status := Status and not StickyFlag;
if StickyFlag and Status = StickyFlag then ...
C: 

Status |= StickyFlag;
Status &= ~StickyFlag;
if (Status & StickyFlag) { ...
Although bit operations on integers and operations on sets can be considered similar if the sets are implemented using bits, there is no direct parallel between their uses unless a non-standard conversion between integers and sets is possible.

During expression evaluation, and in "both languages", a boolean value may be internally stored as a single bit, a single byte, a full machine word, a position in the generated code, or as a condition code in a status register, depending on machine, compiler, and situation; these factors are usually more important than the language compiled.

C has a less strict model of floating point types than Pascal. In C, integers may be implicitly converted to floating point numbers, and vice versa (though possible precision loss may be flagged by warnings). In Pascal, integers may be implicitly converted to codice_52, but conversion of codice_52 to codice_29 (where information may be lost) must be done explicitly via the functions codice_55 and codice_56, which truncate or round off the fraction, respectively.

Both C and Pascal include enumeration types. A Pascal example:
type
var
A C example:
enum color {red, green, blue};
enum color a;
The behavior of the types in the two languages however is very different. In C, codice_57 becomes just a synonym for 0, codice_58 for 1, codice_59 for 2, and nothing prevents a value outside this range to be assigned to the variable codice_60. Furthermore, operations like codice_61 are strictly forbidden in Pascal; instead you would use codice_62. In C, enums can be freely converted to and from ints, but in Pascal, the function ord() must be used to convert from enumerated types to integers, in opposite conversion must be used typecast operation like codice_63 for codice_58 value return.

Both C and Pascal allow arrays of other complex types, including other arrays. However, there the similarity between the languages ends. C arrays are simply defined by a base type and the number of elements:

int a[SIZE];

and are always indexed from 0 up to SIZE-1 (i.e. modulo SIZE).

In Pascal, the range of indices is often specified by a subrange (as introduced under simple types above). The ten elements of
var a : array[0..9] of integer;
would be indexed by 0..9 (just as in C in this case). Array indices can be any ordinal data type, however, not just ranges:

type

var picture : array[1..640, 1..480] of RGB

var palette : array[byte, 0..2] of byte

Strings consisting of n (>1) characters are defined as packed arrays with range 1..n.

In C expressions, an identifier representing an array is treated as a constant pointer to the first element of the array, thus, given the declarations codice_65 and codice_66 the assignment codice_67 is valid and causes p and a to point to the same array. As the identifier codice_60 represents a "constant" address, codice_69 is not valid however.

While arrays in C are fixed, pointers to them are interchangeable. This flexibility allows C to manipulate any length array using the same code. It also leaves the programmer with the responsibility not to write outside the allocated array, as no checks are built in into the language.

In Pascal, arrays are a distinct type from pointers. This makes bounds checking for arrays possible from a compiler perspective. Practically all Pascal compilers support range checking as a compile "option". 
The ability to both have arrays that change length at runtime, and be able to check them under language control, is often termed "dynamic arrays". In Pascal the number of elements in each array type is determined at compile-time and cannot be changed during the execution of the program. Hence, it is not possible to define an array whose length depends in any way on program data.

C has the ability to initialize arrays of arbitrary length. The codice_70 operator can be used to obtain the size of a statically initialized array in C code. For instance in the following code, the terminating index for the loop automatically adjusts should the list of strings be changed.
static char *wordlist[] = {
static int listSize = (sizeof(wordlist)/sizeof(wordlist[0]));
int i;

for (i=0; i<listSize; i++)
for (i=listSize-1; i>=0; i--)
Original Pascal has neither array initialization (outside of the case of strings) nor a means of determining arbitrary array sizes at compile time.

One way of implementing the above example in Pascal, but without the automatic size adjustment, is:
const

type
var

procedure CreateList(var w: wordlist);
begin
end;

begin
end.
However, in modern Pascal you can use SetLength to get the same result:
var

begin
end.
In both languages, a string is a primitive array of characters.

In Pascal a string literal of length n is compatible with the type codice_71. In C a string generally has the type codice_72.

Pascal has no support for variable-length arrays, and so any set of routines to perform string operations is dependent on a particular string size. The now standardized Pascal "conformant array parameter" extension solves this to a great extent, and many or even most implementations of Pascal have support for strings native to the language.

C string literals are null-terminated; that is to say, a trailing null character as an end-of-string sentinel:

const char *p;
p = "the rain in Spain"; /* null-terminated */

Null-termination must be manually maintained for string variables stored in arrays (this is often partly handled by library routines).

C lacks built-in string or array assignment, so the string is not being transferred to p, but rather p is being made to point to the constant string in memory.

In Pascal, unlike C, the string's first character element is at index 1 and not 0 (leading it to be length-prefixed). This is because Pascal stores the length of the string at the 0th element of the character array. If this difference is not well understood it can lead to errors when porting or trying to interface object code generated by both languages.

FreeBSD developer Poul-Henning Kamp, writing in "ACM Queue", would later refer to the victory of null-terminated strings over length-prefixed strings as "the most expensive one-byte mistake" ever.

Both C and Pascal can declare "record" types. In C, they are termed "structures".

struct a {

type a = record 
end;
In Pascal, we can use the sentence "with <name_of_record> do" in order to use directly the fields of that record, like local variables, instead of write <name_of_record>.<name_of_field>. Here there is an example:

type 
var
r1 : r;
begin
with r1 do begin
end;
There is no equivalent feature to with in C.

In C, the exact bit length of a field can be specified:

struct a {

How much storage is used depends on traits (e.g., word-alignment) of the target system.

This feature is available in Pascal by using the subrange construct (3 bits gives a range from 0 to 7) in association with the keyword packed:

type a = packed record
end;

Both C and Pascal support records which can include different fields overlapping each other:

union a {

type a = record
end;

Both language processors are free to allocate only as much space for these records as needed to contain the largest type in the union/record.

The biggest difference between C and Pascal is that Pascal supports the explicit use of a "tagfield" for the language processor to determine if the valid component of the variant record is being accessed:

type a = record
end;

In this case, the tagfield q must be set to the right state to access the proper parts of the record.

In C, pointers can be made to point at most program entities, including objects or functions:
int a;
int *b;
int (*compare)(int c, int d);
int MyCompare(int c, int d);
b = &a;
compare = &MyCompare;
In C, since arrays and pointers have a close equivalence, the following are the same:
a = b[5];
a = *(b+5);
a = *(5+b);
a = 5[b];
Thus, pointers are often used in C as just another method to access arrays.

To create dynamic data, the library functions codice_73 and codice_74 are used to obtain and release dynamic blocks of data. Thus, dynamic memory allocation is not built into the language processor. This is especially valuable when C is being used in operating system kernels or embedded targets as these things are very platform (not just architecture) specific and would require changing the C compiler for each platform (or operating system) that it would be used on.

Pascal doesn't have the same kind of pointers as C, but it does have an indirection operator that covers the most common use of C pointers. Each pointer is bound to a single dynamic data item, and can only be moved by assignment:
type a = ^integer;
var b, c: a;
new(b);
c := b;
Pointers in Pascal are type safe; i.e. a pointer to one data type can only be assigned to a pointer of the same data type. Also pointers can never be assigned to non-pointer variables. Pointer arithmetic (a common source of programming errors in C, especially when combined with endianness issues and platform-independent type sizes) is not permitted in Pascal.
All of these restrictions reduce the possibility of pointer-related errors in Pascal compared to C, but do not prevent invalid pointer references in Pascal altogether. For example, a runtime error will occur if a pointer is referenced before it has been initialized or after it has been disposed.

The languages differ significantly when it comes to expression evaluation, but all-in-all they are comparable.

"Pascal"

"C"

Most operators serve several purposes in Pascal, for instance, the minus sign may be used for negation, subtraction, or set difference (depending on both type and syntactical context), the codice_94 operator may be used to compare numbers, strings, or sets, and so on. C uses dedicated operator symbols to a greater extent.

The two languages use different operators for assignment. Pascal, like ALGOL, uses the mathematical equality operator codice_95 for the equality test and the symbol codice_96 for assignment, whereas C, like B, uses the mathematical equality operator for assignment. In C (and B) the new codice_97 symbol was therefore introduced for the equality test.

It is a common mistake in C, due either to inexperience or to a simple typing error, to accidentally put assignment expressions in conditional statements such as codice_98. The code in braces will always execute because the assignment expression codice_99 has the value 10 which is non-zero and therefore considered "true" in C; this is in part because C (and ALGOL) allow multiple assignment in the form codice_100 which is not supported by Pascal. Also note that codice_60 now has the value codice_102, which may affect the following code. Recent C compilers try to detect these cases and warn the user, asking for a less ambiguous syntax like codice_103.

This kind of mistake cannot happen in Pascal, as assignments are not expressions and do not have a value: using the wrong operator will cause an unambiguous compilation error, and it's also less likely that anyone would mistake the codice_96 symbol for an equality test.

It is notable that ALGOL's conditional expression in the form codice_105 has an equivalent in C but not in Pascal.

When Niklaus Wirth designed Pascal, the desire was to limit the number of levels of precedence (fewer parse routines, after all). So the OR and exclusive OR operators are treated just like an Addop and processed at the level of a math expression. Similarly, the AND is treated like a Mulop and processed with Term. The precedence levels are
Notice that there is only ONE set of syntax rules, applying to both kinds of operators. According to this grammar, then, expressions like

are perfectly legal. And, in fact, they are, as far as the parser is concerned. Pascal doesn't allow the mixing of arithmetic and Boolean variables, and things like this are caught at the semantic level, when it comes time to generate code for them, rather than at the syntax level.

The authors of C took a diametrically opposite approach: they treat the operators as different, and in fact, in C there are no fewer than 15 levels. That's because C also has the operators '=', '+=' and its kin, '«', '»', '++', '--', etc. Although in C the arithmetic and Boolean operators are treated separately, the variables are not: a Boolean test can be made on any integer value.

In Pascal a "boolean" expression that relies on a particular evaluation ordering (possibly via side-effects in function calls) is, more or less, regarded as an error. The Pascal compiler has the freedom to use whatever ordering it may prefer and must always evaluate the whole expression even if the result can be determined by partial evaluation.

In C, dependence on "boolean" evaluation order is perfectly legal, and often systematically employed using the codice_8 and codice_9 operators together with operators such as codice_108, codice_109, the comma operator, etc. The codice_8 and codice_9 operators thereby function as combinations of logical operators and conditional "statements".

Short circuit expression evaluation has been commonly considered an advantage for C because of the "evaluation problem":

var i: integer;

This seemingly straightforward search is problematic in Pascal because the array access a[i] would be invalid for i equal to 11.

However, in superscalar processors there is a penalty for all jumps because they cause pipeline stalls, and programs created for them are more efficient if jumps are removed where possible. Pascal's ability to evaluate using a fixed formula without jumps can be an advantage with highly optimizing compilers, whereas C has effectively prevented this by requiring short circuit optimization.

Statements for building control structures are roughly analogous and relatively similar (at least the first three).

Pascal has:
C has:

Pascal, in its original form, did not have an equivalent to default, but an equivalent else clause is a common extension. Pascal programmers otherwise had to guard case-statements with an expression such as: .

C has the so-called early-out statements break and continue, and some Pascals have them as well.

Both C and Pascal have a goto statement. However, since Pascal has nested procedures/functions, jumps can be done from an inner procedure or function to the containing one; this was commonly used to implement error recovery. C has this ability via the ANSI C setjmp and longjmp. This is equivalent, but arguably less safe, since it stores program specific information like jump addresses and stack frames in a programmer accessible structure.

Pascal routines that return a value are called functions; routines that don't return a value are called procedures. All routines in C are called functions; C functions that do not return a value are declared with a return type of "void".

Pascal procedures are considered equivalent to C "void" functions, and Pascal functions are equivalent to C functions that return a value.

The following two declarations in C:

int f(int x, int y);
void k(int q);
are equivalent to the following declarations in Pascal:

function f(x, y: integer): integer;
procedure k(q: integer);
Pascal has two different types of parameters: pass-by-value, and pass-by-reference (VAR).

function f(var k: integer): integer;
x := f(t);
In C all parameters are passed by value but pass-by-reference can be simulated using pointers. The following segment is similar to the Pascal segment above:
int f(int *k); //function accepts a pointer as parameter
x = f(&t);
C allows for functions to accept a variable number of parameters, known as variadic functions.
int f(int a, ...);
f(1, 2, 3, 4, 5);
The function codice_112 uses a special set of functions that allow it to access each of the parameters in turn.

Additionally Pascal has I/O statements built into the language to handle variable amount of parameters, like codice_113. Pascal allows procedures and functions to be nested. This is convenient to allow variables that are local to a group of procedures, but not global. C lacks this feature and the localization of variables or functions can be done only for a compiling module wherein the variables or functions would have been declared static.

C allows functions to be indirectly invoked through a function pointer. In the following example, the statement codice_114 is equivalent to codice_115:

int (*cmpar)(const char *a, const char *b);
const char *s1 = "hello";
const char *s2 = "world";

cmpar = &strcmp;
b = (*cmpar)(s1, s2);
Pascal also allows functions and procedures to be passed as parameters to functions or procedures:
procedure ShowHex(i: integer);
end;

procedure ShowInt(i: integer);
end;

procedure Demo(procedure Show(i: integer));
var j: integer;
begin
end;
Early C had neither constant declarations nor type declarations, and the C language was originally defined as needing a "preprocessor"; a separate program, and pass, that handled constant, include and macro definitions, to keep memory usage down. Later, with ANSI C, it obtained constant and type definitions features and the preprocessor also became part of the language, leading to the syntax we see today.

Pascal constant and type defines are built in, but there were programmers using a preprocessor also with Pascal (sometimes the same one used with C), certainly not as common as with C. Although often pointed out as a "lack" in Pascal, technically C doesn't have program modularity nor macros built in either. It has a simple low level separate compilation facility, however (traditionally using the same generic linker used for assembly language), Pascal does not.

In C, the programmer may inspect the byte-level representation of any object by pointing a codice_39 pointer to it:

int a;
char *p = (char *)(&a);
char c = *p; // first byte of a
It may be possible to do something similar in Pascal using an undiscriminated variant record:

var a: integer;
begin
end;

Although casting is possible on most Pascal compilers and interpreters, even in the code above a2c.a and a2c.b aren't required by any Pascal standardizations to share the same address space. Niklaus Wirth, the designer of Pascal, has written about the problematic nature of attempting type escapes using this approach:

"Most implementors of Pascal decided that this checking would be too expensive, enlarging code and deteriorating program efficiency. As a consequence, the variant record became a favourite feature to breach the type system by all programmers in love with tricks, which usually turn into pitfalls and calamities".

Several languages now specifically exclude such type escapes, for example Java, C# and Wirth's own Oberon.

In C files do not exist as a built-in type (they are defined in a system header) and all I/O takes place via library calls. Pascal has file handling built into the language.

The typical statements used to perform I/O in each language are:
printf("The sum is: %d\n", x);
writeln('The sum is: ', x);
The main difference is that C uses a "format string" that is interpreted to find the arguments to the printf function and convert them, whereas Pascal performs that under the control of the language processor. The Pascal method is arguably faster, because no interpretation takes place, but the C method is highly extensible.

Some popular Pascal implementations have incorporated virtually all C constructs into Pascal. Examples include type casts, being able to obtain the address of any variable, local or global, and different types of integers with special promotion properties.

However, the incorporation of C's lenient attitude towards types and type conversions can result in a Pascal that loses some or all of its type security. For example, Java and C# were created in part to address some of the perceived type security issues of C, and have "managed" pointers that cannot be used to create invalid references. In its original form (as described by Niklaus Wirth), Pascal qualifies as a managed pointer language, some 30 years before either Java or C#. However, a Pascal amalgamated with C would lose that protection by definition. In general, the lower dependence on pointers for basic tasks makes it safer than C in practice.

The Extended Pascal standard extends Pascal to support many things C supports, which the original standard Pascal did not, in a type safer manner. For example, schema types support (besides other uses) variable-length arrays while keeping the type-safety of mandatory carrying the array dimension with the array, allowing automatic run-time checks for out-of-range indices also for dynamically sized arrays.




</doc>
<doc id="33397133" url="https://en.wikipedia.org/wiki?curid=33397133" title="GNU cflow">
GNU cflow

GNU cflow is a flow graph generator that is part of the GNU Project. It reads a collection of C source files and generates a C flow graph of external references. It uses only sources and doesn't need to run the program.

It was initially an implementation of the UNIX utility cflow.

cflow is a Unix command generating a C-language flowgraph.

Besides GNU, there are other implementations of "cflow", like the one for Tru64 Unix.



</doc>
<doc id="992538" url="https://en.wikipedia.org/wiki?curid=992538" title="Struct (C programming language)">
Struct (C programming language)

A struct in the C programming language (and many derivatives) is a composite data type (or record) declaration that defines a physically grouped list of variables under one name in a block of memory, allowing the different variables to be accessed via a single pointer or by the struct declared name which returns the same address. The struct data type can contain other data types so is used for mixed-data-type records such as a hard-drive directory entry (file length, name, extension, physical address, etc.), or other mixed-type records (name, address, telephone, balance, etc.).

The C struct directly references a "contiguous block" of physical memory, usually delimited (sized) by word-length boundaries. It corresponds to the similarly named feature available in some assemblers for Intel processors. Language implementations that could utilize half-word or byte boundaries (giving denser packing, using less memory) were considered advanced in the mid-1980s. Being a block of contiguous memory, each field within a struct is located at a certain fixed offset from the start.

Because the contents of a struct are stored in contiguous memory, the sizeof operator must be used to get the number of bytes needed to store a particular type of struct, just as it can be used for primitives. The alignment of particular fields in the struct (with respect to word boundaries) is implementation-specific and may include padding, although modern compilers typically support the codice_1 directive, which changes the size in bytes used for alignment.

In the C++ language, a struct is identical to a C++ class but has a different default visibility: class members are private by default, whereas struct members are public by default.

The struct data type in C was derived from the ALGOL 68 struct data type.

Like its C counterpart, the struct data type in C# ("Structure" in Visual Basic .NET) is similar to a class. The biggest difference between a struct and a class in these languages is that when a struct is passed as an argument to a function, any modifications to the struct in that function will not be reflected in the original variable (unless pass-by-reference is used).

This differs from C++, where classes or structs can be statically allocated or dynamically allocated either on the stack (similar to C#) or on the heap, with an explicit pointer. In C++, the only difference between a struct and a class is that the members and base classes of a struct are public by default. (A class defined with the codice_2 keyword has private members and base classes by default.)

Golang also uses structs.

The general syntax for a struct declaration in C is:

Here codice_3 is optional in some contexts.

Such a codice_4 declaration may also appear in the context of a typedef declaration of a type alias or the declaration or definition of a variable:

There are three ways to initialize a structure. For the codice_4 type

"C89-style initializers" are used when contiguous members may be given.

For non contiguous or out of order members list, "designated initializer" style may be used

If an initializer is given or if the object is statically allocated, omitted elements are initialized to 0.

A third way of initializing a structure is to copy the value of an existing object of the same type

A struct may be assigned to another struct. A compiler might use codice_6 to perform such an assignment.

Pointers can be used to refer to a codice_4 by its address. This is useful for passing structs to a function. The pointer can be dereferenced using the codice_8 operator. The codice_9 operator dereferences the pointer to struct (left operand) and then accesses the value of a member of the struct (right operand).

Typedefs can be used as shortcuts, for example:



</doc>
<doc id="51190369" url="https://en.wikipedia.org/wiki?curid=51190369" title="Strsafe.h">
Strsafe.h

strsafe.h is a non-standard C header file provided with the Windows SDK starting with Windows XP Service Pack 2 that provides safer buffer handling than that which is provided by the standard C string functions, which are widely known to have security issues involving buffer overruns when not used correctly.

The functions included in strsafe.h replace standard C string handling and I/O functions including codice_1, codice_2, codice_3 and codice_4. The strsafe functions require the length of the string in either characters or bytes as a parameter and if an operation would exceed the length of the destination buffer, the operation fails and the string is still terminated with a null in its final valid index so that using it in other library functions will not result in undefined behavior. Independent security researchers have noted that security issues are still possible with the functions from strsafe.h if they are not passed the correct buffer length. The use of this library is recommended by the United States Department of Homeland Security.



</doc>
<doc id="8218" url="https://en.wikipedia.org/wiki?curid=8218" title="Dennis Ritchie">
Dennis Ritchie

Dennis MacAlistair Ritchie (September 9, 1941 – October 12, 2011) was an American computer scientist. He created the C programming language and, with long-time colleague Ken Thompson, the Unix operating system and B programming language. Ritchie and Thompson were awarded the Turing Award from the ACM in 1983, the Hamming Medal from the IEEE in 1990 and the National Medal of Technology from President Bill Clinton in 1999. Ritchie was the head of Lucent Technologies System Software Research Department when he retired in 2007. He was the "R" in K&R C, and commonly known by his username dmr.

Dennis Ritchie was born in Bronxville, New York. His father was Alistair E. Ritchie, a longtime Bell Labs scientist and co-author of "The Design of Switching Circuits" on switching circuit theory. As a child, Dennis moved with his family to Summit, New Jersey, where he graduated from Summit High School. He graduated from Harvard University with degrees in physics and applied mathematics.

In 1967, Ritchie began working at the Bell Labs Computing Sciences Research Center, and in 1968, he defended his PhD thesis on "Program Structure and Computational Complexity" at Harvard under the supervision of Patrick C. Fischer. However, Ritchie never officially received his PhD degree. 

During the 1960s, Ritchie and Ken Thompson worked on the Multics operating system at Bell Labs. Thompson then found an old PDP-7 machine and developed his own application programs and operating system from scratch, aided by Ritchie and others. In 1970, Brian Kernighan suggested the name "Unix", a pun on the name "Multics". To supplement assembly language with a system-level programming language, Thompson created B. Later, B was replaced by C, created by Ritchie, who continued to contribute to the development of Unix and C for many years.

During the 1970s, Ritchie collaborated with James Reeds and Robert Morris on a ciphertext-only attack on the M-209 US cipher machine that could solve messages of at least 2000–2500 letters. Ritchie relates that, after discussions with the NSA, the authors decided not to publish it, as they were told that the principle was applicable to machines still in use by foreign governments.

Ritchie was also involved with the development of the Plan 9 and Inferno operating systems, and the programming language Limbo.

As part of an AT&T restructuring in the mid-1990s, Ritchie was transferred to Lucent Technologies, where he retired in 2007 as head of System Software Research Department.

Ritchie is best known as the creator of the C programming language, a key developer of the Unix operating system, and co-author of the book "The C Programming Language"; he was the 'R' in "K&R" (a common reference to the book's authors Kernighan and Ritchie). Ritchie worked together with Ken Thompson, who is credited with writing the original version of Unix; one of Ritchie's most important contributions to Unix was its porting to different machines and platforms. They were so influential on Research Unix that Doug McIlroy later wrote, "The names of Ritchie and Thompson may safely be assumed to be attached to almost everything not otherwise attributed."

Ritchie liked to emphasize that he was just one member of a group. He suggested that many of the improvements he introduced simply "looked like a good thing to do," and that anyone else in the same place at the same time might have done the same thing.

Nowadays, the C language is widely used in application, operating system, and embedded system development, and its influence is seen in most modern programming languages. Unix has also been influential, establishing computing concepts and principles that have been widely adopted.

In an interview from 1999, Ritchie clarified that he saw Linux and BSD operating systems as a continuation of the basis of the Unix operating system, and as derivatives of Unix:

In the same interview, he stated that he viewed both Unix and Linux as "the continuation of ideas that were started by Ken and me and many others, many years ago."

In 1983, Ritchie and Thompson received the Turing Award "for their development of generic operating systems theory and specifically for the implementation of the UNIX operating system". Ritchie's Turing Award lecture was titled "Reflections on Software Research". In 1990, both Ritchie and Thompson received the IEEE Richard W. Hamming Medal from the Institute of Electrical and Electronics Engineers (IEEE), "for the origination of the UNIX operating system and the C programming language".

In 1997, both Ritchie and Thompson were made Fellows of the Computer History Museum, "for co-creation of the UNIX operating system, and for development of the C programming language."

On April 21, 1999, Thompson and Ritchie jointly received the National Medal of Technology of 1998 from President Bill Clinton for co-inventing the UNIX operating system and the C programming language which, according to the citation for the medal, "led to enormous advances in computer hardware, software, and networking systems and stimulated growth of an entire industry, thereby enhancing American leadership in the Information Age".

In 2005, the Industrial Research Institute awarded Ritchie its Achievement Award in recognition of his contribution to science and technology, and to society generally, with his development of the Unix operating system.

In 2011, Ritchie, along with Thompson, was awarded the Japan Prize for Information and Communications for his work in the development of the Unix operating system.

Ritchie was found dead on October 12, 2011, at the age of 70 at his home in Berkeley Heights, New Jersey, where he lived alone. First news of his death came from his former colleague, Rob Pike. The cause and exact time of death have not been disclosed. He had been in frail health for several years following treatment for prostate cancer and heart disease. News of Ritchie's death was largely overshadowed by the media coverage of the death of Apple co-founder Steve Jobs, which occurred the week before.

Following Ritchie's death, computer historian Paul E. Ceruzzi stated:

In an interview shortly after Ritchie's death, long time colleague Brian Kernighan said Ritchie never expected C to be so significant.
Kernighan told "The New York Times" "The tools that Dennis built—and their direct descendants—run pretty much everything today.” Kernighan reminded readers of how important a role C and Unix had played in the development of later high-profile projects, such as the iPhone. Other testimonials to his influence followed.

Reflecting upon his death, a commentator compared the relative importance of Steve Jobs and Ritchie, concluding that "[Ritchie's] work played a key role in spawning the technological revolution of the last forty years—including technology on which Apple went on to build its fortune." Another commentator said, "Ritchie, on the other hand, invented and co-invented two key software technologies which make up the DNA of effectively every single computer software product we use directly or even indirectly in the modern age. It sounds like a wild claim, but it really is true." Another said, "many in computer science and related fields knew of Ritchie’s importance to the growth and development of, well, everything to do with computing..."

The Fedora 16 Linux distribution, which was released about a month after he died, was dedicated to his memory. FreeBSD 9.0, released January 12, 2012 was also dedicated in his memory.

Asteroid 294727 Dennisritchie, discovered by astronomers Tom Glinos and David H. Levy in 2008, was named in his memory. The official was published by the Minor Planet Center on 7 February 2012 ().





</doc>
<doc id="54502205" url="https://en.wikipedia.org/wiki?curid=54502205" title="Register (keyword)">
Register (keyword)

In the C programming language, codice_1 is a reserved word (or keyword), type modifier, storage class, and hint. The codice_1 keyword was deprecated in C++, until it became reserved and unused in C++17. It "suggests" that the compiler store a declared variable in a CPU register (or some other faster location) instead of in RAM. If possible, depending of type of CPU and complexity of the program code, it will optimize access to that variable, and will hence improve the execution time of a program. In C (but not C++ where the keyword is essentially ignored) the location of a variable declared with codice_1 cannot be accessed, but the codice_4 operator can be applied. Aside from this limitation, codice_1 is essentially meaningless in modern compilers due to optimization which will place variables in a register if appropriate regardless of whether the hint is given. For programming of embedded systems codice_1 may still be significant; for example the Microchip MPLAB XC32 compiler allows the programmer to specify a particular register with the keyword, however this is discouraged in favor of the compiler's optimizations. When used, codice_1 is typically for loop counters, or possibly for other very frequently used variables in the code.



</doc>
<doc id="607497" url="https://en.wikipedia.org/wiki?curid=607497" title="C99">
C99

C99 (previously known as C9X) is an informal name for ISO/IEC 9899:1999, a past version of the C programming language standard. It extends the previous version (C90) with new features for the language and the standard library, and helps implementations make better use of available computer hardware, such as IEEE 754-1985 floating-point arithmetic, and compiler technology. The C11 version of the C programming language standard, published in 2011, replaces C99.

After ANSI produced the official standard for the C programming language in 1989, which became an international standard in 1990, the C language specification remained relatively static for some time, while C++ continued to evolve, largely during its own standardization effort. Normative Amendment 1 created a new standard for C in 1995, but only to correct some details of the 1989 standard and to add more extensive support for international character sets. The standard underwent further revision in the late 1990s, leading to the publication of ISO/IEC 9899:1999 in 1999, which was adopted as an ANSI standard in May 2000. The language defined by that version of the standard is commonly referred to as "C99". The international C standard is maintained by the working group ISO/IEC JTC1/SC22/WG14.

C99 is, for the most part, backward compatible with C89, but it is stricter in some ways.

In particular, a declaration that lacks a type specifier no longer has codice_1 implicitly assumed. The C standards committee decided that it was of more value for compilers to diagnose inadvertent omission of the type specifier than to silently process legacy code that relied on implicit codice_1. In practice, compilers are likely to display a warning, then assume codice_1 and continue translating the program.

C99 introduced several new features, many of which had already been implemented as extensions in several compilers:


Parts of the C99 standard are included in the current version of the C++ standard, including integer types, headers, and library functions. Variable-length arrays are not among these included parts because C++'s Standard Template Library already includes similar functionality.

A major feature of C99 is its numerics support, and in particular its support for access to the features of IEEE 754-1985 (also known as IEC 60559) floating-point hardware present in the vast majority of modern processors (defined in "Annex F IEC 60559 floating-point arithmetic"). Platforms without IEEE 754 hardware can also implement it in software.

On platforms with IEEE 754 floating point:


FLT_EVAL_METHOD == 2 tends to limit the risk of rounding errors affecting numerically unstable expressions (see IEEE 754 design rationale) and is the designed default method for x87 hardware, but yields unintuitive behavior for the unwary user; FLT_EVAL_METHOD == 1 was the default evaluation method originally used in K&R C, which promoted all floats to double in expressions; and FLT_EVAL_METHOD == 0 is also commonly used and specifies a strict "evaluate to type" of the operands. (For gcc, FLT_EVAL_METHOD == 2 is the default on 32 bit x86, and FLT_EVAL_METHOD == 0 is the default on 64 bit x86-64, but FLT_EVAL_METHOD == 2 can be specified on x86-64 with option -mfpmath=387.) Before C99, compilers could round intermediate results inconsistently, especially when using x87 floating-point hardware, leading to compiler-specific behaviour; such inconsistencies are not permitted in compilers conforming to C99 (annex F).

The following annotated example C99 code for computing a continued fraction function demonstrates the main features:

Footnotes:

A standard macro codice_24 is defined with value codice_25 to indicate that C99 support is available. As with the codice_26 macro for C90, codice_24 can be used to write code that will compile differently for C90 and C99 compilers, as in this example that ensures that codice_28 is available in either case (by replacing it with codice_19 in C90 to avoid linker errors).

Most C compilers provide support for at least some of the features introduced in C99.

Historically, Microsoft has been slow to implement new C features in their Visual C++ tools, instead focusing mainly on supporting developments in the C++ standards. However, with the introduction of Visual C++ 2013 Microsoft implemented a limited subset of C99, which was expanded in Visual C++ 2015.

Since ratification of the 1999 C standard, the standards working group prepared technical reports specifying improved support for embedded processing, additional character data types (Unicode support), and library functions with improved bounds checking. Work continues on technical reports addressing decimal floating point, additional mathematical special functions, and additional dynamic memory allocation functions. The C and C++ standards committees have been collaborating on specifications for threaded programming.

The next revision of the C standard, C11, was ratified in 2011. The C standards committee adopted guidelines that limited the adoption of new features that have not been tested by existing implementations. Much effort went into developing a memory model, in order to clarify sequence points and to support threaded programming.





</doc>
<doc id="58106740" url="https://en.wikipedia.org/wiki?curid=58106740" title="C18 (C standard revision)">
C18 (C standard revision)

C18 is the informal name for ISO/IEC 9899:2018, the most recent standard for the C programming language, published in June 2018. It replaced C11 (standard ISO/IEC 9899:2011). It has been informally named as C17 too.

C18 will be superseded by C2x.

C18 addressed defects in C11 without introducing new language features.

The codice_1 macro is increased to the value codice_2.

List of compilers supporting C18:




</doc>
<doc id="55189988" url="https://en.wikipedia.org/wiki?curid=55189988" title="CERT C Coding Standard">
CERT C Coding Standard

The SEI CERT C Coding Standard is a software coding standard for the C programming language, developed by the CERT Coordination Center to improve the safety, reliability, and security of software systems.

Guidelines in the CERT C Secure Coding Standard are cross-referenced with several other standards including Common Weakness Enumeration (CWE) entries and MISRA.




</doc>
<doc id="6021" url="https://en.wikipedia.org/wiki?curid=6021" title="C (programming language)">
C (programming language)

C (, as in the letter "c") is a general-purpose, procedural computer programming language supporting structured programming, lexical variable scope, and recursion, while a static type system prevents unintended operations. By design, C provides constructs that map efficiently to typical machine instructions and has found lasting use in applications previously coded in assembly language. Such applications include operating systems and various application software for computers, from supercomputers to embedded systems.

C was originally developed at Bell Labs by Dennis Ritchie between 1972 and 1973 to make utilities running on Unix. Later, it was applied to re-implementing the kernel of the Unix operating system. During the 1980s, C gradually gained popularity. It has become one of the most widely used programming languages, with C compilers from various vendors available for the majority of existing computer architectures and operating systems. C has been standardized by the ANSI since 1989 (see ANSI C) and by the International Organization for Standardization.

C is an imperative procedural language. It was designed to be compiled using a relatively straightforward compiler to provide low-level access to memory and language constructs that map efficiently to machine instructions, all with minimal runtime support. Despite its low-level capabilities, the language was designed to encourage cross-platform programming. A standards-compliant C program written with portability in mind can be compiled for a wide variety of computer platforms and operating systems with few changes to its source code. The language is available on various platforms, from embedded microcontrollers to supercomputers.

Like most procedural languages in the ALGOL tradition, C has facilities for structured programming and allows lexical variable scope and recursion. Its static type system prevents unintended operations. In C, all executable code is contained within subroutines (also called "functions", though not strictly in the sense of functional programming). Function parameters are always passed by value. Pass-by-reference is simulated in C by explicitly passing pointer values. C program source text is free-format, using the semicolon as a statement terminator and curly braces for grouping blocks of statements.

The C language also exhibits the following characteristics:


While C does not include certain features found in other languages (such as object orientation and garbage collection), these can be implemented or emulated, often through the use of external libraries (e.g., the GLib Object System or the Boehm garbage collector).

Many later languages have borrowed directly or indirectly from C, including C++, C#, Unix's C shell, D, Go, Java, JavaScript, Limbo, LPC, Objective-C, Perl, PHP, Python, Rust, Swift, Verilog and SystemVerilog (hardware description languages). These languages have drawn many of their control structures and other basic features from C. Most of them (Python being a dramatic exception) also express highly similar syntax to C, and they tend to combine the recognizable expression and statement syntax of C with underlying type systems, data models, and semantics that can be radically different.

The origin of C is closely tied to the development of the Unix operating system, originally implemented in assembly language on a PDP-7 by Dennis Ritchie and Ken Thompson, incorporating several ideas from colleagues. Eventually, they decided to port the operating system to a PDP-11. The original PDP-11 version of Unix was also developed in assembly language.

Thompson desired a programming language to make utilities for the new platform. At first, he tried to make a Fortran compiler, but soon gave up the idea. Instead, he created a cut-down version of the recently developed BCPL systems programming language. The official description of BCPL was not available at the time, and Thompson modified the syntax to be less wordy, producing the similar but somewhat simpler B. However, few utilities were ultimately written in B because it was too slow, and B could not take advantage of PDP-11 features such as byte addressability.

In 1972, Ritchie started to improve B, which resulted in creating a new language C. The C compiler and some utilities made with it were included in Version 2 Unix.

At Version 4 Unix released in November 1973, the Unix kernel was extensively re-implemented by C. By this time, the C language had acquired some powerful features such as codice_12 types.

Unix was one of the first operating system kernels implemented in a language other than assembly. Earlier instances include the Multics system (which was written in PL/I) and Master Control Program (MCP) for the Burroughs B5000 (which was written in ALGOL) in 1961. In around 1977, Ritchie and Stephen C. Johnson made further changes to the language to facilitate portability of the Unix operating system. Johnson's Portable C Compiler served as the basis for several implementations of C on new platforms.

In 1978, Brian Kernighan and Dennis Ritchie published the first edition of "The C Programming Language". This book, known to C programmers as "K&R", served for many years as an informal specification of the language. The version of C that it describes is commonly referred to as "K&R C". The second edition of the book covers the later ANSI C standard, described below.

"K&R" introduced several language features:


Even after the publication of the 1989 ANSI standard, for many years K&R C was still considered the "lowest common denominator" to which C programmers restricted themselves when maximum portability was desired, since many older compilers were still in use, and because carefully written K&R C code can be legal Standard C as well.

In early versions of C, only functions that return types other than codice_30 must be declared if used before the function definition; functions used without prior declaration were presumed to return type codice_30.

For example:

The codice_30 type specifiers which are commented out could be omitted in K&R C, but are required in later standards.

Since K&R function declarations did not include any information about function arguments, function parameter type checks were not performed, although some compilers would issue a warning message if a local function was called with the wrong number of arguments, or if multiple calls to an external function used different numbers or types of arguments. Separate tools such as Unix's lint utility were developed that (among other things) could check for consistency of function use across multiple source files.

In the years following the publication of K&R C, several features were added to the language, supported by compilers from AT&T (in particular PCC) and some other vendors. These included:


The large number of extensions and lack of agreement on a standard library, together with the language popularity and the fact that not even the Unix compilers precisely implemented the K&R specification, led to the necessity of standardization.

During the late 1970s and 1980s, versions of C were implemented for a wide variety of mainframe computers, minicomputers, and microcomputers, including the IBM PC, as its popularity began to increase significantly.

In 1983, the American National Standards Institute (ANSI) formed a committee, X3J11, to establish a standard specification of C. X3J11 based the C standard on the Unix implementation; however, the non-portable portion of the Unix C library was handed off to the IEEE working group 1003 to become the basis for the 1988 POSIX standard. In 1989, the C standard was ratified as ANSI X3.159-1989 "Programming Language C". This version of the language is often referred to as ANSI C, Standard C, or sometimes C89.

In 1990, the ANSI C standard (with formatting changes) was adopted by the International Organization for Standardization (ISO) as ISO/IEC 9899:1990, which is sometimes called C90. Therefore, the terms "C89" and "C90" refer to the same programming language.

ANSI, like other national standards bodies, no longer develops the C standard independently, but defers to the international C standard, maintained by the working group ISO/IEC JTC1/SC22/WG14. National adoption of an update to the international standard typically occurs within a year of ISO publication.

One of the aims of the C standardization process was to produce a superset of K&R C, incorporating many of the subsequently introduced unofficial features. The standards committee also included several additional features such as function prototypes (borrowed from C++), codice_15 pointers, support for international character sets and locales, and preprocessor enhancements. Although the syntax for parameter declarations was augmented to include the style used in C++, the K&R interface continued to be permitted, for compatibility with existing source code.

C89 is supported by current C compilers, and most modern C code is based on it. Any program written only in Standard C and without any hardware-dependent assumptions will run correctly on any platform with a conforming C implementation, within its resource limits. Without such precautions, programs may compile only on a certain platform or with a particular compiler, due, for example, to the use of non-standard libraries, such as GUI libraries, or to a reliance on compiler- or platform-specific attributes such as the exact size of data types and byte endianness.

In cases where code must be compilable by either standard-conforming or K&R C-based compilers, the codice_38 macro can be used to split the code into Standard and K&R sections to prevent the use on a K&R C-based compiler of features available only in Standard C.

After the ANSI/ISO standardization process, the C language specification remained relatively static for several years. In 1995, Normative Amendment 1 to the 1990 C standard (ISO/IEC 9899/AMD1:1995, known informally as C95) was published, to correct some details and to add more extensive support for international character sets.

The C standard was further revised in the late 1990s, leading to the publication of ISO/IEC 9899:1999 in 1999, which is commonly referred to as "C99". It has since been amended three times by Technical Corrigenda.

C99 introduced several new features, including inline functions, several new data types (including codice_39 and a codice_40 type to represent complex numbers), variable-length arrays and flexible array members, improved support for IEEE 754 floating point, support for variadic macros (macros of variable arity), and support for one-line comments beginning with codice_41, as in BCPL or C++. Many of these had already been implemented as extensions in several C compilers.

C99 is for the most part backward compatible with C90, but is stricter in some ways; in particular, a declaration that lacks a type specifier no longer has codice_30 implicitly assumed. A standard macro codice_43 is defined with value codice_44 to indicate that C99 support is available. GCC, Solaris Studio, and other C compilers now support many or all of the new features of C99. The C compiler in Microsoft Visual C++, however, implements the C89 standard and those parts of C99 that are required for compatibility with C++11.

In 2007, work began on another revision of the C standard, informally called "C1X" until its official publication on 2011-12-08. The C standards committee adopted guidelines to limit the adoption of new features that had not been tested by existing implementations.

The C11 standard adds numerous new features to C and the library, including type generic macros, anonymous structures, improved Unicode support, atomic operations, multi-threading, and bounds-checked functions. It also makes some portions of the existing C99 library optional, and improves compatibility with C++. The standard macro codice_43 is defined as codice_46 to indicate that C11 support is available.

Published in June 2018, C18 is the current standard for the C programming language. It introduces no new language features, only technical corrections and clarifications to defects in C11. The standard macro codice_43 is defined as codice_48.

Historically, embedded C programming requires nonstandard extensions to the C language in order to support exotic features such as fixed-point arithmetic, multiple distinct memory banks, and basic I/O operations.

In 2008, the C Standards Committee published a technical report extending the C language to address these issues by providing a common standard for all implementations to adhere to. It includes a number of features not available in normal C, such as fixed-point arithmetic, named address spaces, and basic I/O hardware addressing.

C has a formal grammar specified by the C standard. Line endings are generally not significant in C; however, line boundaries do have significance during the preprocessing phase. Comments may appear either between the delimiters codice_49 and codice_50, or (since C99) following codice_41 until the end of the line. Comments delimited by codice_49 and codice_50 do not nest, and these sequences of characters are not interpreted as comment delimiters if they appear inside string or character literals.

C source files contain declarations and function definitions. Function definitions, in turn, contain declarations and statements. Declarations either define new types using keywords such as codice_12, codice_35, and codice_14, or assign types to and perhaps reserve storage for new variables, usually by writing the type followed by the variable name. Keywords such as codice_57 and codice_30 specify built-in types. Sections of code are enclosed in braces (codice_59 and codice_60, sometimes called "curly brackets") to limit the scope of declarations and to act as a single statement for control structures.

As an imperative language, C uses "statements" to specify actions. The most common statement is an "expression statement", consisting of an expression to be evaluated, followed by a semicolon; as a side effect of the evaluation, functions may be called and variables may be assigned new values. To modify the normal sequential execution of statements, C provides several control-flow statements identified by reserved keywords. Structured programming is supported by codice_61(-codice_62) conditional execution and by codice_63-codice_4, codice_4, and codice_2 iterative execution (looping). The codice_2 statement has separate initialization, testing, and reinitialization expressions, any or all of which can be omitted. codice_68 and codice_69 can be used to leave the innermost enclosing loop statement or skip to its reinitialization. There is also a non-structured codice_70 statement which branches directly to the designated label within the function. codice_5 selects a codice_72 to be executed based on the value of an integer expression.

Expressions can use a variety of built-in operators and may contain function calls. The order in which arguments to functions and operands to most operators are evaluated is unspecified. The evaluations may even be interleaved. However, all side effects (including storage to variables) will occur before the next "sequence point"; sequence points include the end of each expression statement, and the entry to and return from each function call. Sequence points also occur during evaluation of expressions containing certain operators (codice_73, codice_10, codice_75 and the comma operator). This permits a high degree of object code optimization by the compiler, but requires C programmers to take more care to obtain reliable results than is needed for other programming languages.

Kernighan and Ritchie say in the Introduction of "The C Programming Language": "C, like any other language, has its blemishes. Some of the operators have the wrong precedence; some parts of the syntax could be better." The C standard did not attempt to correct many of these blemishes, because of the impact of such changes on already existing software.

The basic C source character set includes the following characters:


Newline indicates the end of a text line; it need not correspond to an actual single character, although for convenience C treats it as one.

Additional multi-byte encoded characters may be used in string literals, but they are not entirely portable. The latest C standard (C11) allows multi-national Unicode characters to be embedded portably within C source text by using codice_83 or codice_84 encoding (where the codice_85 denotes a hexadecimal character), although this feature is not yet widely implemented.

The basic C execution character set contains the same characters, along with representations for alert, backspace, and carriage return. Run-time support for extended character sets has increased with each revision of the C standard.

C89 has 32 reserved words, also known as keywords, which are the words that cannot be used for any purposes other than those for which they are predefined:

C99 reserved five more words:

C11 reserved seven more words:

Most of the recently reserved words begin with an underscore followed by a capital letter, because identifiers of that form were previously reserved by the C standard for use only by implementations. Since existing program source code should not have been using these identifiers, it would not be affected when C implementations started supporting these extensions to the programming language. Some standard headers do define more convenient synonyms for underscored identifiers. The language previously included a reserved word called codice_130, but this was seldom implemented, and has now been removed as a reserved word.

C supports a rich set of operators, which are symbols used within an expression to specify the manipulations to be performed while evaluating that expression. C has operators for:


C uses the operator codice_136 (used in mathematics to express equality) to indicate assignment, following the precedent of Fortran and PL/I, but unlike ALGOL and its derivatives. C uses the operator codice_156 to test for equality. The similarity between these two operators (assignment and equality) may result in the accidental use of one in place of the other, and in many cases, the mistake does not produce an error message (although some compilers produce warnings). For example, the conditional expression codice_176 might mistakenly be written as codice_177, which will be evaluated as true if codice_76 is not zero after the assignment.

The C operator precedence is not always intuitive. For example, the operator codice_156 binds more tightly than (is executed prior to) the operators codice_9 (bitwise AND) and codice_149 (bitwise OR) in expressions such as codice_182, which must be written as codice_183 if that is the coder's intent.

The "hello, world" example, which appeared in the first edition of "K&R", has become the model for an introductory program in most programming textbooks, regardless of programming language. The program prints "hello, world" to the standard output, which is usually a terminal or screen display.

The original version was:
main()

A standard-conforming "hello, world" program is:


int main(void)

The first line of the program contains a preprocessing directive, indicated by codice_184. This causes the compiler to replace that line with the entire text of the codice_185 standard header, which contains declarations for standard input and output functions such as codice_186 and codice_187. The angle brackets surrounding codice_185 indicate that codice_185 is located using a search strategy that prefers headers provided with the compiler to other headers having the same name, as opposed to double quotes which typically include local or project-specific header files.

The next line indicates that a function named codice_190 is being defined. The codice_190 function serves a special purpose in C programs; the run-time environment calls the codice_190 function to begin program execution. The type specifier codice_30 indicates that the value that is returned to the invoker (in this case the run-time environment) as a result of evaluating the codice_190 function, is an integer. The keyword codice_15 as a parameter list indicates that this function takes no arguments.

The opening curly brace indicates the beginning of the definition of the codice_190 function.

The next line "calls" (diverts execution to) a function named codice_186, which in this case is supplied from a system library. In this call, the codice_186 function is "passed" (provided with) a single argument, the address of the first character in the string literal codice_199. The string literal is an unnamed array with elements of type codice_57, set up automatically by the compiler with a final 0-valued character to mark the end of the array (codice_186 needs to know this). The codice_202 is an "escape sequence" that C translates to a "newline" character, which on output signifies the end of the current line. The return value of the codice_186 function is of type codice_30, but it is silently discarded since it is not used. (A more careful program might test the return value to determine whether or not the codice_186 function succeeded.) The semicolon codice_206 terminates the statement.

The closing curly brace indicates the end of the code for the codice_190 function. According to the C99 specification and newer, the codice_190 function, unlike any other function, will implicitly return a value of codice_80 upon reaching the codice_60 that terminates the function. (Formerly an explicit codice_211 statement was required.) This is interpreted by the run-time system as an exit code indicating successful execution.

The type system in C is static and weakly typed, which makes it similar to the type system of ALGOL descendants such as Pascal. There are built-in types for integers of various sizes, both signed and unsigned, floating-point numbers, and enumerated types (codice_14). Integer type codice_57 is often used for single-byte characters. C99 added a boolean datatype. There are also derived types including arrays, pointers, records (codice_12), and unions (codice_35).

C is often used in low-level systems programming where escapes from the type system may be necessary. The compiler attempts to ensure type correctness of most expressions, but the programmer can override the checks in various ways, either by using a "type cast" to explicitly convert a value from one type to another, or by using pointers or unions to reinterpret the underlying bits of a data object in some other way.

Some find C's declaration syntax unintuitive, particularly for function pointers. (Ritchie's idea was to declare identifiers in contexts resembling their use: "declaration reflects use".)

C's "usual arithmetic conversions" allow for efficient code to be generated, but can sometimes produce unexpected results. For example, a comparison of signed and unsigned integers of equal width requires a conversion of the signed value to unsigned. This can generate unexpected results if the signed value is negative.

C supports the use of pointers, a type of reference that records the address or location of an object or function in memory. Pointers can be "dereferenced" to access data stored at the address pointed to, or to invoke a pointed-to function. Pointers can be manipulated using assignment or pointer arithmetic. The run-time representation of a pointer value is typically a raw memory address (perhaps augmented by an offset-within-word field), but since a pointer's type includes the type of the thing pointed to, expressions including pointers can be type-checked at compile time. Pointer arithmetic is automatically scaled by the size of the pointed-to data type. Pointers are used for many purposes in C. Text strings are commonly manipulated using pointers into arrays of characters. Dynamic memory allocation is performed using pointers. Many data types, such as trees, are commonly implemented as dynamically allocated codice_12 objects linked together using pointers. Pointers to functions are useful for passing functions as arguments to higher-order functions (such as qsort or bsearch) or as callbacks to be invoked by event handlers.

A "null pointer value" explicitly points to no valid location. Dereferencing a null pointer value is undefined, often resulting in a segmentation fault. Null pointer values are useful for indicating special cases such as no "next" pointer in the final node of a linked list, or as an error indication from functions returning pointers. In appropriate contexts in source code, such as for assigning to a pointer variable, a "null pointer constant" can be written as codice_80, with or without explicit casting to a pointer type, or as the codice_218 macro defined by several standard headers. In conditional contexts, null pointer values evaluate to false, while all other pointer values evaluate to true.

Void pointers (codice_219) point to objects of unspecified type, and can therefore be used as "generic" data pointers. Since the size and type of the pointed-to object is not known, void pointers cannot be dereferenced, nor is pointer arithmetic on them allowed, although they can easily be (and in many contexts implicitly are) converted to and from any other object pointer type.

Careless use of pointers is potentially dangerous. Because they are typically unchecked, a pointer variable can be made to point to any arbitrary location, which can cause undesirable effects. Although properly used pointers point to safe places, they can be made to point to unsafe places by using invalid pointer arithmetic; the objects they point to may continue to be used after deallocation (dangling pointers); they may be used without having been initialized (wild pointers); or they may be directly assigned an unsafe value using a cast, union, or through another corrupt pointer. In general, C is permissive in allowing manipulation of and conversion between pointer types, although compilers typically provide options for various levels of checking. Some other programming languages address these problems by using more restrictive reference types.

Array types in C are traditionally of a fixed, static size specified at compile time. (The more recent C99 standard also allows a form of variable-length arrays.) However, it is also possible to allocate a block of memory (of arbitrary size) at run-time, using the standard library's codice_220 function, and treat it as an array. C's unification of arrays and pointers means that declared arrays and these dynamically allocated simulated arrays are virtually interchangeable.

Since arrays are always accessed (in effect) via pointers, array accesses are typically "not" checked against the underlying array size, although some compilers may provide bounds checking as an option. Array bounds violations are therefore possible and rather common in carelessly written code, and can lead to various repercussions, including illegal memory accesses, corruption of data, buffer overruns, and run-time exceptions. If bounds checking is desired, it must be done manually.

C does not have a special provision for declaring multi-dimensional arrays, but rather relies on recursion within the type system to declare arrays of arrays, which effectively accomplishes the same thing. The index values of the resulting "multi-dimensional array" can be thought of as increasing in row-major order.

Multi-dimensional arrays are commonly used in numerical algorithms (mainly from applied linear algebra) to store matrices. The structure of the C array is well suited to this particular task. However, since arrays are passed merely as pointers, the bounds of the array must be known fixed values or else explicitly passed to any subroutine that requires them, and dynamically sized arrays of arrays cannot be accessed using double indexing. (A workaround for this is to allocate the array with an additional "row vector" of pointers to the columns.)

C99 introduced "variable-length arrays" which address some, but not all, of the issues with ordinary C arrays.

The subscript notation codice_221 (where codice_222 designates a pointer) is syntactic sugar for codice_223. Taking advantage of the compiler's knowledge of the pointer type, the address that codice_224 points to is not the base address (pointed to by codice_222) incremented by codice_27 bytes, but rather is defined to be the base address incremented by codice_27 multiplied by the size of an element that codice_222 points to. Thus, codice_221 designates the codice_230th element of the array.

Furthermore, in most expression contexts (a notable exception is as operand of codice_108), the name of an array is automatically converted to a pointer to the array's first element. This implies that an array is never copied as a whole when named as an argument to a function, but rather only the address of its first element is passed. Therefore, although function calls in C use pass-by-value semantics, arrays are in effect passed by reference.

The size of an element can be determined by applying the operator codice_108 to any dereferenced element of codice_222, as in codice_234 or codice_235, and the number of elements in a declared array codice_78 can be determined as codice_237. The latter only applies to array names: variables declared with subscripts (codice_238). Due to the semantics of C, it is not possible to determine the entire size of arrays through pointers to arrays or those created by dynamic allocation (codice_220); code such as codice_240 (where codice_241 designates a pointer) will not work since the compiler assumes the size of the pointer itself is being requested. Since array name arguments to codice_108 are not converted to pointers, they do not exhibit such ambiguity. However, arrays created by dynamic allocation are accessed by pointers rather than true array variables, so they suffer from the same codice_108 issues as array pointers.

Thus, despite this apparent equivalence between array and pointer variables, there is still a distinction to be made between them. Even though the name of an array is, in most expression contexts, converted into a pointer (to its first element), this pointer does not itself occupy any storage; the array name is not an l-value, and its address is a constant, unlike a pointer variable. Consequently, what an array "points to" cannot be changed, and it is impossible to assign a new address to an array name. Array contents may be copied, however, by using the codice_244 function, or by accessing the individual elements.

One of the most important functions of a programming language is to provide facilities for managing memory and the objects that are stored in memory. C provides three distinct ways to allocate memory for objects:


These three approaches are appropriate in different situations and have various trade-offs. For example, static memory allocation has little allocation overhead, automatic allocation may involve slightly more overhead, and dynamic memory allocation can potentially have a great deal of overhead for both allocation and deallocation. The persistent nature of static objects is useful for maintaining state information across function calls, automatic allocation is easy to use but stack space is typically much more limited and transient than either static memory or heap space, and dynamic memory allocation allows convenient allocation of objects whose size is known only at run-time. Most C programs make extensive use of all three.

Where possible, automatic or static allocation is usually simplest because the storage is managed by the compiler, freeing the programmer of the potentially error-prone chore of manually allocating and releasing storage. However, many data structures can change in size at runtime, and since static allocations (and automatic allocations before C99) must have a fixed size at compile-time, there are many situations in which dynamic allocation is necessary. Prior to the C99 standard, variable-sized arrays were a common example of this. (See the article on codice_220 for an example of dynamically allocated arrays.) Unlike automatic allocation, which can fail at run time with uncontrolled consequences, the dynamic allocation functions return an indication (in the form of a null pointer value) when the required storage cannot be allocated. (Static allocation that is too large is usually detected by the linker or loader, before the program can even begin execution.)

Unless otherwise specified, static objects contain zero or null pointer values upon program startup. Automatically and dynamically allocated objects are initialized only if an initial value is explicitly specified; otherwise they initially have indeterminate values (typically, whatever bit pattern happens to be present in the storage, which might not even represent a valid value for that type). If the program attempts to access an uninitialized value, the results are undefined. Many modern compilers try to detect and warn about this problem, but both false positives and false negatives can occur.

Another issue is that heap memory allocation has to be synchronized with its actual usage in any program in order for it to be reused as much as possible. For example, if the only pointer to a heap memory allocation goes out of scope or has its value overwritten before codice_249 is called, then that memory cannot be recovered for later reuse and is essentially lost to the program, a phenomenon known as a "memory leak." Conversely, it is possible for memory to be freed but continue to be referenced, leading to unpredictable results. Typically, the symptoms will appear in a portion of the program far removed from the actual error, making it difficult to track down the problem. (Such issues are ameliorated in languages with automatic garbage collection.)

The C programming language uses libraries as its primary method of extension. In C, a library is a set of functions contained within a single "archive" file. Each library typically has a header file, which contains the prototypes of the functions contained within the library that may be used by a program, and declarations of special data types and macro symbols used with these functions. In order for a program to use a library, it must include the library's header file, and the library must be linked with the program, which in many cases requires compiler flags (e.g., codice_250, shorthand for "link the math library").

The most common C library is the C standard library, which is specified by the ISO and ANSI C standards and comes with every C implementation (implementations which target limited environments such as embedded systems may provide only a subset of the standard library). This library supports stream input and output, memory allocation, mathematics, character strings, and time values. Several separate standard headers (for example, codice_185) specify the interfaces for these and other standard library facilities.

Another common set of C library functions are those used by applications specifically targeted for Unix and Unix-like systems, especially functions which provide an interface to the kernel. These functions are detailed in various standards such as POSIX and the Single UNIX Specification.

Since many programs have been written in C, there are a wide variety of other libraries available. Libraries are often written in C because C compilers generate efficient object code; programmers then create interfaces to the library so that the routines can be used from higher-level languages like Java, Perl, and Python.

File input and output (I/O) is not part of the C language itself but instead is handled by libraries (such as the C standard library) and their associated header files (e.g. codice_185). File handling is generally implemented through high-level I/O which works through streams. A stream is from this perspective a data flow that is independent of devices, while a file is a concrete device. The high level I/O is done through the association of a stream to a file. In the C standard library, a buffer (a memory area or queue) is temporarily used to store data before it's sent to the final destination. This reduces the time spent waiting for slower devices, for example a hard drive or solid state drive. Low-level I/O functions are not part of the standard C library but are generally part of "bare metal" programming (programming that's independent of any operating system such as most but not all embedded programming). With few exceptions, implementations include low-level I/O.

A number of tools have been developed to help C programmers find and fix statements with undefined behavior or possibly erroneous expressions, with greater rigor than that provided by the compiler. The tool lint was the first such, leading to many others.

Automated source code checking and auditing are beneficial in any language, and for C many such tools exist, such as Lint. A common practice is to use Lint to detect questionable code when a program is first written. Once a program passes Lint, it is then compiled using the C compiler. Also, many compilers can optionally warn about syntactically valid constructs that are likely to actually be errors. MISRA C is a proprietary set of guidelines to avoid such questionable code, developed for embedded systems.

There are also compilers, libraries, and operating system level mechanisms for performing actions that are not a standard part of C, such as bounds checking for arrays, detection of buffer overflow, serialization, dynamic memory tracking, and automatic garbage collection.

Tools such as Purify or Valgrind and linking with libraries containing special versions of the memory allocation functions can help uncover runtime errors in memory usage.

C is widely used for systems programming in implementing operating systems and embedded system applications, because C code, when written for portability, can be used for most purposes, yet when needed, system-specific code can be used to access specific hardware addresses and to perform type punning to match externally imposed interface requirements, with a low run-time demand on system resources.

C can also be used for website programming using CGI as a "gateway" for information between the Web application, the server, and the browser. C is often chosen over interpreted languages because of its speed, stability, and near-universal availability.

One consequence of C's wide availability and efficiency is that compilers, libraries and interpreters of other programming languages are often implemented in C. The reference implementations of Python, Perl and PHP, for example, are all written in C.

Because the layer of abstraction is thin and the overhead is low, C enables programmers to create efficient implementations of algorithms and data structures, useful for computationally intense programs. For example, the GNU Multiple Precision Arithmetic Library, the GNU Scientific Library, Mathematica, and MATLAB are completely or partially written in C.

C is sometimes used as an intermediate language by implementations of other languages. This approach may be used for portability or convenience; by using C as an intermediate language, additional machine-specific code generators are not necessary. C has some features, such as line-number preprocessor directives and optional superfluous commas at the end of initializer lists, that support compilation of generated code. However, some of C's shortcomings have prompted the development of other C-based languages specifically designed for use as intermediate languages, such as C--.

C has also been widely used to implement end-user applications. However, such applications can also be written in newer, higher-level languages.

C has both directly and indirectly influenced many later languages such as C#, D, Go, Java, JavaScript, Limbo, LPC, Perl, PHP, Python, and Unix's C shell. The most pervasive influence has been syntactical, all of the languages mentioned combine the statement and (more or less recognizably) expression syntax of C with type systems, data models and/or large-scale program structures that differ from those of C, sometimes radically.

Several C or near-C interpreters exist, including Ch and CINT, which can also be used for scripting.

When object-oriented languages became popular, C++ and Objective-C were two different extensions of C that provided object-oriented capabilities. Both languages were originally implemented as source-to-source compilers; source code was translated into C, and then compiled with a C compiler.

The C++ programming language was devised by Bjarne Stroustrup as an approach to providing object-oriented functionality with a C-like syntax. C++ adds greater typing strength, scoping, and other tools useful in object-oriented programming, and permits generic programming via templates. Nearly a superset of C, C++ now supports most of C, with a few exceptions.

Objective-C was originally a very "thin" layer on top of C, and remains a strict superset of C that permits object-oriented programming using a hybrid dynamic/static typing paradigm. Objective-C derives its syntax from both C and Smalltalk: syntax that involves preprocessing, expressions, function declarations, and function calls is inherited from C, while the syntax for object-oriented features was originally taken from Smalltalk.

In addition to C++ and Objective-C, Ch, Cilk and Unified Parallel C are nearly supersets of C.





</doc>
<doc id="61252437" url="https://en.wikipedia.org/wiki?curid=61252437" title="C2x">
C2x

C2x is an informal name for the next (after C18) major C language standard revision.

It is not expected to be voted on until 2021.

It adds a new principle to the "Original Principles" of C:

Among proposed features:


The GCC 9 compiler has "-std=c2x" option to support this standard, as does Clang 9.0.



</doc>
