***Distributed hash table***
A  distributed hash table  ( DHT ) is a distributed system that provides a lookup service similar to a hash table: ( key ,  value ) pairs are stored in a DHT, and any participating node can efficiently retrieve the value associated with a given key. The main advantage of a DHT is that nodes can be added/removed with minimum work around re-distributting keys.  Keys  are unique identifiers which map to particular  values , which in turn can be anything from addresses, to documents, to arbitrary data. Responsibility for maintaining the mapping from keys to values is distributed among the nodes, in such a way that a change in the set of participants causes a minimal amount of disruption. This allows a DHT to scale to extremely large numbers of nodes and to handle continual node arrivals, departures, and failures.
 DHTs form an infrastructure that can be used to build more complex services, such as anycast, cooperative Web caching, distributed file systems, domain name services, instant messaging, multicast, and also peer-to-peer file sharing and content distribution systems. Notable distributed networks that use DHTs include BitTorrent's distributed tracker, the Coral Content Distribution Network, the Kad network, the Storm botnet, the Tox instant messenger, Freenet, the YaCy search engine, and the InterPlanetary File System.
 

 **Properties**

 DHTs characteristically emphasize the following properties:
 
 Autonomy and decentralization: the nodes collectively form the system without any central coordination. 
 Fault tolerance: the system should be reliable (in some sense) even with nodes continuously joining, leaving, and failing. 
 Scalability: the system should function efficiently even with thousands or millions of nodes. A key technique used to achieve these goals is that any one node needs to coordinate with only a few other nodes in the system – most commonly, O(log  n ) of the  
   
     
       
         n 
       
     
     {\displaystyle n} 
    participants (see below) – so that only a limited amount of work needs to be done for each change in membership.
 Some DHT designs seek to be secure against malicious participants and to allow participants to remain anonymous, though this is less common than in many other peer-to-peer (especially file sharing) systems; see anonymous P2P.
 Finally, DHTs must deal with more traditional distributed systems issues such as load balancing, data integrity, and performance (in particular, ensuring that operations such as routing and data storage or retrieval complete quickly).
 

 **Structure**

 The structure of a DHT can be decomposed into several main components.  The foundation is an abstract  keyspace , such as the set of 160-bit strings. A  keyspace partitioning  scheme splits ownership of this keyspace among the participating nodes. An  overlay network  then connects the nodes, allowing them to find the owner of any given key in the keyspace.
 Once these components are in place, a typical use of the DHT for storage and retrieval might proceed as follows. Suppose the keyspace is the set of 160-bit strings. To index a file with given  filename  and  data  in the DHT, the SHA-1 hash of  filename  is generated, producing a 160-bit key  k , and a message  put ( k, data )  is sent to any node participating in the DHT. The message is forwarded from node to node through the overlay network until it reaches the single node responsible for key  k  as specified by the keyspace partitioning. That node then stores the key and the data. Any other client can then retrieve the contents of the file by again hashing  filename  to produce  k  and asking any DHT node to find the data associated with  k  with a message  get ( k ) . The message will again be routed through the overlay to the node responsible for  k , which will reply with the stored  data .
 The keyspace partitioning and overlay network components are described below with the goal of capturing the principal ideas common to most DHTs; many designs differ in the details.
 

 **Keyspace partitioning**

 Most DHTs use some variant of consistent hashing or rendezvous hashing to map keys to nodes. The two algorithms appear to have been devised independently and simultaneously to solve the distributed hash table problem.
 Both consistent hashing and rendezvous hashing have the essential property that removal or addition of one node changes only the set of keys owned by the nodes with adjacent IDs, and leaves all other nodes unaffected. Contrast this with a traditional hash table in which addition or removal of one bucket causes nearly the entire keyspace to be remapped. Since any change in ownership typically corresponds to bandwidth-intensive movement of objects stored in the DHT from one node to another, minimizing such reorganization is required to efficiently support high rates of churn (node arrival and failure).
 

 **Consistent hashing**

 Consistent hashing employs a function  
   
     
       
         δ 
         ( 
         
           k 
           
             1 
           
         
         , 
         
           k 
           
             2 
           
         
         ) 
       
     
     {\displaystyle \delta (k_{1},k_{2})} 
    that defines an abstract notion of the distance between the keys  
   
     
       
         
           k 
           
             1 
           
         
       
     
     {\displaystyle k_{1}} 
    and  
   
     
       
         
           k 
           
             2 
           
         
       
     
     {\displaystyle k_{2}} 
   , which is unrelated to geographical distance or network latency. Each node is assigned a single key called its  identifier  (ID). A node with ID  
   
     
       
         
           i 
           
             x 
           
         
       
     
     {\displaystyle i_{x}} 
    owns all the keys  
   
     
       
         
           k 
           
             m 
           
         
       
     
     {\displaystyle k_{m}} 
    for which  
   
     
       
         
           i 
           
             x 
           
         
       
     
     {\displaystyle i_{x}} 
    is the closest ID, measured according to  
   
     
       
         δ 
         ( 
         
           k 
           
             m 
           
         
         , 
         
           i 
           
             x 
           
         
         ) 
       
     
     {\displaystyle \delta (k_{m},i_{x})} 
   .
 For example, the Chord DHT uses consistent hashing, which treats nodes as points on a circle, and  
   
     
       
         δ 
         ( 
         
           k 
           
             1 
           
         
         , 
         
           k 
           
             2 
           
         
         ) 
       
     
     {\displaystyle \delta (k_{1},k_{2})} 
    is the distance traveling clockwise around the circle from  
   
     
       
         
           k 
           
             1 
           
         
       
     
     {\displaystyle k_{1}} 
    to  
   
     
       
         
           k 
           
             2 
           
         
       
     
     {\displaystyle k_{2}} 
   . Thus, the circular keyspace is split into contiguous segments whose endpoints are the node identifiers. If  
   
     
       
         
           i 
           
             1 
           
         
       
     
     {\displaystyle i_{1}} 
    and  
   
     
       
         
           i 
           
             2 
           
         
       
     
     {\displaystyle i_{2}} 
    are two adjacent IDs, with a shorter clockwise distance from  
   
     
       
         
           i 
           
             1 
           
         
       
     
     {\displaystyle i_{1}} 
    to  
   
     
       
         
           i 
           
             2 
           
         
       
     
     {\displaystyle i_{2}} 
   , then the node with ID  
   
     
       
         
           i 
           
             2 
           
         
       
     
     {\displaystyle i_{2}} 
    owns all the keys that fall between  
   
     
       
         
           i 
           
             1 
           
         
       
     
     {\displaystyle i_{1}} 
    and  
   
     
       
         
           i 
           
             2 
           
         
       
     
     {\displaystyle i_{2}} 
   .
 

 **Rendezvous hashing**

 In rendezvous hashing, also called highest random weight (HRW) hashing, all clients use the same hash function  
   
     
       
         h 
         ( 
         ) 
       
     
     {\displaystyle h()} 
    (chosen ahead of time) to associate a key to one of the  n  available servers.
Each client has the same list of identifiers  { S 1 ,  S 2 , ...,  S n  } , one for each server.
Given some key  k , a client computes  n  hash weights  w 1  =  h ( S 1 ,  k ),  w 2  =  h ( S 2 ,  k ), ...,  w n  =  h ( S n ,  k ) .
The client associates that key with the server corresponding to the highest hash weight for that key.
A server with ID  
   
     
       
         
           S 
           
             x 
           
         
       
     
     {\displaystyle S_{x}} 
    owns all the keys  
   
     
       
         
           k 
           
             m 
           
         
       
     
     {\displaystyle k_{m}} 
    for which the hash weight  
   
     
       
         h 
         ( 
         
           S 
           
             x 
           
         
         , 
         
           k 
           
             m 
           
         
         ) 
       
     
     {\displaystyle h(S_{x},k_{m})} 
    is higher than the hash weight of any other node for that key.
 

 **Locality-preserving hashing**

 Locality-preserving hashing ensures that similar keys are assigned to similar objects. This can enable a more efficient execution of range queries. Self-Chord decouples object keys from peer IDs and sorts keys along the ring with a statistical approach based on the swarm intelligence paradigm. Sorting ensures that similar keys are stored by neighbour nodes and that discovery procedures, including range queries, can be performed in logarithmic time.
 

 **Overlay network**

 Each node maintains a set of links to other nodes (its  neighbors  or routing table). Together, these links form the overlay network. A node picks its neighbors according to a certain structure, called the network's topology.
 All DHT topologies share some variant of the most essential property: for any key  k , each node either has a node ID that owns  k  or has a link to a node whose node ID is  closer  to  k , in terms of the keyspace distance defined above. It is then easy to route a message to the owner of any key  k  using the following greedy algorithm (that is not necessarily globally optimal): at each step, forward the message to the neighbor whose ID is closest to  k . When there is no such neighbor, then we must have arrived at the closest node, which is the owner of  k  as defined above. This style of routing is sometimes called key-based routing.
 Beyond basic routing correctness, two important constraints on the topology are to guarantee that the maximum number of hops in any route (route length) is low, so that requests complete quickly; and that the maximum number of neighbors of any node (maximum node degree) is low, so that maintenance overhead is not excessive. Of course, having shorter routes requires higher maximum degree. Some common choices for maximum degree and route length are as follows, where  n  is the number of nodes in the DHT, using Big O notation:
 
 The most common choice,  
   
     
       
         O 
         ( 
         log 
         ⁡ 
         n 
         ) 
       
     
     {\displaystyle O(\log n)} 
    degree/route length, is not optimal in terms of degree/route length tradeoff, but such topologies typically allow more flexibility in choice of neighbors. Many DHTs use that flexibility to pick neighbors that are close in terms of latency in the physical underlying network. In general, all DHTs construct navigable Small-World network topologies, which trade-off route length vs. network degree.
 Maximum route length is closely related to diameter: the maximum number of hops in any shortest path between nodes. Clearly, the network's worst case route length is at least as large as its diameter, so DHTs are limited by the degree/diameter tradeoff that is fundamental in graph theory. Route length can be greater than diameter, since the greedy routing algorithm may not find shortest paths. 

 **Algorithms for overlay networks**

 Aside from routing, there exist many algorithms that exploit the structure of the overlay network for sending a message to all nodes, or a subset of nodes, in a DHT. These algorithms are used by applications to do overlay multicast, range queries, or to collect statistics. Two systems that are based on this approach are Structella, which implements flooding and random walks on a Pastry overlay, and DQ-DHT, which implements a dynamic querying search algorithm over a Chord network. 

 **Security**

 Because of the decentralization, fault tolerance, and scalability of DHTs, they are inherently more resilient against a hostile attacker than a centralized system. Open systems for distributed data storage that are robust against massive hostile attackers are feasible. A DHT system that is carefully designed to have Byzantine fault tolerance can defend against a security weakness, known as the Sybil attack, which affects all current DHT designs. Petar Maymounkov, one of the original authors of Kademlia, has proposed a way to circumvent the weakness to the Sybil attack by incorporating social trust relationships into the system design. The new system, codenamed Tonika or also known by its domain name as 5ttt, is based on an algorithm design known as "electric routing" and co-authored with the mathematician Jonathan Kelner. Maymounkov has now undertaken a comprehensive implementation effort of this new system. However, research into effective defences against Sybil attacks is generally considered an open question, and wide variety of potential defences are proposed every year in top security research conferences.
 

 **Implementations**

 Most notable differences encountered in practical instances of DHT implementations include at least the following:
 
 The address space is a parameter of DHT. Several real-world DHTs use 128-bit or 160-bit key space 
 Some real-world DHTs use hash functions other than SHA-1. 
 In the real world the key  
   
     
       
         k 
       
     
     {\displaystyle k} 
    could be a hash of a file's  content  rather than a hash of a file's  name  to provide content-addressable storage, so that renaming of the file does not prevent users from finding it. 
 Some DHTs may also publish objects of different types. For example, key  
   
     
       
         k 
       
     
     {\displaystyle k} 
    could be the node  
   
     
       
         I 
         D 
       
     
     {\displaystyle ID} 
    and associated data could describe how to contact this node. This allows publication-of-presence information and often used in IM applications, etc. In the simplest case,  
   
     
       
         I 
         D 
       
     
     {\displaystyle ID} 
    is just a random number that is directly used as key  
   
     
       
         k 
       
     
     {\displaystyle k} 
    (so in a 160-bit DHT  
   
     
       
         I 
         D 
       
     
     {\displaystyle ID} 
    will be a 160-bit number, usually randomly chosen). In some DHTs, publishing of nodes' IDs is also used to optimize DHT operations. 
 Redundancy can be added to improve reliability.  The  
   
     
       
         ( 
         k 
         , 
         d 
         a 
         t 
         a 
         ) 
       
     
     {\displaystyle (k,data)} 
    key pair can be stored in more than one node corresponding to the key. Usually, rather than selecting just one node, real world DHT algorithms select  
   
     
       
         i 
       
     
     {\displaystyle i} 
    suitable nodes, with  
   
     
       
         i 
       
     
     {\displaystyle i} 
    being an implementation-specific parameter of the DHT. In some DHT designs, nodes agree to handle a certain keyspace range, the size of which may be chosen dynamically, rather than hard-coded. 
 Some advanced DHTs like Kademlia perform iterative lookups through the DHT first in order to select a set of suitable nodes and send  
   
     
       
         p 
         u 
         t 
         ( 
         k 
         , 
         d 
         a 
         t 
         a 
         ) 
       
     
     {\displaystyle put(k,data)} 
    messages only to those nodes, thus drastically reducing useless traffic, since published messages are only sent to nodes that seem suitable for storing the key  
   
     
       
         k 
       
     
     {\displaystyle k} 
   ; and iterative lookups cover just a small set of nodes rather than the entire DHT, reducing useless forwarding. In such DHTs, forwarding of  
   
     
       
         p 
         u 
         t 
         ( 
         k 
         , 
         d 
         a 
         t 
         a 
         ) 
       
     
     {\displaystyle put(k,data)} 
    messages may only occur as part of a self-healing algorithm: if a target node receives a  
   
     
       
         p 
         u 
         t 
         ( 
         k 
         , 
         d 
         a 
         t 
         a 
         ) 
       
     
     {\displaystyle put(k,data)} 
    message, but believes that  
   
     
       
         k 
       
     
     {\displaystyle k} 
    is out of its handled range and a closer node (in terms of DHT keyspace) is known, the message is forwarded to that node. Otherwise, data are indexed locally. This leads to a somewhat self-balancing DHT behavior. Of course, such an algorithm requires nodes to publish their presence data in the DHT so the iterative lookups can be performed. 

 **Examples**

 **DHT protocols and implementations**

 Apache Cassandra 
 BATON Overlay 
 Mainline DHT - Standard DHT used by BitTorrent (based on Kademlia as provided by Khashmir) 
 CAN (Content Addressable Network) 
 Chord 
 Koorde 
 Kademlia 
 Pastry 
 P-Grid 
 Riak 
 Tapestry 
 TomP2P 
 Voldemort 

 **Applications using DHTs**

 BTDigg: BitTorrent DHT search engine 
 CloudSNAP: a decentralized web application deployment platform 
 Codeen: web caching 
 Coral Content Distribution Network 
 FAROO: peer-to-peer Web search engine 
 Freenet: a censorship-resistant anonymous network 
 GlusterFS: a distributed file system used for storage virtualization 
 GNUnet: Freenet-like distribution network including a DHT implementation 
 I2P: An open-source anonymous peer-to-peer network 
  I2P-Bote: serverless secure anonymous e-mail 
 IPFS: A content-addressable, peer-to-peer hypermedia distribution protocol 
 JXTA: open-source P2P platform 
 LBRY: a free, open and community-run digital marketplace 
 Oracle Coherence: an in-memory data grid built on top of a Java DHT implementation 
 Perfect Dark: a peer-to-peer file-sharing application from Japan 
 Retroshare: a Friend-to-friend network 
 Ring: a privacy-preserving voice, video and chat communication platform, based on a Kademlia-like DHT 
 Tox: an instant messaging system intended to function as a Skype replacement 
 Twister: a microblogging peer-to-peer platform 
 YaCy: a distributed search engine 

 