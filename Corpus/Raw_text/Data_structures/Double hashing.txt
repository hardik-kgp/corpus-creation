***Double hashing***
Double hashing  is a computer programming technique used in conjunction with open-addressing in hash tables to resolve hash collisions, by using a secondary hash of the key as an offset when a collision occurs.   Double hashing with open addressing is a classical data structure on a table  
   
     
       
         T 
       
     
     {\displaystyle T} 
   .
 It uses one hash value as an index into the table and then repeatedly steps forward an interval until the desired value is located, an empty location is reached, or the entire table has been searched; but this interval is set by a second, independent hash function. Unlike the alternative collision-resolution methods of linear probing and quadratic probing, the interval depends on the data, so that values mapping to the same location have different bucket sequences; this minimizes repeated collisions and the effects of clustering. 
 Given two random, uniform, and independent hash functions  
   
     
       
         
           h 
           
             1 
           
         
       
     
     {\displaystyle h_{1}} 
    and  
   
     
       
         
           h 
           
             2 
           
         
       
     
     {\displaystyle h_{2}} 
   , the  
   
     
       
         i 
       
     
     {\displaystyle i} 
   th location in the bucket sequence for value  
   
     
       
         k 
       
     
     {\displaystyle k} 
    in a hash table of  
   
     
       
         
           | 
         
         T 
         
           | 
         
       
     
     {\displaystyle |T|} 
    buckets is:  
   
     
       
         h 
         ( 
         i 
         , 
         k 
         ) 
         = 
         ( 
         
           h 
           
             1 
           
         
         ( 
         k 
         ) 
         + 
         i 
         ⋅ 
         
           h 
           
             2 
           
         
         ( 
         k 
         ) 
         ) 
         
         mod 
         
         
         
           | 
         
         T 
         
           | 
         
         . 
       
     
     {\displaystyle h(i,k)=(h_{1}(k)+i\cdot h_{2}(k))\mod |T|.} 
   
Generally,  
   
     
       
         
           h 
           
             1 
           
         
       
     
     {\displaystyle h_{1}} 
    and  
   
     
       
         
           h 
           
             2 
           
         
       
     
     {\displaystyle h_{2}} 
    are selected from a set of universal hash functions;  
   
     
       
         
           h 
           
             1 
           
         
       
     
     {\displaystyle h_{1}} 
    is selected to have a range of  
   
     
       
         { 
         0 
         , 
         
           | 
         
         T 
         
           | 
         
         − 
         1 
         } 
       
     
     {\displaystyle \{0,|T|-1\}} 
    and  
   
     
       
         
           h 
           
             2 
           
         
       
     
     {\displaystyle h_{2}} 
    to have a range of  
   
     
       
         { 
         1 
         , 
         
           | 
         
         T 
         
           | 
         
         − 
         1 
         } 
       
     
     {\displaystyle \{1,|T|-1\}} 
   . Double hashing approximates a random distribution; more precisely, pair-wise independent hash functions yield a probability of  
   
     
       
         ( 
         n 
         
           / 
         
         
           | 
         
         T 
         
           | 
         
         
           ) 
           
             2 
           
         
       
     
     {\displaystyle (n/|T|)^{2}} 
    that any pair of keys will follow the same bucket sequence.
 

 **Selection of h**
**2**
**(k)**

 The secondary hash function  
   
     
       
         
           h 
           
             2 
           
         
         ( 
         k 
         ) 
       
     
     {\displaystyle h_{2}(k)} 
    should have several characteristics:
 
 it should never yield an index of zero 
 it should cycle through the whole table 
 it should be very fast to compute 
 it should be pair-wise independent of  
   
     
       
         
           h 
           
             1 
           
         
         ( 
         k 
         ) 
       
     
     {\displaystyle h_{1}(k)} 
   
 The distribution characteristics of  
   
     
       
         
           h 
           
             2 
           
         
       
     
     {\displaystyle h_{2}} 
    are irrelevant. It is analogous to a random-number generator - it is only necessary that  
   
     
       
         
           h 
           
             2 
           
         
       
     
     {\displaystyle h_{2}} 
    be ’’relatively prime’’ to |T|. In practice, if division hashing is used for both functions, the divisors are chosens as primes.
 

 **Analysis**

 Let  
   
     
       
         n 
       
     
     {\displaystyle n} 
    be the number of elements stored in  
   
     
       
         T 
       
     
     {\displaystyle T} 
   , then  
   
     
       
         T 
       
     
     {\displaystyle T} 
   's load factor is  
   
     
       
         α 
         = 
         n 
         
           / 
         
         
           | 
         
         T 
         
           | 
         
       
     
     {\displaystyle \alpha =n/|T|} 
   .  That is, start by randomly, uniformly and independently selecting two universal hash functions  
   
     
       
         
           h 
           
             1 
           
         
       
     
     {\displaystyle h_{1}} 
    and  
   
     
       
         
           h 
           
             2 
           
         
       
     
     {\displaystyle h_{2}} 
    to build a double hashing table  
   
     
       
         T 
       
     
     {\displaystyle T} 
   . All elements are put in  
   
     
       
         T 
       
     
     {\displaystyle T} 
    by double hashing using  
   
     
       
         
           h 
           
             1 
           
         
       
     
     {\displaystyle h_{1}} 
    and  
   
     
       
         
           h 
           
             2 
           
         
       
     
     {\displaystyle h_{2}} 
   .
Given a key  
   
     
       
         k 
       
     
     {\displaystyle k} 
   , determining the  
   
     
       
         ( 
         i 
         + 
         1 
         ) 
       
     
     {\displaystyle (i+1)} 
   -st hash location is computed by:
 
   
     
       
         h 
         ( 
         i 
         , 
         k 
         ) 
         = 
         ( 
         
           h 
           
             1 
           
         
         ( 
         k 
         ) 
         + 
         i 
         ⋅ 
         
           h 
           
             2 
           
         
         ( 
         k 
         ) 
         ) 
         
         mod 
         
         
         
           | 
         
         T 
         
           | 
         
         . 
       
     
     {\displaystyle h(i,k)=(h_{1}(k)+i\cdot h_{2}(k))\mod |T|.} 
   
 Let  
   
     
       
         T 
       
     
     {\displaystyle T} 
    have fixed load factor  
   
     
       
         α 
         : 
         1 
         > 
         α 
         > 
         0 
       
     
     {\displaystyle \alpha :1>\alpha >0} 
   .
 
 Bradford and Katehakis
showed the expected number of probes for an unsuccessful search in  
   
     
       
         T 
       
     
     {\displaystyle T} 
   , still using these initially chosen hash functions, is  
   
     
       
         
           
             1 
             
               1 
               − 
               α 
             
           
         
       
     
     {\displaystyle {\frac {1}{1-\alpha }}} 
    regardless of the distribution of the inputs. Pair-wise independence of the hash functions suffices.
 Like all other forms of open addressing, double hashing becomes linear as the hash table approaches maximum capacity. The usual heuristic is to limit the table loading to 75% of capacity.  Eventually, rehashing to a larger size will be necessary, as with all other open addressing schemes.
 

 **Quadratic double hashing**

 