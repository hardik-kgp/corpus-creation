***Linear hashing***
Linear hashing  ( LH ) is a dynamic data structure which implements a hash table and grows or shrinks one bucket at a time. It was invented by Witold Litwin in 1980.  It has been analyzed by Baeza-Yates and Soza-Pollman. 
It is the first in a number of schemes known as dynamic hashing
 
such as Larson's Linear Hashing with Partial Extensions, 

Linear Hashing with Priority Splitting,

Linear Hashing with Partial Expansions and Priority Splitting,

or Recursive Linear Hashing.
 The file structure of a dynamic hashing data structure adapts itself to changes in the size of the file, so expensive periodic file reorganization is avoided. A Linear Hashing file expends by splitting
a pre-determined bucket into two and contracts by merging two predetermined buckets into one. The trigger for a reconstruction depends on the flavor of the scheme; it could be an overflow at a bucket or  load factor (number of records over the number of buckets) moving outside of a predetermined range. Linear Hashing has also been made into a scalable distributed data structure,  LH* . In LH*, each bucket resides at a different server.
 LH* itself has been expanded to provide data availability in the presence of
failed buckets.
 Key based operations (inserts, deletes, updates, reads) in LH and 
LH* take maximum constant time independent of the number of buckets and hence of records.
 

 **Algorithm details**

 Records in LH or LH* consists of a key and a content, the latter basically all the other attributes of the record.  They are stored in buckets. For example, in Ellis' implementation, a bucket is a linked list of records. The file allows the key based CRUD operations create or insert, read, update, and delete as well as a scan operations that scans all records, for example to do a database select operation on a non-key attribute. Records are stored in buckets whose numbering starts with 0. 

 **Hash functions**

 In order to access a record with key  
   
     
       
         c 
       
     
     {\displaystyle c} 
   , a family of hash functions, called
collectively a dynamic hash function is applied to the key  
   
     
       
         c 
       
     
     {\displaystyle c} 
   . At any time, 
at most two hash functions  
   
     
       
         
           h 
           
             i 
           
         
       
     
     {\displaystyle h_{i}} 
    and  
   
     
       
         
           h 
           
             i 
             + 
             1 
           
         
       
     
     {\displaystyle h_{i+1}} 
    are used. A typical
example uses the division modulo x operation. If the original number of buckets is
 
   
     
       
         N 
       
     
     {\displaystyle N} 
   , then the family of hash functions is  
   
     
       
         
           h 
           
             i 
           
         
         ( 
         c 
         ) 
         ↦ 
         c 
         
           
           ( 
           mod 
           
           N 
           ⋅ 
           
             2 
             
               i 
             
           
           ) 
         
       
     
     {\displaystyle h_{i}(c)\mapsto c{\pmod {N\cdot 2^{i}}}} 
   
 

 **File expansion**

 As the file grows through insertions, it expands gracefully through the splitting
of one bucket into two buckets. The sequence of buckets to split is predetermined.
This is the fundamental difference to schemes like Fagin's extendible hashing.

For the two new buckets, the hash function  
   
     
       
         
           h 
           
             i 
           
         
       
     
     {\displaystyle h_{i}} 
    is replaces with 
 
   
     
       
         
           h 
           
             i 
             + 
             1 
           
         
       
     
     {\displaystyle h_{i+1}} 
   . The number of the bucket to be split is part of the 
file state and called the split pointer  
   
     
       
         s 
       
     
     {\displaystyle s} 
   . 

 **Split control**

 A split can be performed whenever a bucket overflows.  This is an uncontrolled split.
Alternatively, the file can monitor the load factor and performs a split whenever
the load factor exceeds a threshold. This was controlled splitting. 

 **Addressing**

 Addressing is based on the file state, consisting of the split pointer  
   
     
       
         s 
       
     
     {\displaystyle s} 
   
and the level  
   
     
       
         l 
       
     
     {\displaystyle l} 
   .  If the level is  
   
     
       
         l 
       
     
     {\displaystyle l} 
   , then the hash functions
used are  
   
     
       
         
           h 
           
             l 
           
         
       
     
     {\displaystyle h_{l}} 
    and  
   
     
       
         
           h 
           
             l 
             + 
             1 
           
         
       
     
     {\displaystyle h_{l+1}} 
   .
 The LH algorithm for hashing key  
   
     
       
         c 
       
     
     {\displaystyle c} 
    is 
   
     
       
         a 
         := 
         
           h 
           
             l 
           
         
         ( 
         c 
         ) 
       
     
     {\displaystyle a:=h_{l}(c)} 
   
 if  
   
     
       
         a 
         < 
         s 
         : 
         a 
         := 
         
           h 
           
             l 
             + 
             1 
           
         
         ( 
         c 
         ) 
       
     
     {\displaystyle a<s:a:=h_{l+1}(c)} 
   
 

 **Splitting**

 When a bucket is split, split pointer and possibly the level are updated according to 
   
     
       
         s 
         := 
         s 
         + 
         1 
       
     
     {\displaystyle s:=s+1} 
   
 if  
   
     
       
         s 
         ≥ 
         N 
         × 
         
           2 
           
             l 
           
         
       
     
     {\displaystyle s\geq N\times 2^{l}} 
   :  
   
     
       
         l 
         + 
         = 
         1 
         , 
         s 
         = 
         0 
       
     
     {\displaystyle l+=1,s=0} 
   
 

 **File contraction**

 If under controlled splitting the load factor sinks below a threshold, a merge operation
is triggered. The merge operation undoes the last split, also resetting the file state.
 

 **File state calculation**

 The file state consists of split pointer  
   
     
       
         s 
       
     
     {\displaystyle s} 
    and level  
   
     
       
         l 
       
     
     {\displaystyle l} 
   . If the 
original file started with  
   
     
       
         N 
         = 
         1 
       
     
     {\displaystyle N=1} 
    buckets, then the number of buckets 
 
   
     
       
         n 
       
     
     {\displaystyle n} 
    and the file state are related via
 
   
     
       
         n 
         = 
         
           2 
           
             l 
           
         
         + 
         s 
       
     
     {\displaystyle n=2^{l}+s} 
   
 

 **LH***

 The main contribution of LH* is to allow a client of an LH* file to find the bucket where
the record resides even if the client does not know the file state. Clients in fact store
their version of the file state, which is initially just the knowledge of the first bucket, namely Bucket 0. Based on their file state, a client calculates the address of a
key and sends a request to that bucket. At the bucket, the request is checked and if
the record is not at the bucket, it is forwarded.  In a reasonably stable system, that is, 
if there is only one split or merge going on while the request is processed, it can
be shown that there are at most two forwards. After a forward, the final bucket sends an 
Image Adjustment Message to the client whose state is now closer to the state of the distributed file.  While forwards are reasonably rare for active clients, 
their number can be even further reduced by additional information exchange between 
servers and clients  

 **Adoption in language systems**

 Griswold and Townsend  discussed the adoption of linear hashing in the Icon language. They discussed the implementation alternatives of dynamic array algorithm used in linear hashing, and presented performance comparisons using a list of Icon benchmark applications.
 

 **Adoption in database systems**

 Linear hashing is used in the Berkeley database system (BDB), which in turn is used by many software systems such as OpenLDAP, using a C implementation derived from the CACM article and first published on the Usenet in 1988 by Esmond Pitt.
 

 