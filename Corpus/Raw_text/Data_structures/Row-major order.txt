***Row-major order***
In computing,  row-major order  and  column-major order  are methods for storing multidimensional arrays  in linear storage such as random access memory.
 The difference between the orders lies in which elements of an array are contiguous in memory. In a row-major order, the consecutive elements of a row reside next to each other, whereas the same holds true for consecutive elements of a column in a column-major order. While the terms allude to the rows and columns of a two-dimensional array, i.e. a matrix, the orders can be generalized to arrays of any dimension by noting that the terms row-major and column-major are equivalent to lexicographic and colexicographic orders, respectively.
 Data layout is critical for correctly passing arrays between programs written in different programming languages. It is also important for performance when traversing an array because modern CPUs process sequential data more efficiently than nonsequential data. This is primarily due to CPU caching. In addition, contiguous access makes it possible to use SIMD instructions that operate on vectors of data. In some media such as tape or NAND flash memory, accessing sequentially is orders of magnitude faster than nonsequential access. 

 **Explanation and example**

 The terms row-major and column-major stem from the terminology related to ordering objects.  A general way to order objects with many attributes is to first group and order them by one attribute, and then, within each such group, group and order them by another attribute, etc. If more than one attribute participate in ordering, the first would be called  major  and the last  minor . If two attributes participate in ordering, it is sufficient to name only the major attribute.
 In the case of arrays, the attributes are the indices along each dimension. For matrices in mathematical notation, the first index indicates the  row , and the second indicates the  column , e.g., given a matrix  A  ,  a 1,2  is in its first row and second column. This convention is carried over to the syntax in programming languages, although often with indexes starting at 0 instead of 1. Even though the row is indicated by the  first  index and the column by the  second  index, no grouping order between the dimensions is implied by this. The choice of how to group and order the indices, either by row-major or column-major methods, is thus a matter of convention. The same terminology can be applied to even higher dimensional arrays. Row-major grouping starts from the  leftmost  index  and column-major from the  rightmost  index, leading to lexicographic and colexicographic (or colex) orders, respectively.
 For example, for the array
 
 
   
     
       
         A 
         = 
         
           
             [ 
             
               
                 
                   
                     a 
                     
                       11 
                     
                   
                 
                 
                   
                     a 
                     
                       12 
                     
                   
                 
                 
                   
                     a 
                     
                       13 
                     
                   
                 
               
               
                 
                   
                     a 
                     
                       21 
                     
                   
                 
                 
                   
                     a 
                     
                       22 
                     
                   
                 
                 
                   
                     a 
                     
                       23 
                     
                   
                 
               
             
             ] 
           
         
       
     
     {\displaystyle A={\begin{bmatrix}a_{11}&a_{12}&a_{13}\\a_{21}&a_{22}&a_{23}\end{bmatrix}}} 
   the two possible ways (in C, indexing from 0) are
 
 The two possible ways (from Fortran, 1-indexed):
 
 
Note how the use of  A[i][j]  with multi-step indexing as in C, as opposed to a neutral notation like  A(i,j)  as in Fortran, almost inevitably implies row-major order for syntactic reasons, so to speak, because it can be rewritten as  (A[i])[j] , and the  A[i]  row part can even be assigned to an intermediate variable that is then indexed in a separate expression. (No other implications should be assumed, e.g., Fortran is not column-major simply  because  of its notation, and even the above implication could intentionally be circumvented in a new language.)
 To use column-major order in a row-major environment, or vice versa, for whatever reason, one workaround is to assign non-conventional roles to the indexes (using the first index for the column and the second index for the row), and another is to bypass language syntax by explicitly computing positions in a one-dimensional array. Of course, deviating from convention probably incurs a cost that increases with the degree of necessary interaction with conventional language features and other code, not only in the form of increased vulnerability to mistakes (forgetting to also invert matrix multiplication order, reverting to convention during code maintenance, etc.), but also in the form of having to actively rearrange elements, all of which have to be weighed against any original purpose such as increasing performance.
 

 **Programming languages and libraries**

 Programming languages or their standard libraries that support multi-dimensional arrays typically have a native row-major or column-major storage order for these arrays.
 Row-major order is used in C/C++/Objective-C (for C-style arrays), PL/I, Pascal, Speakeasy, SAS, and Rasdaman. Column-major order is used in Fortran, MATLAB, GNU Octave, S-Plus, R, Julia, and Scilab. A special case would be OpenGL (and OpenGL ES) for graphics processing. Since "recent mathematical treatments of linear algebra and related fields invariably treat vectors as columns," designer Mark Segal decided to substitute this for the convention in predecessor IRIS GL, which was to write vectors as rows; for compatibility, transformation matrices would still be stored in vector-major rather than coordinate-major order, and he then used the "subterfuge [to] say that matrices in OpenGL are stored in column major order". This was really only relevant for presentation, because matrix multiplication was stack-based and could still be interpreted as post-multiplication, but, worse, reality leaked through the C-based API because individual elements would be accessed as  M[vector][coordinate]  or, effectively,  M[column][row] , which unfortunately muddled the convention that the designer sought to adopt, and this was even preserved in the OpenGL Shading Language that was later added (although this also makes it possible to access coordinates by name instead, e.g.,  M[vector].y ). As a result, many developers will now simply declare that having the column as the first index is the definition of column-major, even though this is clearly not the case with a real column-major language like Fortran.
 

 **Neither row-major nor column-major**

 A typical alternative for dense array storage is to use Iliffe vectors, which typically store elements in the same row contiguously (like row-major order), but not the rows themselves. They are used in (ordered by age): Java, C#/CLI/.Net, Scala, and Swift.
 Even less dense is to use lists of lists, e.g., in Python, and in the Wolfram Language of Wolfram Mathematica. An alternative approach uses tables of tables, e.g., in Lua. 

 **External libraries**

 Support for multi-dimensional arrays may also be provided by external libraries, which may even support arbitrary orderings, where each dimension has a stride value, and row-major or column-major are just two possible resulting interpretations.
 Row-major order is the default in NumPy (for Python).
 Column-major order is the default in Eigen (for C++).
 Torch (for Lua) changed from column-major to row-major default order.
 

 **Transposition**

 As exchanging the indices of an array is the essence of array transposition, an array stored as row-major but read as column-major (or vice versa) will appear transposed.  As actually performing this rearrangement in memory is typically an expensive operation, some systems provide options to specify individual matrices as being stored transposed. The programmer must then decide whether or not to rearrange the elements in memory, based on the actual usage (including the number of times that the array is reused in a computation).
 For example, the Basic Linear Algebra Subprograms functions are passed flags indicating which arrays are transposed. 

 **Address calculation in general**

 The concept generalizes to arrays with more than two dimensions.
 For a  d -dimensional  
   
     
       
         
           N 
           
             1 
           
         
         × 
         
           N 
           
             2 
           
         
         × 
         ⋯ 
         × 
         
           N 
           
             d 
           
         
       
     
     {\displaystyle N_{1}\times N_{2}\times \cdots \times N_{d}} 
    array with dimensions  N k  ( k =1... d ), a given element of this array is specified by a tuple  
   
     
       
         ( 
         
           n 
           
             1 
           
         
         , 
         
           n 
           
             2 
           
         
         , 
         … 
         , 
         
           n 
           
             d 
           
         
         ) 
       
     
     {\displaystyle (n_{1},n_{2},\ldots ,n_{d})} 
    of  d  (zero-based) indices  
   
     
       
         
           n 
           
             k 
           
         
         ∈ 
         [ 
         0 
         , 
         
           N 
           
             k 
           
         
         − 
         1 
         ] 
       
     
     {\displaystyle n_{k}\in [0,N_{k}-1]} 
   .
 In row-major order, the  last  dimension is contiguous, so that the memory-offset of this element is given by:
 
 
   
     
       
         
           n 
           
             d 
           
         
         + 
         
           N 
           
             d 
           
         
         ⋅ 
         ( 
         
           n 
           
             d 
             − 
             1 
           
         
         + 
         
           N 
           
             d 
             − 
             1 
           
         
         ⋅ 
         ( 
         
           n 
           
             d 
             − 
             2 
           
         
         + 
         
           N 
           
             d 
             − 
             2 
           
         
         ⋅ 
         ( 
         ⋯ 
         + 
         
           N 
           
             2 
           
         
         
           n 
           
             1 
           
         
         ) 
         ⋯ 
         ) 
         ) 
         ) 
         = 
         
           ∑ 
           
             k 
             = 
             1 
           
           
             d 
           
         
         
           ( 
           
             
               ∏ 
               
                 ℓ 
                 = 
                 k 
                 + 
                 1 
               
               
                 d 
               
             
             
               N 
               
                 ℓ 
               
             
           
           ) 
         
         
           n 
           
             k 
           
         
       
     
     {\displaystyle n_{d}+N_{d}\cdot (n_{d-1}+N_{d-1}\cdot (n_{d-2}+N_{d-2}\cdot (\cdots +N_{2}n_{1})\cdots )))=\sum _{k=1}^{d}\left(\prod _{\ell =k+1}^{d}N_{\ell }\right)n_{k}} 
   In column-major order, the  first  dimension is contiguous, so that the memory-offset of this element is given by:
 
 
   
     
       
         
           n 
           
             1 
           
         
         + 
         
           N 
           
             1 
           
         
         ⋅ 
         ( 
         
           n 
           
             2 
           
         
         + 
         
           N 
           
             2 
           
         
         ⋅ 
         ( 
         
           n 
           
             3 
           
         
         + 
         
           N 
           
             3 
           
         
         ⋅ 
         ( 
         ⋯ 
         + 
         
           N 
           
             d 
             − 
             1 
           
         
         
           n 
           
             d 
           
         
         ) 
         ⋯ 
         ) 
         ) 
         ) 
         = 
         
           ∑ 
           
             k 
             = 
             1 
           
           
             d 
           
         
         
           ( 
           
             
               ∏ 
               
                 ℓ 
                 = 
                 1 
               
               
                 k 
                 − 
                 1 
               
             
             
               N 
               
                 ℓ 
               
             
           
           ) 
         
         
           n 
           
             k 
           
         
       
     
     {\displaystyle n_{1}+N_{1}\cdot (n_{2}+N_{2}\cdot (n_{3}+N_{3}\cdot (\cdots +N_{d-1}n_{d})\cdots )))=\sum _{k=1}^{d}\left(\prod _{\ell =1}^{k-1}N_{\ell }\right)n_{k}} 
   where the empty product is the multiplicative identity element, i.e.,  
   
     
       
         
           ∏ 
           
             ℓ 
             = 
             1 
           
           
             0 
           
         
         
           N 
           
             ℓ 
           
         
         = 
         
           ∏ 
           
             ℓ 
             = 
             d 
             + 
             1 
           
           
             d 
           
         
         
           N 
           
             ℓ 
           
         
         = 
         1 
       
     
     {\displaystyle \prod _{\ell =1}^{0}N_{\ell }=\prod _{\ell =d+1}^{d}N_{\ell }=1} 
   .
 For a given order, the stride in dimension  k  is given by the multiplication value in parentheses before index  n k  in the right hand-side summations above.
 More generally, there are  d!  possible orders for a given array, one for each permutation of dimensions (with row-major and column-order just 2 special cases), although the lists of stride values are not necessarily permutations of each other, e.g., in the 2-by-3 example above, the strides are (3,1) for row-major and (1,2) for column-major.
 

 **Sources**

 Donald E. Knuth,  The Art of Computer Programming Volume 1: Fundamental Algorithms , third edition, section 2.2.6 (Addison-Wesley: New York, 1997). 