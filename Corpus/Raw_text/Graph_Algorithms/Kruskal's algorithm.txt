***Kruskal's algorithm***
 Kruskal's algorithm  is a minimum-spanning-tree algorithm which finds an edge of the least possible weight that connects any two trees in the forest. It is a greedy algorithm in graph theory as it finds a minimum spanning tree for a connected weighted graph adding increasing cost arcs at each step. This means it finds a subset of the edges that forms a tree that includes every vertex, where the total weight of all the edges in the tree is minimized.  If the graph is not connected, then it finds a  minimum spanning forest  (a minimum spanning tree for each connected component).
 This algorithm first appeared in  Proceedings of the American Mathematical Society , pp. 48–50 in 1956, and was written by Joseph Kruskal. Other algorithms for this problem include Prim's algorithm, Reverse-delete algorithm, and Borůvka's algorithm.
 

 **Algorithm**

 create a forest  F  (a set of trees), where each vertex in the graph is a separate tree 
 create a set  S  containing all the edges in the graph 
 while  S  is nonempty and  F  is not yet spanning
 remove an edge with minimum weight from  S 
 if the removed edge connects two different trees then add it to the forest  F , combining two trees into a single tree At the termination of the algorithm, the forest forms a minimum spanning forest of the graph. If the graph is connected, the forest has a single component and forms a minimum spanning tree
 

 **Pseudocode**

 The following code is implemented with disjoint-set data structure:
 
 KRUSKAL(G):
1 A = ∅
2  foreach  v ∈ G.V:
3    MAKE-SET(v)
4  foreach  (u, v) in G.E ordered by weight(u, v), increasing:
5     if  FIND-SET(u) ≠ FIND-SET(v):
6       A = A ∪ {(u, v)}
7       UNION(FIND-SET(u), FIND-SET(v))
8  return  A
 

 **Complexity**

 Kruskal's algorithm can be shown to run in  O ( E  log  E ) time, or equivalently,  O ( E  log  V ) time, where  E  is the number of edges in the graph and  V  is the number of vertices, all with simple data structures. These running times are equivalent because:
 
 E  is at most  
   
     
       
         
           V 
           
             2 
           
         
       
     
     {\displaystyle V^{2}} 
    and  
   
     
       
         log 
         ⁡ 
         
           V 
           
             2 
           
         
         = 
         2 
         log 
         ⁡ 
         V 
       
     
     {\displaystyle \log V^{2}=2\log V} 
    is  
   
     
       
         O 
         ( 
         log 
         ⁡ 
         V 
         ) 
       
     
     {\displaystyle O(\log V)} 
   . 
 Each isolated vertex is a separate component of the minimum spanning forest. If we ignore isolated vertices we obtain  V  ≤ 2 E , so log  V  is  
   
     
       
         O 
         ( 
         log 
         ⁡ 
         E 
         ) 
       
     
     {\displaystyle O(\log E)} 
   . We can achieve this bound as follows: first sort the edges by weight using a comparison sort in  O ( E  log  E ) time; this allows the step "remove an edge with minimum weight from  S " to operate in constant time. Next, we use a disjoint-set data structure to keep track of which vertices are in which components. We need to perform O( V ) operations, as in each iteration we connect a vertex to the spanning tree, two 'find' operations and possibly one union for each edge. Even a simple disjoint-set data structure such as disjoint-set forests with union by rank can perform O( V ) operations in  O ( V  log  V ) time. Thus the total time is  O ( E  log  E ) =  O ( E  log  V ).
 Provided that the edges are either already sorted or can be sorted in linear time (for example with counting sort or radix sort), the algorithm can use a more sophisticated disjoint-set data structure to run in  O ( E  α( V )) time, where α is the extremely slowly growing inverse of the single-valued Ackermann function.
 

 **Example**

 **Proof of correctness**

 The proof consists of two parts. First, it is proved that the algorithm produces a spanning tree. Second, it is proved that the constructed spanning tree is of minimal weight.
 

 **Spanning tree**

 Let  
   
     
       
         G 
       
     
     {\displaystyle G} 
    be a connected, weighted graph and let  
   
     
       
         Y 
       
     
     {\displaystyle Y} 
    be the subgraph of  
   
     
       
         G 
       
     
     {\displaystyle G} 
    produced by the algorithm.  
   
     
       
         Y 
       
     
     {\displaystyle Y} 
    cannot have a cycle, being within one subtree and not between two different trees.  
   
     
       
         Y 
       
     
     {\displaystyle Y} 
    cannot be disconnected, since the first encountered edge that joins two components of  
   
     
       
         Y 
       
     
     {\displaystyle Y} 
    would have been added by the algorithm. Thus,  
   
     
       
         Y 
       
     
     {\displaystyle Y} 
    is a spanning tree of  
   
     
       
         G 
       
     
     {\displaystyle G} 
   .
 

 **Minimality**

 We show that the following proposition  P  is true by induction: If  F  is the set of edges chosen at any stage of the algorithm, then there is some minimum spanning tree that contains  F .
 
 Clearly  P  is true at the beginning, when  F  is empty: any minimum spanning tree will do, and there exists one because a weighted connected graph always has a minimum spanning tree. 
 Now assume  P  is true for some non-final edge set  F  and let  T  be a minimum spanning tree that contains  F .
 If the next chosen edge  e  is also in  T , then  P  is true for  F  +  e . 
 Otherwise,  e  is not in  T , and  T  +  e  has a cycle  C .  This cycle contains edges which do not belong to  F , since  e  does not form a cycle in  F  but does in  T .  Let  f  be an edge in  C  but not in  F 
   
     
       
         ∪ 
         { 
         e 
         } 
       
     
     {\displaystyle \cup \{e\}} 
   .  Note that  f  belongs also to  T , and by   P  has not be considered by the algorithm, and hence a weight at least as large as  e . Then  T  −  f  +  e  is a tree, and it has the same or less weight as  T .  So  T  −  f  +  e  is a minimum spanning tree containing  F  +  e  and again  P  holds. 
 Therefore, by the principle of induction,  P  holds when  F  has become a spanning tree, which is only possible if  F  is a minimum spanning tree itself. 

 **Parallel Algorithm**

 Kruskal's algorithm is inherently sequential and hard to parallelize. It is, however, possible to perform the initial sorting of the edges in parallel or, alternatively, to use a parallel implementation of a binary heap to extract the minimum-weight edge in every iteration.
As parallel sorting is possible in time  
   
     
       
         O 
         ( 
         n 
         ) 
       
     
     {\displaystyle O(n)} 
    on  
   
     
       
         O 
         ( 
         log 
         ⁡ 
         n 
         ) 
       
     
     {\displaystyle O(\log n)} 
    processors, the runtime of Kruskal's algorithm can be reduced to  O ( E  α( V )), where α again is the inverse of the single-valued Ackermann function.
 A variant of Kruskal's algorithm, named Filter-Kruskal, has been described by Osipov et al. and is better suited for parallelization. The basic idea behind Filter-Kruskal is to partition the edges in a similar way to quicksort and filter out edges that connect vertices of the same tree to reduce the cost of sorting. The following Pseudocode demonstrates this.
 
 FILTER-KRUSKAL(G):
1  if  |G.E| < KruskalThreshhold:
2     return  KRUSKAL(G)
3 pivot = CHOOSE-RANDOM(G.E)
4  
   
     
       
         
           E 
           
             <= 
           
         
       
     
     {\displaystyle E_{<=}} 
   ,  
   
     
       
         
           E 
           
             > 
           
         
       
     
     {\displaystyle E_{>}} 
    = PARTITION(G.E, pivot)
5 A = FILTER-KRUSKAL( 
   
     
       
         
           E 
           
             <= 
           
         
       
     
     {\displaystyle E_{<=}} 
   )
6  
   
     
       
         
           E 
           
             > 
           
         
       
     
     {\displaystyle E_{>}} 
    = FILTER( 
   
     
       
         
           E 
           
             > 
           
         
       
     
     {\displaystyle E_{>}} 
   )
7 A = A ∪ FILTER-KRUSKAL( 
   
     
       
         
           E 
           
             > 
           
         
       
     
     {\displaystyle E_{>}} 
   )
8  return  A

PARTITION(E, pivot):
1  
   
     
       
         
           E 
           
             <= 
           
         
       
     
     {\displaystyle E_{<=}} 
    = ∅,  
   
     
       
         
           E 
           
             > 
           
         
       
     
     {\displaystyle E_{>}} 
    = ∅
2  foreach  (u, v) in E:
3     if  weight(u, v) <= pivot:
4        
   
     
       
         
           E 
           
             <= 
           
         
       
     
     {\displaystyle E_{<=}} 
    =  
   
     
       
         
           E 
           
             <= 
           
         
       
     
     {\displaystyle E_{<=}} 
    ∪ {(u, v)}
5     else 
6        
   
     
       
         
           E 
           
             > 
           
         
       
     
     {\displaystyle E_{>}} 
    =  
   
     
       
         
           E 
           
             > 
           
         
       
     
     {\displaystyle E_{>}} 
    ∪ {(u, v)}
5  return   
   
     
       
         
           E 
           
             <= 
           
         
       
     
     {\displaystyle E_{<=}} 
   ,  
   
     
       
         
           E 
           
             > 
           
         
       
     
     {\displaystyle E_{>}} 
   

FILTER(E):
1  
   
     
       
         
           E 
           
             f 
             i 
             l 
             t 
             e 
             r 
             e 
             d 
           
         
       
     
     {\displaystyle E_{filtered}} 
    = ∅
2  foreach  (u, v) in E:
3     if  FIND-SET(u) ≠ FIND-SET(v):
4        
   
     
       
         
           E 
           
             f 
             i 
             l 
             t 
             e 
             r 
             e 
             d 
           
         
       
     
     {\displaystyle E_{filtered}} 
    =  
   
     
       
         
           E 
           
             f 
             i 
             l 
             t 
             e 
             r 
             e 
             d 
           
         
       
     
     {\displaystyle E_{filtered}} 
    ∪ {(u, v)}
5  return   
   
     
       
         
           E 
           
             f 
             i 
             l 
             t 
             e 
             r 
             e 
             d 
           
         
       
     
     {\displaystyle E_{filtered}} 
   
 
 Filter-Kruskal lends itself better for parallelization as sorting, filtering, and partitioning can easily be performed in parallel by distributing the edges between the processors. Finally, other variants of a parallel implementation of Kruskal's algorithm have been explored. Examples include a scheme that uses helper threads to remove edges that are definitely not part of the MST in the background, and a variant which runs the sequential algorithm on  p  subgraphs, then merges those subgraphs until only one, the final MST, remains. 

 