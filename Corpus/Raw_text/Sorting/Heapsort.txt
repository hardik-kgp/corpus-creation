***Heapsort***

 
 In computer science,  heapsort  is a comparison-based sorting algorithm. Heapsort can be thought of as an improved selection sort: like that algorithm, it divides its input into a sorted and an unsorted region, and it iteratively shrinks the unsorted region by extracting the largest element and moving that to the sorted region. The improvement consists of the use of a heap data structure rather than a linear-time search to find the maximum. Although somewhat slower in practice on most machines than a well-implemented quicksort, it has the advantage of a more favorable worst-case  O( n  log  n )  runtime.  Heapsort is an in-place algorithm, but it is not a stable sort.
 Heapsort was invented by J. W. J. Williams in 1964. This was also the birth of the heap, presented already by Williams as a useful data structure in its own right. In the same year, R. W. Floyd published an improved version that could sort an array in-place, continuing his earlier research into the treesort algorithm. 

 **Overview**

 The heapsort algorithm can be divided into two parts.
 In the first step, a heap is built out of the data (see Binary heap § Building a heap). The heap is often placed in an array with the layout of a complete binary tree. The complete binary tree maps the binary tree structure into the array indices; each array index represents a node; the index of the node's parent, left child branch, or right child branch are simple expressions.  For a zero-based array, the root node is stored at index 0; if  i  is the index of the current node, then
 
 In the second step, a sorted array is created by repeatedly removing the largest element from the heap (the root of the heap), and inserting it into the array. The heap is updated after each removal to maintain the heap property. Once all objects have been removed from the heap, the result is a sorted array.
 Heapsort can be performed in place. The array can be split into two parts, the sorted array and the heap. The storage of heaps as arrays is diagrammed here.  The heap's invariant is preserved after each extraction, so the only cost is that of extraction.
 

 **Algorithm**

 The Heapsort algorithm involves preparing the list by first turning it into a max heap. The algorithm then repeatedly swaps the first value of the list with the last value, decreasing the range of values considered in the heap operation by one, and sifting the new first value into its position in the heap. This repeats until the range of considered values is one value in length.
 The steps are:
 
 Call the buildMaxHeap() function on the list. Also referred to as heapify(), this builds a heap from a list in O(n) operations. 
 Swap the first element of the list with the final element. Decrease the considered range of the list by one. 
 Call the siftDown() function on the list to sift the new first element to its appropriate index in the heap. 
 Go to step (2) unless the considered range of the list is one element. The buildMaxHeap() operation is run once, and is  O( n )  in performance. The siftDown() function is  O(log  n ) , and is called  n  times. Therefore, the performance of this algorithm is  O( n  +  n  log  n ) = O( n  log  n ) .
 **Other variations**

 Ternary heapsort uses a ternary heap instead of a binary heap; that is, each element in the heap has three children. It is more complicated to program, but does a constant number of times fewer swap and comparison operations.  This is because each sift-down step in a ternary heap requires three comparisons and one swap, whereas in a binary heap two comparisons and one swap are required. Two levels in a ternary heap cover 3 2  = 9 elements, doing more work with the same number of comparisons as three levels in the binary heap, which only cover 2 3  = 8.  This is primarily of academic interest, as the additional complexity is not worth the minor savings, and bottom-up heapsort beats both. 
 The smoothsort algorithm is a variation of heapsort developed by Edsger Dijkstra in 1981. Like heapsort, smoothsort's upper bound is  O ( n  log  n ) . The advantage of smoothsort is that it comes closer to  O ( n )  time if the input is already sorted to some degree, whereas heapsort averages  O ( n  log  n )  regardless of the initial sorted state. Due to its complexity, smoothsort is rarely used. 
 Levcopoulos and Petersson describe a variation of heapsort based on a heap of Cartesian trees.  First, a Cartesian tree is built from the input in  O ( n )  time, and its root is placed in a 1-element binary heap.   Then we repeatedly extract the minimum from the binary heap, output the tree's root element, and add its left and right children (if any) which are themselves Cartesian trees, to the binary heap. As they show, if the input is already nearly sorted, the Cartesian trees will be very unbalanced, with few nodes having left and right children, resulting in the binary heap remaining small, and allowing the algorithm to sort more quickly than  O ( n  log  n )  for inputs that are already nearly sorted. 
 Several variants such as weak heapsort require  n  log 2 n + O (1)  comparisons in the worst case, close to the theoretical minimum, using one extra bit of state per node.  While this extra bit makes the algorithms not truly in-place, if space for it can be found inside the element, these algorithms are simple and efficient, : 40  but still slower than binary heaps if key comparisons are cheap enough (e.g. integer keys) that a constant factor does not matter. 
 Katajainen's "ultimate heapsort" requires no extra storage, performs  n  log 2 n + O (1)  comparisons, and a similar number of element moves.  It is, however, even more complex and not justified unless comparisons are very expensive. 

 **Comparison with other sorts**

 Heapsort primarily competes with quicksort, another very efficient general purpose nearly-in-place comparison-based sort algorithm.
 Quicksort is typically somewhat faster due to some factors, but the worst-case running time for quicksort is  O( n 2 ) , which is unacceptable for large data sets and can be deliberately triggered given enough knowledge of the implementation, creating a security risk. See quicksort for a detailed discussion of this problem and possible solutions.
 Thus, because of the  O( n  log  n )  upper bound on heapsort's running time and constant upper bound on its auxiliary storage, embedded systems with real-time constraints or systems concerned with security often use heapsort, such as the Linux kernel. Heapsort also competes with merge sort, which has the same time bounds. Merge sort requires  Ω( n )  auxiliary space, but heapsort requires only a constant amount. Heapsort typically runs faster in practice on machines with small or slow data caches, and does not require as much external memory. On the other hand, merge sort has several advantages over heapsort:
 
 Merge sort on arrays has considerably better data cache performance, often outperforming heapsort on modern desktop computers because merge sort frequently accesses contiguous memory locations (good locality of reference); heapsort references are spread throughout the heap. 
 Heapsort is not a stable sort; merge sort is stable. 
 Merge sort parallelizes well and can achieve close to linear speedup with a trivial implementation; heapsort is not an obvious candidate for a parallel algorithm. 
 Merge sort can be adapted to operate on  singly  linked lists with  O(1)  extra space. Heapsort can be adapted to operate on  doubly  linked lists with only  O(1)  extra space overhead. 
 Merge sort is used in external sorting; heapsort is not. Locality of reference is the issue. Introsort is an alternative to heapsort that combines quicksort and heapsort to retain advantages of both: worst case speed of heapsort and average speed of quicksort.
 

 **Example**

 Let { 6, 5, 3, 1, 8, 7, 2, 4 } be the list that we want to sort from the smallest to the largest. (NOTE, for 'Building the Heap' step: Larger nodes don't stay below smaller node parents. They are swapped with parents, and then recursively checked if another swap is needed, to keep larger numbers above smaller numbers on the heap binary tree.)
 

 