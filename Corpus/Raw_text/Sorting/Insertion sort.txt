***Insertion sort***
Insertion sort  is a simple sorting algorithm that builds the final sorted array (or list) one item at a time. It is much less efficient on large lists than more advanced algorithms such as quicksort, heapsort, or merge sort. However, insertion sort provides several advantages:
 
 Simple implementation: Jon Bentley shows a three-line C version, and a five-line optimized version 
 Efficient for (quite) small data sets, much like other quadratic sorting algorithms 
 More efficient in practice than most other simple quadratic (i.e., O( n 2 )) algorithms such as selection sort or bubble sort 
 Adaptive, i.e., efficient for data sets that are already substantially sorted: the time complexity is O( kn ) when each element in the input is no more than  k  places away from its sorted position 
 Stable; i.e., does not change the relative order of elements with equal keys 
 In-place; i.e., only requires a constant amount O(1) of additional memory space 
 Online; i.e., can sort a list as it receives it When people manually sort cards in a bridge hand, most use a method that is similar to insertion sort. 

 **Algorithm**

 Insertion sort iterates, consuming one input element each repetition, and growing a sorted output list. At each iteration, insertion sort removes one element from the input data, finds the location it belongs within the sorted list, and inserts it there. It repeats until no input elements remain.
 Sorting is typically done in-place, by iterating up the array, growing the sorted list behind it. At each array-position, it checks the value there against the largest value in the sorted list (which happens to be next to it, in the previous array-position checked). If larger, it leaves the element in place and moves to the next. If smaller, it finds the correct position within the sorted list, shifts all the larger values up to make a space, and inserts into that correct position.
 The resulting array after  k  iterations has the property where the first  k  + 1 entries are sorted ("+1" because the first entry is skipped). In each iteration the first remaining entry of the input is removed, and inserted into the result at the correct position, thus extending the result:
 
 becomes
 
 with each element greater than  x  copied to the right as it is compared against  x .

 **Relation to other sorting algorithms**

 Insertion sort is very similar to selection sort. As in selection sort, after  k  passes through the array, the first  k  elements are in sorted order. However, the fundamental difference between the two algorithms is that for selection sort these are the  k  smallest elements of the unsorted input, while in insertion sort they are simply the first  k  elements of the input. The primary advantage of insertion sort over selection sort is that selection sort must always scan all remaining elements to find the absolute smallest element in the unsorted portion of the list, while insertion sort requires only a single comparison when the ( k  + 1)-st element is greater than the  k -th element; when this is frequently true (such as if the input array is already sorted or partially sorted), insertion sort is distinctly more efficient compared to selection sort. On average (assuming the rank of the ( k  + 1)-st element rank is random), insertion sort will require comparing and shifting half of the previous  k  elements, meaning that insertion sort will perform about half as many comparisons as selection sort on average. In the worst case for insertion sort (when the input array is reverse-sorted), insertion sort performs just as many comparisons as selection sort. However, a disadvantage of insertion sort over selection sort is that it requires more writes due to the fact that, on each iteration, inserting the ( k  + 1)-st element into the sorted portion of the array requires many element swaps to shift all of the following elements, while only a single swap is required for each iteration of selection sort. In general, insertion sort will write to the array O( n 2 ) times, whereas selection sort will write only O( n ) times. For this reason selection sort may be preferable in cases where writing to memory is significantly more expensive than reading, such as with EEPROM or flash memory.
 While some divide-and-conquer algorithms such as quicksort and mergesort outperform insertion sort for larger arrays, non-recursive sorting algorithms such as insertion sort or selection sort are generally faster for very small arrays (the exact size varies by environment and implementation, but is typically between 7 and 50 elements). Therefore, a useful optimization in the implementation of those algorithms is a hybrid approach, using the simpler algorithm when the array has been divided to a small size. 

 **Variants**

 D. L. Shell made substantial improvements to the algorithm; the modified version is called Shell sort.  The sorting algorithm compares elements separated by a distance that decreases on each pass. Shell sort has distinctly improved running times in practical work, with two simple variants requiring O( n 3/2 ) and O( n 4/3 ) running time.
 If the cost of comparisons exceeds the cost of swaps, as is the case for example with string keys stored by reference or with human interaction (such as choosing one of a pair displayed side-by-side), then using  binary insertion sort  may yield better performance. Binary insertion sort employs a binary search to determine the correct location to insert new elements, and therefore performs ⌈log 2   n ⌉ comparisons in the worst case, which is O( n  log  n ). The algorithm as a whole still has a running time of O( n 2 ) on average because of the series of swaps required for each insertion.
 The number of swaps can be reduced by calculating the position of multiple elements before moving them. For example, if the target position of two elements is calculated before they are moved into the proper position, the number of swaps can be reduced by about 25% for random data. In the extreme case, this variant works similar to merge sort.
 A variant named  binary merge sort  uses a  binary insertion sort  to sort groups of 32 elements, followed by a final sort using merge sort. It combines the speed of insertion sort on small data sets with the speed of merge sort on large data sets. To avoid having to make a series of swaps for each insertion, the input could be stored in a linked list, which allows elements to be spliced into or out of the list in constant time when the position in the list is known.  However, searching a linked list requires sequentially following the links to the desired position: a linked list does not have random access, so it cannot use a faster method such as binary search.  Therefore, the running time required for searching is O( n ), and the time for sorting is O( n 2 ). If a more sophisticated data structure (e.g., heap or binary tree) is used, the time required for searching and insertion can be reduced significantly; this is the essence of heap sort and binary tree sort.
 In 2006 Bender, Martin Farach-Colton, and Mosteiro published a new variant of insertion sort called  library sort  or  gapped insertion sort  that leaves a small number of unused spaces (i.e., "gaps") spread throughout the array. The benefit is that insertions need only shift elements over until a gap is reached. The authors show that this sorting algorithm runs with high probability in O( n  log  n ) time. If a skip list is used, the insertion time is brought down to O(log  n ), and swaps are not needed because the skip list is implemented on a linked list structure.  The final running time for insertion would be O( n  log  n ).
 List insertion sort  is a variant of insertion sort. It reduces the number of movements. 

 **List insertion sort code in C**

 If the items are stored in a linked list, then the list can be sorted with O(1) additional space.  The algorithm starts with an initially empty (and therefore trivially sorted) list. The input items are taken off the list one at a time, and then inserted in the proper place in the sorted list. When the input list is empty, the sorted list has the desired result.
 

 The algorithm below uses a trailing pointer for the insertion into the sorted list. A simpler recursive method rebuilds the list each time (rather than splicing) and can use O( n ) stack space.
 

 

 