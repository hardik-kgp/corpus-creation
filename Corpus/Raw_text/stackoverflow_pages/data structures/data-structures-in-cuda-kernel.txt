*** data-structures-in-cuda-kernel ***

 I am trying to implement a random forest in CUDA, each thread being an individual decision tree, which requires recursion. However, my computer does not support recursion in CUDA.. So I am trying to use data structures like queue to perform the recursion part.I googled but I can't find much information about that, and I tried using Thrust inside CUDA kernel but it won't compile..
So is there a way to use queue inside a CUDA kernel?
Thanks in advance! 
 
 CUDA, and GPU computation in general, is fast  **only if all threads do the same thing**
 (well, technically every 32 threads need to be doing the exact same on most hardware). GPUs have many computation units, but little  control flow  capabilities. 
 
 in 3D graphics, you apply the exact same projection to all vertices, then apply the same shaders for all pixels, etc. 
 matrix multiplications: you do the exact same order of operations, just on different parts of the data. 
 
 This is what the hardware was optimized for. Decision trees (and thus random forests) are not of this kind. You will be taking different if/else branches in each tree. So this is  not  a good fit for GPUs. You will get horrible branch efficiency. Your performance will drop to less than 1/32 (i.e. 3%) of the theoretical capabilities of your hardware. 
 From Wikipedia CUDA limitations: 
 
 Branches in the program code do not affect performance significantly, provided that each of 32 threads takes the same execution path 
 
 Same execution path = all 32 threads do the "if true" branch, or all 32 do the "else" branch. 
 (There is a "hack" around this, but it is fairly expensive IMHO, and I don't think it will be fully competitive with approaches that are designed for GPUs e.g. via matrix multiplications right away. I'm too lazy to type it in - you'll find it in GPU literature for sure. It's fairly common to speed up  single  if operations. While this should be possible for multiple levels of if's, it will be much less effective because the cost is growing exponentially with the depth. Sometimes, either the CUDA compiler or the CPU may be able to optimize this automatically for simple/shallow if cases.) 
 