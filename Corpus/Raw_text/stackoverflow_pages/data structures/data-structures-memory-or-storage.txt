*** data-structures-memory-or-storage ***

 When we talk about Data Structures (like array), do we refer to how the data is stored in RAM (contiguous memory locations) or the Hard Disk? If it also refers to the Hard Disk, how is the physical implementation different from RAM? 
 
 We prefer the contiguous memory locations. The reason becomes obvious if we look at the hardware level.  
 **CPU**
 doesn't directly interact with the  **RAM**
, it does so via   (often divided into levels such as  , ,  etc. with   being smallest and fastest). Whenever  **CPU**
 want some data, it sends request to  , if not found,   delegates the request to   and so on (till hard disk) as shown in below figure: 
 
 Now when data is not found in any cache, we term it a  **cache miss.**
 To reduce cache miss, when the  **CPU**
 wants to access data at address   in  **RAM**
, it will not only fetch the data at address  , but also the neighborhood of address  (see below picture). Because we assume "if a particular memory location is referenced at a particular time, then it is likely that nearby memory locations will be referenced in the near future (aka  **locality of reference**
). 
 
 Accessing the array elements ensures sequential data access and thus  **minimum cache misses**
. You could now visualize why arrays are much faster than data structures like linked lists in terms of random/sequential data access. Same though process applies to other data structures as well. 
 