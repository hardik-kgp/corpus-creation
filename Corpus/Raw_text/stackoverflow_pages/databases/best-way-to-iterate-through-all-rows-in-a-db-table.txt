*** best-way-to-iterate-through-all-rows-in-a-db-table ***

 I often write little Python scripts to iterate through all rows of a DB-table. 
For example sending all to all subscribers a email. 
 I do it like this 
 
 I wonder if there is a better way to do this cause it is possible that my code loads thousands of rows into the memory. 
 I thought about that it could be done better with  .
Maybe something like that: 
 
 Whats the best way to do it?
How would you do it? 
 
 unless you have BLOBs in there, thousands of rows shouldn't be a problem. Do you know that it is? 
 Also, why bring shame on yourself and your entire family by doing something like 
 
 when the cursor will make the substitution for you in a manner that avoids SQL injection? 
 
 
 You don't have to modify the query, you can use the  **fetchmany**
 method of cursors. Here is how I do it :   
 
 This way you can "SELECT * FROM tbl_subscriber;" but you will only fetch  **some**
 at a time. 
 
 Most MySQL connectors based on libmysqlclient will buffer all the results in client memory by default for performance reasons (with the assumption you won't be reading large resultsets). 
 When you do need to read a large result in MySQLdb you can use a SSCursor to avoid buffering entire large resultsets. 
 http://mysql-python.sourceforge.net/MySQLdb.html#using-and-extending 
 
 SSCursor - 
  A "server-side" cursor. Like Cursor
  but uses CursorUseResultMixIn. Use
  only if you are dealing with
  potentially large result sets. 
 
 This does introduce complications that you must be careful of.  If you don't read all the results from the cursor, a second query will raise an ProgrammingError: 
 
 This means you have to always read everything from the cursor (and potentially multiple resultsets) before issuing another - MySQLdb won't do this for you. 
 
 First of all maybe you don't need Select * from...  
 maybe it's enough for you just to get some stuff like: "SELECT email from..." 
 that would decrease the amount of memory usage anyway:) 
 
 Do you have actual memory problems? When iterating over a cursor, results are fetched one at a time (your DB-API implementation might decide to prefetch results, but then it might offer a function to set the number of prefetched results). 
 