*** cannot-fetch-a-row-from-ole-db-provider-bulk-for-linked-server-null ***

 I try to load my database with tons of data from a .csv file sized 1.4 GB. But when I try to run my code I get errors.  
 Here's my code: 
 
 I try to build a database with lots of stockquotes. But I get this error message: 
 
 Msg 4832, Level 16, State 1, Line 2 Bulk load: An unexpected end of
  file was encountered in the data file. Msg 7399, Level 16, State 1,
  Line 2 The OLE DB provider "BULK" for linked server "(null)" reported
  an error. The provider           did not give any information about
  the error. Msg 7330, Level 16, State 2, Line 2 Cannot fetch a row from
  OLE DB provider "BULK" for linked server "(null)" 
 
 I do not understand much of SQL, but I hope to catch a thing or two. Hope someone see what might be very obvious. 
 
 Resurrecting an old question, but in case this helps someone else: after much trial-and-error I was finally (finally!) able to get rid of this error by changing this: 
 
 To this: 
 
 
 I had same issue.  
 Solution: 
 Verify the CSV or textfile in text editors like notepad+. Last line might be incomplete. Remove it. 
 
 I got the same error when I had a different number of delimited fields in my CSV than columns I had in my table. Check if you have the right number of fields in  . 
 
 I got this error when my format file (i.e. specified using the   param) had a column width that was smaller than the actual column size (e.g.   instead of  ). 
 
 It was an old question but It seems that my finding would enlight some other people having a similar issue. 
 The default SSIS timeout value appears to be 30 seconds. This makes any service bound or IO bound operation in your package goes well beyond that timeout value and causes a timeout. Increasing that timeout value (change to "0" for no timeout) will resolve the issue. 
 
 I got this exception when the char field in my SQL table was too small for the text coming in. Try making the column bigger.  
 
 I encountered a similar issue, but in this case the file being loaded contained some blank lines.  Removing the blank lines solved it. 
 Alternatively, as the file was delimited, I added the correct number of delimiters to the blank lines, which again allowed the file to import successfully - use this option if the blank lines need to be loaded. 
 
 This might be a bad idea with a full 1.5GB, but you can try it on a subset (start with a few rows): 
 
 ... do your BULK INSERT, then 
 
 This will help tell you if your estimates of column are way off. You might also find your columns are out of order, or the BULK INSERT might still fail for some other reason. 
 
 i just want to share my solution to this. The problem was the size of table columns, use varchar(255) and all should work. 
 
 This is my solution: just give up. 
 I always end up using SSMS and  . 
 I have  never  managed to get a real world .csv file to import using this method. This is utterly useless function that only works on pristine datasets that don't exist in the real world. Perhaps I've never had any luck because the datasets I deal with are quite messy and are generated by third parties. 
 And if it goes wrong, it doesn't give any clue as to why. Microsoft, you sadden me with your utter incompetence in this area.  
 Microsoft, perhaps add some error messages, so it says  why  it rejected it? Because it's almost impossible to fix the issue if you don't know why it failed! 
 