*** database-index-on-a-column-with-duplicate-values ***

 If there is a table containing details of employees including a column Gender whose value can be either M/F. Now would it make sense to create an index on this column, would it make the search faster? Logically if we fire a select statement with where clause containing Gender as the column, it should cut down the search time by half. But I have heard that this kind of index will not help and would be actually ignored by the Database Optimizer while executing the query. But I am not getting why? Can somebody please explain?  
 
 In most cases, only one index can be used to optimize a database query. If a query needs to match several indexed columns, the query planner will have to decide which of these indexes to use. Each index has a  cardinality , which is roughly the number of different values across the table. An index with higher cardinality will be more effective, because selecting rows that match the index will result in very few rows to scan to match the other conditions. 
 An index on a   column will only cut the table in half. Any other index will be more effective. 
 As an analogy, think of phone books. If you had a single phone book for an entire country, it would be huge and hard to search for the specific person you want. So phone books are usually made for just a city, or a few cities in an area, to make them reasonable sizes. But if you instead had a "Male phone book" instead of regional phone books, it would be nearly as unusable as a phone book for the entire country. The criteria for creating new phone books is that they should be much smaller than a book for the entire country. A factor of 2 reduction isn't very useful when you're starting with an enormous size. 
 
 Presumably, gender take on two values.  In general, an index on   would not be helpful.  In fact, it might be hurtful. 
 If you are selecting on gender, without an index, the query optimizer does a full table scan of the database pages to satisfy the query.  On a typical page, half the entries would match the query, so you would start getting results on the first hit. 
 In this phase of query execution, an index is typically used to reduce the number of pages being read.  However, if every page has a record with "M" and "F", then every page still has to be read.  To make matters worse, using an index means that you read from one random page, and then another, and another, instead of just reading the values sequentially.  Jumping around pages takes a bit extra time.  If the pages do not all fit in memory, you have a situation called thrashing, and it could take a really, really long time. 
 The one exception to this is a clustered index, where the values on the pages are actually sorted by the values.  In that case, a query using the index would be about 50% faster, because only have the pages need to be read.  This can be particularly effective in an "archive" table, where you have active records that are frequently searched.  This flag might occur on 10%, 1%, or 0.1% of the records, and the clustered index can be a significant speed improvement. 
 It would be rare on a large table to run a query that returns half the records.  Quite possibly, gender in combination with other columns would be a good candidate for inclusion in an index. 
 