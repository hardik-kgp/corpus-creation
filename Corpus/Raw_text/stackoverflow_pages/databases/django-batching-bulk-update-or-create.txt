*** django-batching-bulk-update-or-create ***

 I have data in the database which needs updating peridocially. The source of the data returns everything that's avalible at that point in time, so will include new data that is not already in the database. 
 As I loop through the source data I don't want to be making 1000s of individual writes if possible. 
 Is there anything such as   but works in batches? 
 One thought was using   in combination with manual transactions, but I'm not sure if that just queues up the individual writes or if it would combine it all into one SQL insert?  
 Or similarly could using   on a function with   inside a the loop work? 
 I am not doing anything with the data other than translating it and saving it to a model. Nothing is dependant on that model existing during the loop 
 
 Batching your updates is going to be an upsert command and like @imposeren said, Postgres 9.5 gives you that ability. I think Mysql 5.7 does as well (see  http://dev.mysql.com/doc/refman/5.7/en/insert-on-duplicate.html ) depending on your exact needs. That said it's probably easiest to just use a db cursor. Nothing wrong with that, it's there for when the ORM just isn't enough. 
 Something along these lines should work. It's psuedo-ish code, so don't just cut-n-paste this but the concept is there for ya. 
 
 Assumptions here are: 
 
  is some kind of results iterator, either in a list or dictionary 
 A result from   can be fed directly into a raw sql exec statement 
 If any of the batch updates fail, you'll be rolling back ALL of them. If you want to move that to for each chunk, just push the   block down a bit 
 
 