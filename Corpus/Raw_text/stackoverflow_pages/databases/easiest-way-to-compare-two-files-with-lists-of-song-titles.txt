*** easiest-way-to-compare-two-files-with-lists-of-song-titles ***

 I have two lists of song titles, each in a plain text file,  which are the filenames of licensed lyric files - I want to check if the shorter list titles (needle) are in the longer list (haystack). The script/app should return the list of titles in the needle that aren't in the haystack. 
 I'd prefer to use Python or a shell script (BASH) or just use visual diff program that can handle the fuzziness needed. 
 The main problem is that the titles need to be fuzzy matched to account for data entry errors and possibly also word ordering. 
 Haystack sample (note some duplicate and near duplicate lines, matches highlighted): 
 
 Needle sample: 
 
 Note that the needle title "Your Love Shining Like The Sun" is only a possible match for "Your Love". It's better to fail towards not matching and therefore any uncertain title matches should appear in the output. 
 
 doesn't find any of the matches.   or   seems they'd have the same problem with not being fuzzy enough.   and   were as quick as a manual comparison as I had to still scan through for nearly all matches, they could only cope with whitespace and letter-case differences. 
  from prestosoft.com looks like a possibility but is MS Windows only and I'd prefer a native Linux solution before I go messing with WINE or VirtualBox. 
 The needle is actually a CSV so I've thought about using LibreOffice and treating it as a database and doing SQL queries or using a spreadsheet with hlookup or something ...  Another  question led me to  OpenRefine (formerly google-refine) 
 Seems like this is a common category of problem (it's basically "record linkage" which often uses [Levenshtein] edit-distance calculation), how should I approach it? Suggestions please? 
 
 I did something similar to this in MySQL.  I used the following code to define Levenshtein distance and ratio functions (which I got from the answer to  this question ): 
 
 Assuming you import your lists as the following two tables: 
 
 You can then use a query like the following one to compare the two tables. 
 
 Pick a cutoff value, all rows below that value didn't have good matches.  You can use levenshtein() instead of levenshtein_ratio() if you want to work with edit distances directly, in this case the ORDER BY to ASC. 
 Note that this doesn't have any special provision for word order differences.  Also, if your lists are large, the comparison can be slow. 
 
 Fuzzywuzzy can make your dreams come true: 
 
 Rather than fuzz.ratio, you may get beter results using:  
 
 IMO,  this tutorial  is the best + most concise overview of fuzzy matching in Python  
 
 If you want to go the OpenRefine way, the best is set up a local reconciliation server - I recommand  reconcile csv . 
 Load your haystack in the reconciliation server and have OpenRefine processing your needle file and sending it to the reconciliation service.  
 Reconciliation server return a score with each proposal so you can (I just use those score as example, don't take them for granted): 
 
 bulk accept everything over 0.9 
 review manually everything between 0.8 and 0.9 
 discard everything below 0.8 
 
 
 You might want to look at fuzzywuzzy ( https://github.com/seatgeek/fuzzywuzzy ). 
 
 Usefull params for the extract function are limit, scorer, and processor. 
 