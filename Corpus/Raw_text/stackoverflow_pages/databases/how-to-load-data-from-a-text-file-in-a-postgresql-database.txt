*** how-to-load-data-from-a-text-file-in-a-postgresql-database ***

 I have a file like (CSV file): 
 
 and would like to load these data into a postgresql table. 
 
 The slightly modified version of   below worked better for me, where I specify the   format. This format treats backslash characters in text without any fuss. The default format is the somewhat quirky  . 
 
 
 Let consider that your data are in the file   and that you want to import them in the database table   then the following query does the job 
 
 https://www.postgresql.org/docs/current/static/sql-copy.html 
 
 Check out the COPY command of Postgres: 
 http://www.postgresql.org/docs/current/static/sql-copy.html 
 
 There's  Pgloader  that uses the aforementioned   command and which can load data from csv (and MySQL, SQLite and dBase). It's also using separate threads for reading and copying data, so it's quite fast (interestingly enough, it got written from Python to Common Lisp and got a 20 to 30x speed gain, see  blog post ). 
 To load the csv file one needs to write a little configuration file, like 
 
 