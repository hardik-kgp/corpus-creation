*** solution-for-speeding-up-a-slow-select-distinct-query-in-postgres ***

 The query is basically: 
 
 Pretending that I'm 100% certain the   portion of the query is the reason it runs slowly, I've omitted the rest of the query to avoid confusion, since it is the distinct portion's slowness that I'm primarily concerned with (distinct is always a source of slowness). 
 The table in question has 2.5 million rows of data. The    is  needed for purposes not listed here (because I don't want back a modified query, but rather just general information about making distinct queries run faster at the  DBMS  level,  if  possible). 
 How can I make   run quicker (using Postgres 9, specifically) without altering the SQL (ie, I can't alter this SQL coming in, but have access to optimize something at the DB level)? 
 
 Your DISTINCT is causing it to sort the output rows in order to find duplicates.  If you put an index on the column(s) selected by the query, the database may be able to read them out in index order and save the sort step.  A lot will depend on the details of the query and the tables involved-- your saying you "know the problem is with the DISTINCT" really limits the scope of available answers. 
 
 Oftentimes, you can make such queries run faster by working around the   by using a   instead: 
 
 
 You can try increasing the work_mem setting, depending on the size of Your dataset It can cause switching the query plan to hash aggregates, which are usually faster. 
 But before setting it too high globally, first read up on it. You can easily blow up Your server, because the   setting acts as a multiplier to this number.  
 This means that if you were to set   and you set   (the default), you should have more than 12.8GB of RAM. You're essentially telling the server that it can use that much for performing queries (not even considering any other memory use by Postgres or otherwise). 
 