*** sql-server-statistics ***

 So for this one project, we have a bunch of queries that are executed on a regular basis (every minute or so. I used the "Analyze Query in Database Engine " to check on them.  
 They are pretty simple:
select * from tablex where processed='0' 
 There is an index on processed, and each query should return <1000 rows on a table with 1MM records. 
 The Analyzer recommended creating some STATISTICS on this.... So my question is: What are those statistics ? do they really help performance ? how costly are they for a table like above ?  
 Please bear in mind that by no means I would call myself a SQL Server experienced user ... And this is the first time using this Analyzer. 
 
 Statistics are what SQL Server uses to determine the viability of how to get data. 
 Let's say, for instance, that you have a table that only has a clustered index on the primary key. When you execute  , SQL Server only has one option, to scan every row in the table to find the matching rows. 
 Now we add an index on col1 so you assume that SQL Server will use the index to find the matching rows, but that's not always true. Let's say that the table has 200,000 rows and   only has 2 values: 1 and 0. When SQL Server uses an index to find data, the index contains pointers back to the clustered index position. Given there's only two values in the indexed column, SQL Server decides it makes more sense to just scan the table because using the index would be more work. 
 Now we'll add another 800,000 rows of data to the table, but this time the values in   are widely varied. Now it's a useful index because SQL Server can viably use the index to limit what it needs to pull out of the table. Will SQL Server use the index? 
 It depends. And what it depends on are the Statistics. At some point in time, with   set on, the server will update the statistics for the index and know it's a very good and valid index to use. Until that point, however, it will ignore the index as being irrelevant. 
 That's one use of statistics. But there is another use and that isn't related to indices. SQL Server keeps basic statistics about all of the columns in a table. If there's enough different data to make it worthwhile, SQL Server will actually create a temporary index on a column and use that to filter. While this takes more time than using an existing index, it takes less time than a full table scan. 
 Sometimes you will get recommendations to create specific statistics on columns that would be useful for that. These aren't indices, but the do keep track of the statistical sampling of data in the column so SQL Server can determine whether it makes sense to create a temporary index to return data. 
 HTH 
 
 In Sql Server 2005, set auto create statistics and auto update statistics.  You won't have to worry about creating them or maintaining them yourself, since the database handles this very well itself. 
 