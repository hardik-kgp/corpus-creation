*** what-is-the-relational-database-equivalent-of-factorial-and-the-fibonacci-functi ***

 When learning a new programming language there are always a couple of traditional problems that are good to get yourself moving. For example, Hello world and Fibonacci will show how to read input, print output and compute functions (the bread and butter that will solve basically everything) and while they are really simple they are nontrivial enough to be worth their time (and there is always some fun to be had by calculating the factorial of a ridiculously large number in a language with bignums) 
 So now I'm trying to get to grips with some SQL system and all the textbook examples I can think of involve mind-numbingly boring tables like "Student" or "Employee".  **What nice alternate datasets could I use instead?**
 I am looking for something that ( **in order of importance**
) ... 
 
 **The data can be generated by a straightforward algorithm.**

 
 I don't want to have to enter things by hand. 
 I want to be able to easily increase the size of my tables to stress efficiency, etc 
 
 **Can be used to showcase as much stuff as possible.**
 Selects, Joins, Indexing... You name it. 
 **Can be used to get back some interesting results.**

 
 I can live with "boring" data manipulation if the data is real and has an use by itself but I'd rather have something more interesting if I am creating the dataset from scratch. 
 
 
 In the worst case, I at least presume there should be some sort of benchmark dataset out there that would at least fit the first two criteria and I would love to hear about that too. 
 
 The benchmark database in the Microsoft world is  Northwind .  One similar open source (EPL) one is Eclipse's  Classic Models  database. 
 You can't autogenerate either as far as I know. 
 However, Northwind "imports and exports specialty foods from around the world", while Classic Models sells "scale models of classic cars".  Both are pretty interesting. :) 
 
 SQL is a query language, not a procedural language, so unless you will be playing with PL/SQL or something similar, your examples will be manipulating data.  
 So here is what was fun for me -- data mining! Go to: 
 http://usa.ipums.org/usa/ 
 And download their micro-data (you will need to make an account, but its free).  
 You'll need to write a little script to inject the fixed width file into your db, which in itself should be fun. And you will need to write a little script to auto create the fields (since there are many) based on parsing their meta-file. That's fun, too. 
 Then, you can start asking questions. Suppose the questions are about house prices: 
 Say you want to look at the evolution of house price values by those with incomes in the top 10% of the population over the last 40 years. Then restrict to if they are living in california. See if there is a correlation between income and the proportion of mortgage payments as a percentage of income. Then group this by geographic area. Then see if there is a correlation between those areas with the highest mortgage burden and the percentage of units occupied by renters. Your db will have some built-in statistical functions, but you can always program your own as well -- so correl might be the equivalent of fibonnacci. Then write a little script to do the same thing in R, importing data from your db, manipulating it, and storing the result. 
 The best way to learn about DBs is to use them for some other purpose.  
 Once you are done playing with iPUMS, take a look at GEO data, with (depending on your database) something like PostGis -- the only difference is that iPUMS gives you resolution in terms of tracts, whereas GIS data has latitude/longitude coordinates. Then you can plot a heat map of mortgage burdens for the U.S., and evolve this heat map over different time scales.  
 
 Perhaps you can do something with chemistry. Input the 118 elements, or extract them for an online source.  Use basic rules to combine them into molecules, which you can store in the database.  Combine molecules into bigger molecules and perform more complex queries upon them. 
 
 You will have a hard time finding database agnostic tutorials. The main reason for that is that the  SQL-92 standard  on which most examples are based on is plain old boring. There are updated standards, but most database agnostic tutorials will dumb-it-down to the lowest common denomiator: SQL-92. 
 If you want to learn about databases as a software engineer, I would definitely recommend starting with Microsoft SQL Server. There are many reasons for that, some are facts, some are opinions. The primary reason though is that it's a lot easier to get a lot further with SQL Server. 
 As for sample data, Northwind has been replaced by AdventureWorks. You can get the latest versions from  codeplex . This is a much more realistic database and allows demonstrating way more than basic joins, filtering and roll-ups. The great thing too, is that it is actually maintained for each release of SQL Server and updated to showcase some of the new features of the database. 
 Now, for your goal #1, well, I would consider the scaling out an exercise. After you go through the basic and boring stuff, you should gradually be able to perform efficient large-scale data manipulation and while not really generating data, at least copy/paste/modify your SQL data to take it to the size you think. 
 Keep in mind though that benchmarking databases is not trivial. The performance and efficiency of a database depends on many aspect of your  application . How it is used is just as important as how it is setup. 
 Good luck and do let us know if you find a viable solution outside this forum. 
 
 Implement your genealogical tree within a single table and print it. In itself is not a very general problem, but the approach certainly is, and it should prove reasonably challenging. 
 
 Geographic data can showcase a lot of SQL capabilities while being somewhat complicated (but not too complicated). It's also readily available from many sources online - international organizations, etc. 
 You could create a database with countries, cities, zip codes, etc. Mark capitals of countries (remember that some countries have more than one capital city...). Include GIS data if you want to get really fancy. Also, consider how you might model different address information. Now what if the address information had to support international addresses? You can do the same with phone numbers as well. Once you get the hang of things you could even integrate with Google Maps or something similar. 
 You'd likely have to do the database design and import work yourself, but really that's a pretty huge part of working with databases. 
 
 Eclipse's Classic Model   database is the best open source database equivalent of Factorial and the Fibonacci function .And Microsoft's  Northwind  is the another powerful  alternative that you can use . 
 