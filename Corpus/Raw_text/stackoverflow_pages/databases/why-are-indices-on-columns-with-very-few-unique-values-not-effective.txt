*** why-are-indices-on-columns-with-very-few-unique-values-not-effective ***

 So, most database experts say it's not effective creating an index on a column with very few unique values, relative to the size of the table.  
 Based on how databases work internally (I know most databases store indices using a B-tree), why does a B-Tree with few unique values make searching inefficient?  
 
 First, you need to understand how an index on a column works. In simple words it is nothing but, 
 
 an ordered list of all possible values in the given column with a  pointer  back to the actual record in the database.  
 
 Since it is ordered, a binary search can be used against it, rather than a linear search, which improves performance over a large dataset. 
 Imagine then, your index as a phone book ordered by a column, say  ; but within the set of records with a similar  , there isn't a common pattern or meaningful order for the records: they are ordered purely random. And say we need to search this record: 
 
 Ike Smith 4783 Random Ave. Seattle, WA 98117 
 
 Since the phone book is ordered by  , we need only to go to the  , then the  , then the  , etc. until we find  . And (hopefully) there are only a couple of records under   so we find the one we want fairly quickly. 
 Now, imagine you have a phone book ordered by   instead of  . And within the records that match a given   there is no particular order. And so we try our search again. However, once we find   (using a extremely sophisticated binary search) we are left with close to 620,778 records, which we  have  to check sequentially as they ordered completely random. We're stuck checking  every  single entry for the record we want.  
 This is what happens when you use a very common column as the base of your index: the binary search returns a very large set of possible records with which the database can't make any assumptions beyond the initial indexed column values, so it needs to check sequentially within the resulting set for a matching record. 
 If the phone book were instead ordered by   (a less common variable), then you might find yourself only searching for 18,623 records residing on  . 
 Furthermore, a true phone book usually resembles a composite index: instead of just ordering by a single column (i.e.  ), the values within the resulting set are then ordered by another column (say  ), and then another ( ?) so the search can be done sub linearly at every step until you find the record needed. It it basically an index within an index, where even if the first column is not that common, the combination with the second one provides a specific enough criteria that only a small set of records need to be search linearly. 
 
 In general, the goal of the index is to provide faster than linear search by avoiding having to scan through a significant portion of the data in the table (see  http://en.wikipedia.org/wiki/Database_index ).  If many of the would-be indexed values are identical, the database has to scan a significant portion of the table even after a successful index lookup. 
 So an index that has few unique values would provide very little performance benefit independent of its implementation. 
 
 When you have very few unique values the hash (if you use a hashtable) will be the same for many entries and provide no speed up. With a b tree many entries in the range will be very small. Basically one you run into non unique values you have to either return more entries as results or use more criteria to search the data base 
Since a primary key is guaranteed to have all unique values it is often indexed 
A good example would be to consider the worst case where all the values are the same, in a b-tree or a hashtable you gain no performance advantage by indexing the data 
 
 In a b-tree, the index is stored separately(at least on-disk) from the data. A search on a b-tree requires   for lookups, and another   for the seek to the table itself. 
 When searching without the index, you encounter a large lookup time via scanning the table, namely  . However, when matching results are stored throughout the table, the lookups on the index exceed(in terms of resources) the lookups by doing a table scan.  
 When you have many values that can match a query, you make a   lookup on the index and a seek to the table data itself. You then  almost  reach a table scan (since sequential lookups across most of the table are near a scan) so the small reduction of table scanning by the index is smaller than the waste searching the index itself. 
 More details:
The tree lookup and seek latency(on hard disks) where heads must be repositioned happens once for every match(with a naive index lookup approach) while a table scan simply happens once. Even if the data is clustered in the index, computation and scanning must take place and the query optimizer selects a table scan instead. 
  Pardon the poor organization of this post, I'm operating from lack of sleep 
 